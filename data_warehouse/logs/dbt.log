[0m22:02:08.897129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B137BD5880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B131EB50A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B137D2D280>]}


============================== 22:02:08.901685 | 3b5aa243-25b5-4ca0-a990-4b2cc3fde74e ==============================
[0m22:02:08.901685 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:02:08.902819 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:02:08.924537 [info ] [MainThread]: dbt version: 1.8.5
[0m22:02:08.925539 [info ] [MainThread]: python version: 3.12.2
[0m22:02:08.925938 [info ] [MainThread]: python path: C:\Users\new user\AppData\Local\Programs\Python\Python312\python.exe
[0m22:02:08.926957 [info ] [MainThread]: os info: Windows-11-10.0.22631-SP0
[0m22:02:08.989876 [info ] [MainThread]: Using profiles dir at C:\Users\new user\OneDrive\Learning Progress Review\Data Engineering\Project2\dbt\data_warehouse
[0m22:02:08.990815 [info ] [MainThread]: Using profiles.yml file at C:\Users\new user\OneDrive\Learning Progress Review\Data Engineering\Project2\dbt\data_warehouse\profiles.yml
[0m22:02:08.992390 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\new user\OneDrive\Learning Progress Review\Data Engineering\Project2\dbt\data_warehouse\dbt_project.yml
[0m22:02:08.994338 [info ] [MainThread]: adapter type: postgres
[0m22:02:08.995336 [info ] [MainThread]: adapter version: 1.8.2
[0m22:02:09.091197 [info ] [MainThread]: Configuration:
[0m22:02:09.091197 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m22:02:09.092797 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m22:02:09.093814 [info ] [MainThread]: Required dependencies:
[0m22:02:09.094805 [debug] [MainThread]: Executing "git --help"
[0m22:02:09.126214 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m22:02:09.126214 [debug] [MainThread]: STDERR: "b''"
[0m22:02:09.127214 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m22:02:09.128220 [info ] [MainThread]: Connection:
[0m22:02:09.129215 [info ] [MainThread]:   host: localhost
[0m22:02:09.130214 [info ] [MainThread]:   port: 5433
[0m22:02:09.130214 [info ] [MainThread]:   user: postgres
[0m22:02:09.131221 [info ] [MainThread]:   database: data_warehouse
[0m22:02:09.132795 [info ] [MainThread]:   schema: dbt_dev
[0m22:02:09.133748 [info ] [MainThread]:   connect_timeout: 10
[0m22:02:09.134745 [info ] [MainThread]:   role: None
[0m22:02:09.135742 [info ] [MainThread]:   search_path: None
[0m22:02:09.136739 [info ] [MainThread]:   keepalives_idle: 0
[0m22:02:09.137740 [info ] [MainThread]:   sslmode: None
[0m22:02:09.138740 [info ] [MainThread]:   sslcert: None
[0m22:02:09.138740 [info ] [MainThread]:   sslkey: None
[0m22:02:09.140283 [info ] [MainThread]:   sslrootcert: None
[0m22:02:09.141303 [info ] [MainThread]:   application_name: dbt
[0m22:02:09.141303 [info ] [MainThread]:   retries: 1
[0m22:02:09.142855 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:02:09.143863 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m22:02:11.795997 [debug] [MainThread]: Using postgres connection "debug"
[0m22:02:11.796697 [debug] [MainThread]: On debug: select 1 as id
[0m22:02:11.797776 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:02:11.812646 [debug] [MainThread]: SQL status: SELECT 1 in 0.015 seconds
[0m22:02:11.814659 [debug] [MainThread]: On debug: Close
[0m22:02:11.815660 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m22:02:11.816657 [info ] [MainThread]: [32mAll checks passed![0m
[0m22:02:11.818660 [debug] [MainThread]: Command `dbt debug` succeeded at 22:02:11.818660 after 3.06 seconds
[0m22:02:11.819351 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m22:02:11.819880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B137929220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B137D51100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B137F1B950>]}
[0m22:02:11.820416 [debug] [MainThread]: Flushing usage events
[0m22:09:45.416484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231A07C72F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231A07C4EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231A07C5E50>]}


============================== 22:09:45.420493 | eea2a9f5-b320-48f2-98cc-290da8ab93df ==============================
[0m22:09:45.420493 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:09:45.422492 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse', 'log_path': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s payment', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:09:45.733937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eea2a9f5-b320-48f2-98cc-290da8ab93df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231A0BF2B70>]}
[0m22:09:45.794175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eea2a9f5-b320-48f2-98cc-290da8ab93df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002319F7F6F30>]}
[0m22:09:45.795098 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:09:45.823828 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:09:45.824918 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m22:09:45.825828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'eea2a9f5-b320-48f2-98cc-290da8ab93df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231A0C67AA0>]}
[0m22:09:49.395931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eea2a9f5-b320-48f2-98cc-290da8ab93df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231A1D1DA00>]}
[0m22:09:49.551527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eea2a9f5-b320-48f2-98cc-290da8ab93df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231A2113980>]}
[0m22:09:49.553527 [info ] [MainThread]: Found 3 models, 4 data tests, 1 source, 417 macros
[0m22:09:49.554529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eea2a9f5-b320-48f2-98cc-290da8ab93df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231A217ABD0>]}
[0m22:09:49.557127 [info ] [MainThread]: 
[0m22:09:49.558136 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:09:49.560181 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m22:09:49.621972 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:09:49.622973 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:09:49.623980 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:09:49.639579 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.016 seconds
[0m22:09:49.640590 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:09:49.642558 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse, now create_data_warehouse_dbt_dev_raw)
[0m22:09:49.643559 [debug] [ThreadPool]: Creating schema "database: "data_warehouse"
schema: "dbt_dev_raw"
"
[0m22:09:49.649255 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_raw"
[0m22:09:49.650539 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_raw: BEGIN
[0m22:09:49.651142 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:09:49.659350 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m22:09:49.660388 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_raw"
[0m22:09:49.660388 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "create_data_warehouse_dbt_dev_raw"} */
create schema if not exists "dbt_dev_raw"
[0m22:09:49.662903 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m22:09:49.663913 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_raw: COMMIT
[0m22:09:49.663913 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_raw"
[0m22:09:49.665170 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_raw: COMMIT
[0m22:09:49.668340 [debug] [ThreadPool]: SQL status: COMMIT in 0.003 seconds
[0m22:09:49.669364 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_raw: Close
[0m22:09:49.673728 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev'
[0m22:09:49.679249 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:09:49.679814 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m22:09:49.680336 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:09:49.688075 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m22:09:49.689085 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:09:49.689085 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m22:09:49.693083 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m22:09:49.694166 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m22:09:49.695080 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m22:09:49.696586 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_raw)
[0m22:09:49.699888 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:09:49.700481 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m22:09:49.701222 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:09:49.708820 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m22:09:49.709369 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:09:49.709976 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m22:09:49.713032 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m22:09:49.715014 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m22:09:49.716590 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m22:09:49.720922 [debug] [MainThread]: Using postgres connection "master"
[0m22:09:49.721974 [debug] [MainThread]: On master: BEGIN
[0m22:09:49.722511 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:09:49.753218 [debug] [MainThread]: SQL status: BEGIN in 0.030 seconds
[0m22:09:49.753218 [debug] [MainThread]: Using postgres connection "master"
[0m22:09:49.754232 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:09:49.776787 [debug] [MainThread]: SQL status: SELECT 37 in 0.024 seconds
[0m22:09:49.776787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eea2a9f5-b320-48f2-98cc-290da8ab93df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231A2189D30>]}
[0m22:09:49.776787 [debug] [MainThread]: On master: ROLLBACK
[0m22:09:49.776787 [debug] [MainThread]: Using postgres connection "master"
[0m22:09:49.776787 [debug] [MainThread]: On master: BEGIN
[0m22:09:49.786939 [debug] [MainThread]: SQL status: BEGIN in 0.003 seconds
[0m22:09:49.787948 [debug] [MainThread]: On master: COMMIT
[0m22:09:49.788946 [debug] [MainThread]: Using postgres connection "master"
[0m22:09:49.788946 [debug] [MainThread]: On master: COMMIT
[0m22:09:49.790945 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:09:49.792050 [debug] [MainThread]: On master: Close
[0m22:09:49.792050 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:09:49.792947 [info ] [MainThread]: 
[0m22:09:49.800088 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m22:09:49.800768 [info ] [Thread-1 (]: 1 of 1 START sql tabke model dbt_dev_raw.payment ............................... [RUN]
[0m22:09:49.801802 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.payment'
[0m22:09:49.802873 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m22:09:49.810069 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m22:09:49.813354 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m22:09:49.840925 [debug] [Thread-1 (]: Compilation Error in model payment (models\raw\payment.sql)
  No materialization 'tabke' was found for adapter postgres! (searched types 'default' and 'postgres')
[0m22:09:49.841926 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eea2a9f5-b320-48f2-98cc-290da8ab93df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231A23F04A0>]}
[0m22:09:49.842926 [error] [Thread-1 (]: 1 of 1 ERROR creating sql tabke model dbt_dev_raw.payment ...................... [[31mERROR[0m in 0.04s]
[0m22:09:49.844925 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m22:09:49.846957 [debug] [MainThread]: Using postgres connection "master"
[0m22:09:49.847966 [debug] [MainThread]: On master: BEGIN
[0m22:09:49.848975 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:09:49.867889 [debug] [MainThread]: SQL status: BEGIN in 0.020 seconds
[0m22:09:49.868890 [debug] [MainThread]: On master: COMMIT
[0m22:09:49.869906 [debug] [MainThread]: Using postgres connection "master"
[0m22:09:49.870890 [debug] [MainThread]: On master: COMMIT
[0m22:09:49.871892 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:09:49.872890 [debug] [MainThread]: On master: Close
[0m22:09:49.873947 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:09:49.874453 [debug] [MainThread]: Connection 'create_data_warehouse_dbt_dev_raw' was properly closed.
[0m22:09:49.874453 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_raw' was properly closed.
[0m22:09:49.874453 [debug] [MainThread]: Connection 'model.data_warehouse.payment' was properly closed.
[0m22:09:49.874453 [info ] [MainThread]: 
[0m22:09:49.877547 [info ] [MainThread]: Finished running 1 tabke model in 0 hours 0 minutes and 0.32 seconds (0.32s).
[0m22:09:49.879143 [debug] [MainThread]: Command end result
[0m22:09:49.907955 [info ] [MainThread]: 
[0m22:09:49.908952 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:09:49.910065 [info ] [MainThread]: 
[0m22:09:49.911076 [error] [MainThread]:   Compilation Error in model payment (models\raw\payment.sql)
  No materialization 'tabke' was found for adapter postgres! (searched types 'default' and 'postgres')
[0m22:09:49.912080 [info ] [MainThread]: 
[0m22:09:49.913079 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m22:09:49.915071 [debug] [MainThread]: Command `dbt run` failed at 22:09:49.915071 after 4.62 seconds
[0m22:09:49.915071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231A0612720>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231A1F24F20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231A2098440>]}
[0m22:09:49.916588 [debug] [MainThread]: Flushing usage events
[0m22:10:24.502558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002593EC94620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002593E3CA930>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002593DD70890>]}


============================== 22:10:24.506605 | 52475c72-c5d5-4a3f-bcc5-52233184f806 ==============================
[0m22:10:24.506605 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:10:24.507803 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s payment', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:10:24.700302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '52475c72-c5d5-4a3f-bcc5-52233184f806', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002593E8ECCE0>]}
[0m22:10:24.763404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '52475c72-c5d5-4a3f-bcc5-52233184f806', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002593F0997C0>]}
[0m22:10:24.765412 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:10:24.774442 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:10:24.933519 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m22:10:24.933519 [debug] [MainThread]: Partial parsing: updated file: data_warehouse://models\raw\sources.yml
[0m22:10:24.934518 [debug] [MainThread]: Partial parsing: updated file: data_warehouse://models\raw\payment.sql
[0m22:10:25.381108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '52475c72-c5d5-4a3f-bcc5-52233184f806', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259405CB470>]}
[0m22:10:25.475246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '52475c72-c5d5-4a3f-bcc5-52233184f806', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002593F1F3110>]}
[0m22:10:25.475246 [info ] [MainThread]: Found 3 models, 4 data tests, 9 sources, 417 macros
[0m22:10:25.475246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '52475c72-c5d5-4a3f-bcc5-52233184f806', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259405A5670>]}
[0m22:10:25.475246 [info ] [MainThread]: 
[0m22:10:25.490948 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:10:25.492955 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m22:10:25.549244 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:10:25.550220 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:10:25.551142 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:10:25.562966 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.013 seconds
[0m22:10:25.564970 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:10:25.569644 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev'
[0m22:10:25.575908 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:10:25.576441 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m22:10:25.576975 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:10:25.579635 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m22:10:25.579635 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:10:25.579635 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m22:10:25.579635 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m22:10:25.579635 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m22:10:25.592704 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m22:10:25.593704 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_raw)
[0m22:10:25.597398 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:10:25.597949 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m22:10:25.598498 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:10:25.606340 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m22:10:25.606882 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:10:25.607448 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m22:10:25.610653 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m22:10:25.612253 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m22:10:25.613852 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m22:10:25.618747 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:25.619927 [debug] [MainThread]: On master: BEGIN
[0m22:10:25.620434 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:10:25.627513 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m22:10:25.628062 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:25.628062 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:10:25.653428 [debug] [MainThread]: SQL status: SELECT 37 in 0.024 seconds
[0m22:10:25.654434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '52475c72-c5d5-4a3f-bcc5-52233184f806', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025940254050>]}
[0m22:10:25.655434 [debug] [MainThread]: On master: ROLLBACK
[0m22:10:25.658526 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:25.658526 [debug] [MainThread]: On master: BEGIN
[0m22:10:25.661557 [debug] [MainThread]: SQL status: BEGIN in 0.003 seconds
[0m22:10:25.662525 [debug] [MainThread]: On master: COMMIT
[0m22:10:25.662525 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:25.663539 [debug] [MainThread]: On master: COMMIT
[0m22:10:25.665548 [debug] [MainThread]: SQL status: COMMIT in 0.002 seconds
[0m22:10:25.665548 [debug] [MainThread]: On master: Close
[0m22:10:25.666547 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:10:25.668550 [info ] [MainThread]: 
[0m22:10:25.673332 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m22:10:25.674179 [info ] [Thread-1 (]: 1 of 1 START sql tabke model dbt_dev_raw.payment ............................... [RUN]
[0m22:10:25.675776 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.payment'
[0m22:10:25.676996 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m22:10:25.682003 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m22:10:25.682003 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m22:10:25.682003 [debug] [Thread-1 (]: Compilation Error in model payment (models\raw\payment.sql)
  No materialization 'tabke' was found for adapter postgres! (searched types 'default' and 'postgres')
[0m22:10:25.682003 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '52475c72-c5d5-4a3f-bcc5-52233184f806', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002593E4D7560>]}
[0m22:10:25.692235 [error] [Thread-1 (]: 1 of 1 ERROR creating sql tabke model dbt_dev_raw.payment ...................... [[31mERROR[0m in 0.01s]
[0m22:10:25.694270 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m22:10:25.696215 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:25.696215 [debug] [MainThread]: On master: BEGIN
[0m22:10:25.697311 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:10:25.728942 [debug] [MainThread]: SQL status: BEGIN in 0.031 seconds
[0m22:10:25.728942 [debug] [MainThread]: On master: COMMIT
[0m22:10:25.729948 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:25.729948 [debug] [MainThread]: On master: COMMIT
[0m22:10:25.731938 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:10:25.732955 [debug] [MainThread]: On master: Close
[0m22:10:25.732955 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:10:25.734267 [debug] [MainThread]: Connection 'list_data_warehouse' was properly closed.
[0m22:10:25.734267 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_raw' was properly closed.
[0m22:10:25.735281 [debug] [MainThread]: Connection 'model.data_warehouse.payment' was properly closed.
[0m22:10:25.735281 [info ] [MainThread]: 
[0m22:10:25.736273 [info ] [MainThread]: Finished running 1 tabke model in 0 hours 0 minutes and 0.24 seconds (0.24s).
[0m22:10:25.738261 [debug] [MainThread]: Command end result
[0m22:10:25.764278 [info ] [MainThread]: 
[0m22:10:25.765277 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:10:25.767286 [info ] [MainThread]: 
[0m22:10:25.768259 [error] [MainThread]:   Compilation Error in model payment (models\raw\payment.sql)
  No materialization 'tabke' was found for adapter postgres! (searched types 'default' and 'postgres')
[0m22:10:25.769263 [info ] [MainThread]: 
[0m22:10:25.770270 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m22:10:25.772263 [debug] [MainThread]: Command `dbt run` failed at 22:10:25.772263 after 1.37 seconds
[0m22:10:25.772263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002593ECE5730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002593EA31B80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002593E4D7950>]}
[0m22:10:25.773431 [debug] [MainThread]: Flushing usage events
[0m22:10:45.366700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BE93DF0170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BE93167710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BE93167890>]}


============================== 22:10:45.371230 | 2f0859e5-5793-4204-bdfa-a1a2006c12ef ==============================
[0m22:10:45.371230 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:10:45.372238 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s payment', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:10:45.577537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2f0859e5-5793-4204-bdfa-a1a2006c12ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BE93CD85F0>]}
[0m22:10:45.641874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2f0859e5-5793-4204-bdfa-a1a2006c12ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BE935072C0>]}
[0m22:10:45.643498 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:10:45.652024 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:10:45.796182 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:10:45.797205 [debug] [MainThread]: Partial parsing: updated file: data_warehouse://models\raw\payment.sql
[0m22:10:46.065320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2f0859e5-5793-4204-bdfa-a1a2006c12ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BE95763E60>]}
[0m22:10:46.176741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2f0859e5-5793-4204-bdfa-a1a2006c12ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BE955DB4D0>]}
[0m22:10:46.177818 [info ] [MainThread]: Found 3 models, 4 data tests, 9 sources, 417 macros
[0m22:10:46.178861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2f0859e5-5793-4204-bdfa-a1a2006c12ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BE9575F260>]}
[0m22:10:46.181775 [info ] [MainThread]: 
[0m22:10:46.183365 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:10:46.184371 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m22:10:46.240805 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:10:46.240805 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:10:46.246924 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:10:46.259819 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.013 seconds
[0m22:10:46.261855 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:10:46.267829 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev'
[0m22:10:46.272724 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:10:46.273846 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m22:10:46.274401 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:10:46.297519 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m22:10:46.298543 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:10:46.298543 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m22:10:46.302832 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m22:10:46.303852 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m22:10:46.305834 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m22:10:46.306833 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_raw)
[0m22:10:46.309843 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:10:46.310367 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m22:10:46.310907 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:10:46.318914 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m22:10:46.319457 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:10:46.320007 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m22:10:46.323534 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m22:10:46.324560 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m22:10:46.326533 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m22:10:46.332110 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:46.332648 [debug] [MainThread]: On master: BEGIN
[0m22:10:46.333171 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:10:46.340042 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m22:10:46.340605 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:46.341139 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:10:46.367433 [debug] [MainThread]: SQL status: SELECT 37 in 0.026 seconds
[0m22:10:46.369440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2f0859e5-5793-4204-bdfa-a1a2006c12ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BE95759BB0>]}
[0m22:10:46.369440 [debug] [MainThread]: On master: ROLLBACK
[0m22:10:46.371953 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:46.371953 [debug] [MainThread]: On master: BEGIN
[0m22:10:46.375167 [debug] [MainThread]: SQL status: BEGIN in 0.003 seconds
[0m22:10:46.376181 [debug] [MainThread]: On master: COMMIT
[0m22:10:46.376181 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:46.377186 [debug] [MainThread]: On master: COMMIT
[0m22:10:46.379177 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:10:46.380023 [debug] [MainThread]: On master: Close
[0m22:10:46.381495 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:10:46.382076 [info ] [MainThread]: 
[0m22:10:46.387013 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m22:10:46.388134 [info ] [Thread-1 (]: 1 of 1 START sql table model dbt_dev_raw.payment ............................... [RUN]
[0m22:10:46.389175 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.payment'
[0m22:10:46.389716 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m22:10:46.398698 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m22:10:46.400707 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m22:10:46.440672 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m22:10:46.445025 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:10:46.446107 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m22:10:46.448017 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:10:46.458787 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m22:10:46.458787 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:10:46.459794 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."payment"
  );
  
[0m22:10:46.470802 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.010 seconds
[0m22:10:46.476700 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:10:46.477702 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m22:10:46.479558 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:10:46.501622 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m22:10:46.502649 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:10:46.503755 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m22:10:46.510761 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:10:46.517336 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m22:10:46.522866 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:10:46.523857 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m22:10:46.525797 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m22:10:46.527842 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m22:10:46.530792 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2f0859e5-5793-4204-bdfa-a1a2006c12ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BE91B4C080>]}
[0m22:10:46.532578 [info ] [Thread-1 (]: 1 of 1 OK created sql table model dbt_dev_raw.payment .......................... [[32mSELECT 14596[0m in 0.14s]
[0m22:10:46.534322 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m22:10:46.536520 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:46.536520 [debug] [MainThread]: On master: BEGIN
[0m22:10:46.537144 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:10:46.545139 [debug] [MainThread]: SQL status: BEGIN in 0.008 seconds
[0m22:10:46.545139 [debug] [MainThread]: On master: COMMIT
[0m22:10:46.546144 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:46.546144 [debug] [MainThread]: On master: COMMIT
[0m22:10:46.549147 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:10:46.549147 [debug] [MainThread]: On master: Close
[0m22:10:46.550653 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:10:46.551660 [debug] [MainThread]: Connection 'list_data_warehouse' was properly closed.
[0m22:10:46.552660 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_raw' was properly closed.
[0m22:10:46.552660 [debug] [MainThread]: Connection 'model.data_warehouse.payment' was properly closed.
[0m22:10:46.554809 [info ] [MainThread]: 
[0m22:10:46.555869 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.37 seconds (0.37s).
[0m22:10:46.557468 [debug] [MainThread]: Command end result
[0m22:10:46.586161 [info ] [MainThread]: 
[0m22:10:46.587152 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:10:46.588152 [info ] [MainThread]: 
[0m22:10:46.589160 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:10:46.590669 [debug] [MainThread]: Command `dbt run` succeeded at 22:10:46.590669 after 1.33 seconds
[0m22:10:46.591676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BE955D3D10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BE94130BF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BE93650EC0>]}
[0m22:10:46.592676 [debug] [MainThread]: Flushing usage events
[0m22:13:42.521558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1DFA7380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1E0FD010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1E0FD400>]}


============================== 22:13:42.525780 | 922edb23-46a2-4f57-b5dc-7f45d9550f62 ==============================
[0m22:13:42.525780 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:13:42.527701 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse', 'log_path': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:13:42.724153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1D16BBC0>]}
[0m22:13:42.786992 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1E126450>]}
[0m22:13:42.788995 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:13:42.797359 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:13:42.987253 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 8 files added, 0 files changed.
[0m22:13:42.987253 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\raw\actor.sql
[0m22:13:42.988248 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\raw\address.sql
[0m22:13:42.989248 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\raw\film.sql
[0m22:13:42.989248 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\raw\inventory.sql
[0m22:13:42.990753 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\raw\staff.sql
[0m22:13:42.990753 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\raw\rental.sql
[0m22:13:42.991773 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\raw\film_actor.sql
[0m22:13:42.992759 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\raw\customer.sql
[0m22:13:43.261293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1F73FF20>]}
[0m22:13:43.366224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1F7106B0>]}
[0m22:13:43.367223 [info ] [MainThread]: Found 11 models, 4 data tests, 9 sources, 417 macros
[0m22:13:43.368730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1F763500>]}
[0m22:13:43.372264 [info ] [MainThread]: 
[0m22:13:43.373262 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:13:43.375122 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m22:13:43.440833 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:13:43.441457 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:13:43.441457 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:13:43.456655 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.014 seconds
[0m22:13:43.457657 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:13:43.463013 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:13:43.463557 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:13:43.464086 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:13:43.479890 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.016 seconds
[0m22:13:43.481449 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:13:43.483469 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse, now create_data_warehouse_dbt_dev)
[0m22:13:43.484475 [debug] [ThreadPool]: Creating schema "database: "data_warehouse"
schema: "dbt_dev"
"
[0m22:13:43.489796 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev"
[0m22:13:43.490365 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev: BEGIN
[0m22:13:43.490904 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:13:43.498361 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m22:13:43.499383 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev"
[0m22:13:43.499383 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "create_data_warehouse_dbt_dev"} */
create schema if not exists "dbt_dev"
[0m22:13:43.501905 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.002 seconds
[0m22:13:43.502898 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev: COMMIT
[0m22:13:43.503919 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev"
[0m22:13:43.504901 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev: COMMIT
[0m22:13:43.507747 [debug] [ThreadPool]: SQL status: COMMIT in 0.003 seconds
[0m22:13:43.507747 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev: Close
[0m22:13:43.511274 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev'
[0m22:13:43.516717 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:13:43.517778 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m22:13:43.518324 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:13:43.538199 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m22:13:43.538199 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:13:43.539303 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m22:13:43.542813 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m22:13:43.543815 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m22:13:43.545816 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m22:13:43.545816 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_raw)
[0m22:13:43.549186 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:13:43.549186 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m22:13:43.550245 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:13:43.566741 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m22:13:43.567741 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:13:43.567741 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m22:13:43.572277 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m22:13:43.573364 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m22:13:43.573364 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m22:13:43.581114 [debug] [MainThread]: Using postgres connection "master"
[0m22:13:43.582152 [debug] [MainThread]: On master: BEGIN
[0m22:13:43.583018 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:13:43.605058 [debug] [MainThread]: SQL status: BEGIN in 0.023 seconds
[0m22:13:43.606058 [debug] [MainThread]: Using postgres connection "master"
[0m22:13:43.607062 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:13:43.632989 [debug] [MainThread]: SQL status: SELECT 37 in 0.026 seconds
[0m22:13:43.634995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1BCA4AA0>]}
[0m22:13:43.635995 [debug] [MainThread]: On master: ROLLBACK
[0m22:13:43.638887 [debug] [MainThread]: Using postgres connection "master"
[0m22:13:43.638887 [debug] [MainThread]: On master: BEGIN
[0m22:13:43.642422 [debug] [MainThread]: SQL status: BEGIN in 0.003 seconds
[0m22:13:43.642422 [debug] [MainThread]: On master: COMMIT
[0m22:13:43.643418 [debug] [MainThread]: Using postgres connection "master"
[0m22:13:43.643418 [debug] [MainThread]: On master: COMMIT
[0m22:13:43.645419 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:13:43.646421 [debug] [MainThread]: On master: Close
[0m22:13:43.647422 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:13:43.648417 [info ] [MainThread]: 
[0m22:13:43.652782 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m22:13:43.653407 [info ] [Thread-1 (]: 1 of 11 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m22:13:43.654612 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m22:13:43.655213 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m22:13:43.662218 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m22:13:43.664224 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m22:13:43.701780 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m22:13:43.703781 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:13:43.703781 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m22:13:43.704809 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:13:43.735128 [debug] [Thread-1 (]: SQL status: BEGIN in 0.030 seconds
[0m22:13:43.735128 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:13:43.736201 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."actor"
  );
  
[0m22:13:43.739121 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m22:13:43.744285 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:13:43.745311 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m22:13:43.747292 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:13:43.763654 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m22:13:43.764654 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:13:43.765659 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m22:13:43.770136 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:13:43.775655 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m22:13:43.781169 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:13:43.781169 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m22:13:43.783973 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m22:13:43.785967 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m22:13:43.788977 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1BB0FEF0>]}
[0m22:13:43.788977 [info ] [Thread-1 (]: 1 of 11 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.13s]
[0m22:13:43.791616 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m22:13:43.792124 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m22:13:43.793294 [info ] [Thread-1 (]: 2 of 11 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m22:13:43.794322 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m22:13:43.794859 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m22:13:43.799889 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m22:13:43.802057 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m22:13:43.807070 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m22:13:43.808581 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:13:43.809591 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m22:13:43.810622 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:13:43.820805 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:13:43.821811 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:13:43.821811 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."address"
  );
  
[0m22:13:43.826339 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.003 seconds
[0m22:13:43.829345 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:13:43.829345 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m22:13:43.832861 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:13:43.833864 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m22:13:43.835862 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:13:43.835862 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m22:13:43.839886 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:13:43.842373 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m22:13:43.844049 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:13:43.844678 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m22:13:43.846261 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m22:13:43.847831 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m22:13:43.849405 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1FD89D00>]}
[0m22:13:43.850473 [info ] [Thread-1 (]: 2 of 11 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.06s]
[0m22:13:43.852708 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m22:13:43.853773 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m22:13:43.854868 [info ] [Thread-1 (]: 3 of 11 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m22:13:43.855395 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m22:13:43.855931 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m22:13:43.859108 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m22:13:43.861272 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m22:13:43.865390 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m22:13:43.866397 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:13:43.868392 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m22:13:43.869391 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:13:43.888054 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m22:13:43.889054 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:13:43.889054 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."customer"
  );
  
[0m22:13:43.892570 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.003 seconds
[0m22:13:43.895119 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:13:43.896129 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m22:13:43.898424 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:13:43.900696 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m22:13:43.901753 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:13:43.902704 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m22:13:43.907748 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:13:43.909834 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m22:13:43.911249 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:13:43.911249 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m22:13:43.913256 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m22:13:43.915275 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m22:13:43.916656 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1FCDAB40>]}
[0m22:13:43.917666 [info ] [Thread-1 (]: 3 of 11 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.06s]
[0m22:13:43.919603 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m22:13:43.920742 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m22:13:43.921850 [info ] [Thread-1 (]: 4 of 11 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m22:13:43.922884 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m22:13:43.923431 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m22:13:43.926531 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m22:13:43.928331 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m22:13:43.933581 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m22:13:43.936536 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:13:43.937532 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m22:13:43.937532 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:13:43.965550 [debug] [Thread-1 (]: SQL status: BEGIN in 0.027 seconds
[0m22:13:43.966553 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:13:43.967554 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."film"
  );
  
[0m22:13:43.974685 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.007 seconds
[0m22:13:43.977708 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:13:43.977708 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m22:13:43.979690 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:13:43.981238 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m22:13:43.982580 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:13:43.983582 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m22:13:43.991002 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:13:43.994031 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m22:13:43.995013 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:13:43.995013 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m22:13:43.997317 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m22:13:43.998917 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m22:13:44.000929 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1FDEAE10>]}
[0m22:13:44.001435 [info ] [Thread-1 (]: 4 of 11 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.08s]
[0m22:13:44.003310 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m22:13:44.004341 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m22:13:44.004886 [info ] [Thread-1 (]: 5 of 11 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m22:13:44.005958 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m22:13:44.006482 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m22:13:44.009674 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m22:13:44.011285 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m22:13:44.015675 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m22:13:44.016648 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:13:44.017996 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m22:13:44.019029 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:13:44.048875 [debug] [Thread-1 (]: SQL status: BEGIN in 0.030 seconds
[0m22:13:44.050707 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:13:44.050707 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m22:13:44.056696 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.005 seconds
[0m22:13:44.060803 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:13:44.060901 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m22:13:44.063810 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:13:44.065808 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m22:13:44.066813 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:13:44.067810 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m22:13:44.074423 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:13:44.076429 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m22:13:44.078421 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:13:44.078421 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m22:13:44.080943 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m22:13:44.082486 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m22:13:44.085075 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1FC44800>]}
[0m22:13:44.086136 [info ] [Thread-1 (]: 5 of 11 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.08s]
[0m22:13:44.087737 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m22:13:44.088829 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m22:13:44.089360 [info ] [Thread-1 (]: 6 of 11 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m22:13:44.090418 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m22:13:44.091478 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m22:13:44.094404 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m22:13:44.096267 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m22:13:44.103636 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m22:13:44.105642 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:13:44.106642 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m22:13:44.106642 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:13:44.138761 [debug] [Thread-1 (]: SQL status: BEGIN in 0.031 seconds
[0m22:13:44.138761 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:13:44.139702 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m22:13:44.145264 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m22:13:44.147989 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:13:44.148522 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m22:13:44.151043 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:13:44.153407 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m22:13:44.153407 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:13:44.154412 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m22:13:44.162686 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m22:13:44.165683 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m22:13:44.167683 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:13:44.168684 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m22:13:44.170686 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m22:13:44.171791 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m22:13:44.173799 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1F7E1FD0>]}
[0m22:13:44.173910 [info ] [Thread-1 (]: 6 of 11 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.08s]
[0m22:13:44.176101 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m22:13:44.176609 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m22:13:44.177686 [info ] [Thread-1 (]: 7 of 11 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m22:13:44.178205 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m22:13:44.178727 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m22:13:44.182386 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m22:13:44.185170 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m22:13:44.189489 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m22:13:44.191001 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:13:44.192010 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m22:13:44.193016 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:13:44.203039 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m22:13:44.204038 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:13:44.204038 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m22:13:44.207039 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.002 seconds
[0m22:13:44.211131 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:13:44.211131 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m22:13:44.214198 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:13:44.216135 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m22:13:44.217141 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:13:44.218141 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m22:13:44.223528 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:13:44.226367 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m22:13:44.228277 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:13:44.228277 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m22:13:44.230837 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m22:13:44.231855 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m22:13:44.234278 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1FE2FEF0>]}
[0m22:13:44.235281 [info ] [Thread-1 (]: 7 of 11 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.06s]
[0m22:13:44.236974 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m22:13:44.237550 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m22:13:44.238072 [info ] [Thread-1 (]: 8 of 11 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m22:13:44.239096 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m22:13:44.239096 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m22:13:44.243735 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m22:13:44.244691 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m22:13:44.249794 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m22:13:44.250807 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:13:44.253243 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m22:13:44.254254 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:13:44.263770 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:13:44.264771 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:13:44.264771 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."payment"
  );
  
[0m22:13:44.276622 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.010 seconds
[0m22:13:44.279647 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:13:44.279647 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m22:13:44.282160 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:13:44.285697 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:13:44.286786 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m22:13:44.288650 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:13:44.293178 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m22:13:44.293178 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:13:44.294277 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m22:13:44.306118 [debug] [Thread-1 (]: SQL status: COMMIT in 0.011 seconds
[0m22:13:44.308140 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m22:13:44.309249 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:13:44.309249 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m22:13:44.314783 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:13:44.316778 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m22:13:44.318792 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1F763FB0>]}
[0m22:13:44.319783 [info ] [Thread-1 (]: 8 of 11 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.08s]
[0m22:13:44.320775 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m22:13:44.322217 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m22:13:44.322780 [info ] [Thread-1 (]: 9 of 11 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m22:13:44.323785 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m22:13:44.325093 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m22:13:44.327099 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m22:13:44.329106 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m22:13:44.334731 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m22:13:44.335725 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:13:44.336738 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m22:13:44.337755 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:13:44.346766 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m22:13:44.347889 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:13:44.347889 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."rental"
  );
  
[0m22:13:44.358444 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.010 seconds
[0m22:13:44.361175 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:13:44.362180 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m22:13:44.364216 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:13:44.366185 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m22:13:44.367181 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:13:44.368182 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m22:13:44.378151 [debug] [Thread-1 (]: SQL status: COMMIT in 0.009 seconds
[0m22:13:44.380768 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m22:13:44.381783 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:13:44.383047 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m22:13:44.385058 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m22:13:44.387157 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m22:13:44.388075 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1FCD8BC0>]}
[0m22:13:44.389060 [info ] [Thread-1 (]: 9 of 11 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.06s]
[0m22:13:44.390568 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m22:13:44.391764 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m22:13:44.392271 [info ] [Thread-1 (]: 10 of 11 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m22:13:44.393383 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m22:13:44.394492 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m22:13:44.397381 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m22:13:44.399347 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m22:13:44.406966 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m22:13:44.408799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:13:44.408799 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m22:13:44.409810 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:13:44.439198 [debug] [Thread-1 (]: SQL status: BEGIN in 0.030 seconds
[0m22:13:44.440965 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:13:44.441833 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."staff"
  );
  
[0m22:13:44.448818 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.007 seconds
[0m22:13:44.496586 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:13:44.497586 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m22:13:44.499998 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:13:44.504034 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m22:13:44.504034 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:13:44.505035 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m22:13:44.508643 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:13:44.511329 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m22:13:44.512347 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:13:44.513348 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m22:13:44.515339 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m22:13:44.517335 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m22:13:44.519629 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE202C4E30>]}
[0m22:13:44.519629 [info ] [Thread-1 (]: 10 of 11 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.13s]
[0m22:13:44.521648 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m22:13:44.522818 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m22:13:44.523960 [info ] [Thread-1 (]: 11 of 11 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m22:13:44.525857 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.my_second_dbt_model)
[0m22:13:44.526691 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m22:13:44.530211 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m22:13:44.531946 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m22:13:44.550688 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m22:13:44.553300 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:13:44.554310 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m22:13:44.555376 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:13:44.564424 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m22:13:44.565422 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:13:44.565422 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m22:13:44.569416 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m22:13:44.571976 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:13:44.573010 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m22:13:44.574977 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:13:44.576982 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m22:13:44.576982 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:13:44.578246 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m22:13:44.583213 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:13:44.586204 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m22:13:44.589204 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:13:44.589204 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m22:13:44.591734 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.002 seconds
[0m22:13:44.592815 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m22:13:44.593815 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '922edb23-46a2-4f57-b5dc-7f45d9550f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1E30D640>]}
[0m22:13:44.595818 [info ] [Thread-1 (]: 11 of 11 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.07s]
[0m22:13:44.597116 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m22:13:44.599402 [debug] [MainThread]: Using postgres connection "master"
[0m22:13:44.599937 [debug] [MainThread]: On master: BEGIN
[0m22:13:44.601001 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:13:44.619642 [debug] [MainThread]: SQL status: BEGIN in 0.019 seconds
[0m22:13:44.619642 [debug] [MainThread]: On master: COMMIT
[0m22:13:44.620809 [debug] [MainThread]: Using postgres connection "master"
[0m22:13:44.621685 [debug] [MainThread]: On master: COMMIT
[0m22:13:44.624683 [debug] [MainThread]: SQL status: COMMIT in 0.002 seconds
[0m22:13:44.624683 [debug] [MainThread]: On master: Close
[0m22:13:44.625692 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:13:44.626683 [debug] [MainThread]: Connection 'create_data_warehouse_dbt_dev' was properly closed.
[0m22:13:44.626683 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_raw' was properly closed.
[0m22:13:44.627708 [debug] [MainThread]: Connection 'model.data_warehouse.my_second_dbt_model' was properly closed.
[0m22:13:44.628789 [info ] [MainThread]: 
[0m22:13:44.630082 [info ] [MainThread]: Finished running 10 table models, 1 view model in 0 hours 0 minutes and 1.26 seconds (1.26s).
[0m22:13:44.633433 [debug] [MainThread]: Command end result
[0m22:13:44.662454 [info ] [MainThread]: 
[0m22:13:44.663451 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:13:44.664454 [info ] [MainThread]: 
[0m22:13:44.666456 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=0 SKIP=0 TOTAL=11
[0m22:13:44.668463 [debug] [MainThread]: Command `dbt run` succeeded at 22:13:44.668463 after 2.26 seconds
[0m22:13:44.669457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1D0EFEF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1DCF8800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE1DCF8B60>]}
[0m22:13:44.669457 [debug] [MainThread]: Flushing usage events
[0m22:20:28.708301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63CD05DF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63D4A5CA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63D4A7650>]}


============================== 22:20:28.712323 | d2738c8f-2ad8-4c1a-a7b9-c81692f3686e ==============================
[0m22:20:28.712323 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:20:28.713101 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:20:28.903698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63D4A4680>]}
[0m22:20:28.965226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63D9005C0>]}
[0m22:20:28.967236 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:20:28.974351 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:20:29.144765 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 9 files added, 0 files changed.
[0m22:20:29.145767 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediate\dim_film_actor.sql
[0m22:20:29.145767 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediate\dim_actor.sql
[0m22:20:29.146772 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediate\dim_film.sql
[0m22:20:29.147778 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediate\dim_address.sql
[0m22:20:29.148767 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediate\dim_rental.sql
[0m22:20:29.149775 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediate\dim_customer.sql
[0m22:20:29.150782 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediate\dim_staff.sql
[0m22:20:29.150782 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediate\dim_inventory.sql
[0m22:20:29.151783 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\intermediate\fact_payment.sql
[0m22:20:29.409111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63EC68920>]}
[0m22:20:29.527358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63EC1A150>]}
[0m22:20:29.528375 [info ] [MainThread]: Found 20 models, 4 data tests, 9 sources, 417 macros
[0m22:20:29.529353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63D9301D0>]}
[0m22:20:29.531394 [info ] [MainThread]: 
[0m22:20:29.533358 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:20:29.538999 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m22:20:29.596951 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:20:29.596951 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:20:29.597878 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:20:29.612764 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.014 seconds
[0m22:20:29.613788 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:20:29.616947 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:20:29.617950 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:20:29.618477 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:20:29.647505 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.029 seconds
[0m22:20:29.648531 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:20:29.652840 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:20:29.653363 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:20:29.653899 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:20:29.675791 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.022 seconds
[0m22:20:29.677808 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:20:29.678796 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse, now create_data_warehouse_dbt_dev_intermediate)
[0m22:20:29.679792 [debug] [ThreadPool]: Creating schema "database: "data_warehouse"
schema: "dbt_dev_intermediate"
"
[0m22:20:29.685846 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_intermediate"
[0m22:20:29.686349 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_intermediate: BEGIN
[0m22:20:29.686951 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:20:29.707486 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m22:20:29.707486 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_intermediate"
[0m22:20:29.708493 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_intermediate: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "create_data_warehouse_dbt_dev_intermediate"} */
create schema if not exists "dbt_dev_intermediate"
[0m22:20:29.710486 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m22:20:29.711492 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_intermediate: COMMIT
[0m22:20:29.711492 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_intermediate"
[0m22:20:29.712492 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_intermediate: COMMIT
[0m22:20:29.717494 [debug] [ThreadPool]: SQL status: COMMIT in 0.005 seconds
[0m22:20:29.718496 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_intermediate: Close
[0m22:20:29.721761 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev'
[0m22:20:29.727463 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:20:29.728593 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m22:20:29.729160 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:20:29.751976 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m22:20:29.752969 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:20:29.753983 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m22:20:29.759329 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m22:20:29.760331 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m22:20:29.762330 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m22:20:29.763330 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_intermediate)
[0m22:20:29.767478 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m22:20:29.768560 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: BEGIN
[0m22:20:29.769103 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:20:29.777159 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m22:20:29.777692 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m22:20:29.778248 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediate"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediate'
  
[0m22:20:29.781711 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m22:20:29.783686 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: ROLLBACK
[0m22:20:29.785473 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: Close
[0m22:20:29.786474 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediate, now list_data_warehouse_dbt_dev_raw)
[0m22:20:29.789107 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:20:29.789632 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m22:20:29.790202 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:20:29.808093 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m22:20:29.808093 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:20:29.809113 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m22:20:29.813093 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:20:29.814111 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m22:20:29.815119 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m22:20:29.822867 [debug] [MainThread]: Using postgres connection "master"
[0m22:20:29.823436 [debug] [MainThread]: On master: BEGIN
[0m22:20:29.823984 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:20:29.830849 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m22:20:29.831371 [debug] [MainThread]: Using postgres connection "master"
[0m22:20:29.832441 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:20:29.868575 [debug] [MainThread]: SQL status: SELECT 38 in 0.036 seconds
[0m22:20:29.870275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63ECC14F0>]}
[0m22:20:29.871262 [debug] [MainThread]: On master: ROLLBACK
[0m22:20:29.874213 [debug] [MainThread]: Using postgres connection "master"
[0m22:20:29.874213 [debug] [MainThread]: On master: BEGIN
[0m22:20:29.877318 [debug] [MainThread]: SQL status: BEGIN in 0.003 seconds
[0m22:20:29.877318 [debug] [MainThread]: On master: COMMIT
[0m22:20:29.878395 [debug] [MainThread]: Using postgres connection "master"
[0m22:20:29.879322 [debug] [MainThread]: On master: COMMIT
[0m22:20:29.880323 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:20:29.881314 [debug] [MainThread]: On master: Close
[0m22:20:29.882310 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:20:29.883304 [info ] [MainThread]: 
[0m22:20:29.888668 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m22:20:29.889642 [info ] [Thread-1 (]: 1 of 20 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m22:20:29.890365 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m22:20:29.891497 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m22:20:29.899815 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m22:20:29.901807 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m22:20:29.938630 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m22:20:29.940546 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:20:29.941534 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m22:20:29.942538 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:20:29.968833 [debug] [Thread-1 (]: SQL status: BEGIN in 0.026 seconds
[0m22:20:29.968833 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:20:29.969838 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."actor"
  );
  
[0m22:20:29.972304 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m22:20:29.979311 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:20:29.980309 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m22:20:29.982334 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:29.985336 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:20:29.986320 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m22:20:29.988880 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:20:30.006973 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m22:20:30.007981 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:20:30.008889 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m22:20:30.013016 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:20:30.019022 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m22:20:30.024695 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:20:30.025251 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m22:20:30.031303 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:20:30.034514 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m22:20:30.038966 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63B013EC0>]}
[0m22:20:30.040123 [info ] [Thread-1 (]: 1 of 20 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.15s]
[0m22:20:30.042902 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m22:20:30.045103 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m22:20:30.046592 [info ] [Thread-1 (]: 2 of 20 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m22:20:30.048611 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m22:20:30.050611 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m22:20:30.054638 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m22:20:30.056245 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m22:20:30.062682 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m22:20:30.063775 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:20:30.065682 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m22:20:30.065682 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:30.076547 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:20:30.076547 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:20:30.077617 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."address"
  );
  
[0m22:20:30.080546 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m22:20:30.083549 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:20:30.084548 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m22:20:30.086547 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:30.089552 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:20:30.089552 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m22:20:30.091548 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:30.093567 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m22:20:30.094552 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:20:30.094552 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m22:20:30.099545 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:20:30.102555 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m22:20:30.104708 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:20:30.105717 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m22:20:30.109347 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:20:30.111475 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m22:20:30.112487 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63ED7DE20>]}
[0m22:20:30.114487 [info ] [Thread-1 (]: 2 of 20 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.06s]
[0m22:20:30.115890 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m22:20:30.116459 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m22:20:30.118079 [info ] [Thread-1 (]: 3 of 20 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m22:20:30.119165 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m22:20:30.120255 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m22:20:30.125458 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m22:20:30.126768 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m22:20:30.131334 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m22:20:30.132331 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:20:30.133334 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m22:20:30.135365 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:30.159035 [debug] [Thread-1 (]: SQL status: BEGIN in 0.024 seconds
[0m22:20:30.160029 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:20:30.160029 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."customer"
  );
  
[0m22:20:30.164029 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.003 seconds
[0m22:20:30.167028 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:20:30.168032 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m22:20:30.171031 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:20:30.174117 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:20:30.175103 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m22:20:30.177028 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:30.178087 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m22:20:30.179122 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:20:30.180066 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m22:20:30.183467 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:20:30.187664 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m22:20:30.188670 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:20:30.189665 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m22:20:30.193677 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m22:20:30.194678 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m22:20:30.195676 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63F363DD0>]}
[0m22:20:30.196669 [info ] [Thread-1 (]: 3 of 20 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.08s]
[0m22:20:30.197660 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m22:20:30.198660 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m22:20:30.200096 [info ] [Thread-1 (]: 4 of 20 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m22:20:30.201749 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m22:20:30.202621 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m22:20:30.206173 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m22:20:30.207318 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m22:20:30.211270 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m22:20:30.213285 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:20:30.214280 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m22:20:30.215283 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:30.224674 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m22:20:30.224674 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:20:30.226180 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."film"
  );
  
[0m22:20:30.235186 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.009 seconds
[0m22:20:30.239186 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:20:30.240190 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m22:20:30.242190 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:30.245191 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:20:30.246190 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m22:20:30.248187 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:30.251522 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m22:20:30.252571 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:20:30.253578 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m22:20:30.260577 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m22:20:30.262577 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m22:20:30.264160 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:20:30.265168 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m22:20:30.271340 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:20:30.272342 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m22:20:30.273340 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63F267B00>]}
[0m22:20:30.274343 [info ] [Thread-1 (]: 4 of 20 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.07s]
[0m22:20:30.276345 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m22:20:30.277139 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m22:20:30.278193 [info ] [Thread-1 (]: 5 of 20 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m22:20:30.278799 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m22:20:30.279856 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m22:20:30.284218 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m22:20:30.285887 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m22:20:30.290710 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m22:20:30.292619 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:20:30.293617 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m22:20:30.294618 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:30.302619 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m22:20:30.302619 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:20:30.303619 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m22:20:30.309757 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.005 seconds
[0m22:20:30.314764 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:20:30.316779 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m22:20:30.318765 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:20:30.322768 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:20:30.323770 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m22:20:30.324773 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:30.328290 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m22:20:30.329292 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:20:30.330295 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m22:20:30.336288 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:20:30.340288 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m22:20:30.342293 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:20:30.342293 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m22:20:30.347085 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m22:20:30.348088 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m22:20:30.350080 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63F2F7EF0>]}
[0m22:20:30.351089 [info ] [Thread-1 (]: 5 of 20 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.07s]
[0m22:20:30.352591 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m22:20:30.353630 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m22:20:30.354170 [info ] [Thread-1 (]: 6 of 20 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m22:20:30.355773 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m22:20:30.356883 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m22:20:30.360099 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m22:20:30.361173 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m22:20:30.364881 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m22:20:30.366856 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:20:30.367858 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m22:20:30.368864 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:30.373299 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m22:20:30.373299 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:20:30.373299 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m22:20:30.383068 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m22:20:30.386521 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:20:30.388501 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m22:20:30.390861 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:30.393881 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:20:30.393881 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m22:20:30.395862 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:30.398074 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m22:20:30.399092 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:20:30.400077 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m22:20:30.405970 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:20:30.407992 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m22:20:30.409980 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:20:30.409980 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m22:20:30.413975 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m22:20:30.415995 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m22:20:30.416979 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63ECCECC0>]}
[0m22:20:30.418341 [info ] [Thread-1 (]: 6 of 20 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.06s]
[0m22:20:30.420806 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m22:20:30.421973 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m22:20:30.422514 [info ] [Thread-1 (]: 7 of 20 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m22:20:30.423638 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m22:20:30.424161 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m22:20:30.426839 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m22:20:30.428470 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m22:20:30.432753 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m22:20:30.434734 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:20:30.435736 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m22:20:30.436739 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:30.455333 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m22:20:30.456415 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:20:30.456415 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m22:20:30.459335 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.002 seconds
[0m22:20:30.462433 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:20:30.462433 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m22:20:30.464335 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:30.468950 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:20:30.469913 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m22:20:30.471916 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:20:30.473918 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m22:20:30.474919 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:20:30.474919 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m22:20:30.479914 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:20:30.526706 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m22:20:30.527715 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:20:30.528748 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m22:20:30.534125 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:20:30.536249 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m22:20:30.537126 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63F3BC740>]}
[0m22:20:30.538133 [info ] [Thread-1 (]: 7 of 20 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.11s]
[0m22:20:30.540138 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m22:20:30.540985 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m22:20:30.541488 [info ] [Thread-1 (]: 8 of 20 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m22:20:30.542667 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m22:20:30.543201 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m22:20:30.548051 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m22:20:30.549190 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m22:20:30.553945 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m22:20:30.555922 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:20:30.555922 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m22:20:30.557001 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:30.566431 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m22:20:30.567436 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:20:30.568430 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."payment"
  );
  
[0m22:20:30.573823 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.008 seconds
[0m22:20:30.573823 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:20:30.573823 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m22:20:30.582651 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:30.586649 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:20:30.587653 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m22:20:30.589845 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:20:30.591934 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m22:20:30.592928 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:20:30.593856 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m22:20:30.602754 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m22:20:30.604807 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m22:20:30.605859 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:20:30.606760 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m22:20:30.611761 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:20:30.613331 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m22:20:30.614336 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63D84DE50>]}
[0m22:20:30.615339 [info ] [Thread-1 (]: 8 of 20 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.07s]
[0m22:20:30.618214 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m22:20:30.618792 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m22:20:30.619824 [info ] [Thread-1 (]: 9 of 20 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m22:20:30.620913 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m22:20:30.621467 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m22:20:30.624740 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m22:20:30.625990 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m22:20:30.630268 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m22:20:30.632270 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:20:30.633486 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m22:20:30.634499 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:30.644849 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:20:30.644849 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:20:30.646198 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."rental"
  );
  
[0m22:20:30.660851 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.013 seconds
[0m22:20:30.665942 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:20:30.666906 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m22:20:30.669908 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:20:30.672906 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:20:30.673919 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m22:20:30.675908 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:20:30.678447 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m22:20:30.679448 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:20:30.680447 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m22:20:30.689456 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m22:20:30.691447 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m22:20:30.693466 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:20:30.694464 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m22:20:30.698452 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:20:30.700702 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m22:20:30.701702 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63F37E1E0>]}
[0m22:20:30.703027 [info ] [Thread-1 (]: 9 of 20 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.08s]
[0m22:20:30.705039 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m22:20:30.706008 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m22:20:30.707177 [info ] [Thread-1 (]: 10 of 20 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m22:20:30.707681 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m22:20:30.708757 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m22:20:30.712559 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m22:20:30.714270 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m22:20:30.718057 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m22:20:30.720057 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:20:30.721439 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m22:20:30.722966 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:30.730033 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m22:20:30.730033 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:20:30.731082 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."staff"
  );
  
[0m22:20:30.737009 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.005 seconds
[0m22:20:30.739999 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:20:30.741026 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m22:20:30.743000 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:30.745997 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:20:30.746997 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m22:20:30.748998 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:20:30.751000 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m22:20:30.751999 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:20:30.753011 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m22:20:30.756001 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m22:20:30.758999 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m22:20:30.760000 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:20:30.760000 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m22:20:30.764373 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m22:20:30.765372 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m22:20:30.766372 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63F1C52B0>]}
[0m22:20:30.767994 [info ] [Thread-1 (]: 10 of 20 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.06s]
[0m22:20:30.769680 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m22:20:30.770801 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m22:20:30.771320 [info ] [Thread-1 (]: 11 of 20 START sql table model dbt_dev_intermediate.dim_actor .................. [RUN]
[0m22:20:30.772384 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m22:20:30.772919 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m22:20:30.776156 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m22:20:30.777743 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m22:20:30.782055 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m22:20:30.785130 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:20:30.785130 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m22:20:30.786517 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:30.796686 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:20:30.797691 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:20:30.797691 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m22:20:30.801689 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m22:20:30.804687 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:20:30.805780 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m22:20:30.807686 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:30.809684 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m22:20:30.809684 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:20:30.810775 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m22:20:30.815695 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:20:30.818693 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup"
[0m22:20:30.819715 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:20:30.820708 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup" cascade
[0m22:20:30.822707 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m22:20:30.824807 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m22:20:30.825696 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63D19E150>]}
[0m22:20:30.827189 [info ] [Thread-1 (]: 11 of 20 OK created sql table model dbt_dev_intermediate.dim_actor ............. [[32mSELECT 200[0m in 0.05s]
[0m22:20:30.829254 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m22:20:30.830310 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m22:20:30.830845 [info ] [Thread-1 (]: 12 of 20 START sql table model dbt_dev_intermediate.dim_address ................ [RUN]
[0m22:20:30.831917 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m22:20:30.832980 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m22:20:30.836710 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m22:20:30.838415 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m22:20:30.843659 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m22:20:30.845568 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:20:30.847566 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m22:20:30.848642 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:30.857216 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m22:20:30.858316 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:20:30.859223 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m22:20:30.863215 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.003 seconds
[0m22:20:30.866213 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:20:30.867214 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp" rename to "dim_address"
[0m22:20:30.870222 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:20:30.871215 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m22:20:30.872326 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:20:30.873213 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m22:20:30.876910 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:20:30.880914 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup"
[0m22:20:30.882917 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:20:30.883921 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup" cascade
[0m22:20:30.886929 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m22:20:30.887921 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m22:20:30.888998 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63F24C0B0>]}
[0m22:20:30.890918 [info ] [Thread-1 (]: 12 of 20 OK created sql table model dbt_dev_intermediate.dim_address ........... [[32mSELECT 603[0m in 0.06s]
[0m22:20:30.892568 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m22:20:30.893714 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m22:20:30.894235 [info ] [Thread-1 (]: 13 of 20 START sql table model dbt_dev_intermediate.dim_customer ............... [RUN]
[0m22:20:30.895826 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m22:20:30.896896 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m22:20:30.901353 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m22:20:30.904080 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m22:20:30.910540 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m22:20:30.913537 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:20:30.914543 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m22:20:30.915543 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:30.942072 [debug] [Thread-1 (]: SQL status: BEGIN in 0.026 seconds
[0m22:20:30.943150 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:20:30.943150 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m22:20:30.946094 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m22:20:30.948584 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:20:30.949590 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m22:20:30.952811 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:20:30.954817 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m22:20:30.955813 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:20:30.955813 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m22:20:30.960363 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:20:30.962365 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup"
[0m22:20:30.963371 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:20:30.964364 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup" cascade
[0m22:20:30.965361 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m22:20:30.967875 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m22:20:30.969875 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63F2420C0>]}
[0m22:20:30.970880 [info ] [Thread-1 (]: 13 of 20 OK created sql table model dbt_dev_intermediate.dim_customer .......... [[32mSELECT 599[0m in 0.07s]
[0m22:20:30.972985 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m22:20:30.973550 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m22:20:30.974657 [info ] [Thread-1 (]: 14 of 20 START sql table model dbt_dev_intermediate.dim_film ................... [RUN]
[0m22:20:30.975747 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m22:20:30.976255 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m22:20:30.979057 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m22:20:30.980744 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m22:20:30.985712 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m22:20:30.988226 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:20:30.989246 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m22:20:30.990230 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:31.021918 [debug] [Thread-1 (]: SQL status: BEGIN in 0.032 seconds
[0m22:20:31.022941 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:20:31.023929 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m22:20:31.033691 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.009 seconds
[0m22:20:31.036990 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:20:31.038072 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp" rename to "dim_film"
[0m22:20:31.040192 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:31.042189 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m22:20:31.044193 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:20:31.045214 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m22:20:31.052164 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m22:20:31.055186 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup"
[0m22:20:31.055186 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:20:31.056691 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup" cascade
[0m22:20:31.058697 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m22:20:31.059717 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m22:20:31.060696 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63F24C0B0>]}
[0m22:20:31.061702 [info ] [Thread-1 (]: 14 of 20 OK created sql table model dbt_dev_intermediate.dim_film .............. [[32mSELECT 1000[0m in 0.09s]
[0m22:20:31.063698 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m22:20:31.064749 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m22:20:31.065311 [info ] [Thread-1 (]: 15 of 20 START sql table model dbt_dev_intermediate.dim_film_actor ............. [RUN]
[0m22:20:31.066489 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m22:20:31.067599 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m22:20:31.071202 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m22:20:31.072430 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m22:20:31.075642 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m22:20:31.077244 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:20:31.079077 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m22:20:31.080084 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:31.089337 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m22:20:31.089337 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:20:31.090449 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m22:20:31.094343 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m22:20:31.098525 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:20:31.099530 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m22:20:31.102796 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:31.104921 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m22:20:31.105447 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:20:31.105991 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m22:20:31.111313 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:20:31.113987 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup"
[0m22:20:31.114993 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:20:31.115983 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup" cascade
[0m22:20:31.118505 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m22:20:31.120514 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m22:20:31.121513 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63ED1FEF0>]}
[0m22:20:31.122866 [info ] [Thread-1 (]: 15 of 20 OK created sql table model dbt_dev_intermediate.dim_film_actor ........ [[32mSELECT 5462[0m in 0.05s]
[0m22:20:31.124932 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m22:20:31.125472 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m22:20:31.126536 [info ] [Thread-1 (]: 16 of 20 START sql table model dbt_dev_intermediate.dim_inventory .............. [RUN]
[0m22:20:31.127574 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m22:20:31.128663 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m22:20:31.132971 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m22:20:31.134589 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m22:20:31.140978 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m22:20:31.142981 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:20:31.143972 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m22:20:31.144981 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:31.154890 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:20:31.154890 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:20:31.156891 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m22:20:31.161415 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m22:20:31.164436 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:20:31.165439 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m22:20:31.167958 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:20:31.171069 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m22:20:31.172069 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:20:31.172069 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m22:20:31.178819 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:20:31.181846 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup"
[0m22:20:31.182819 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:20:31.183819 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup" cascade
[0m22:20:31.186136 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m22:20:31.188157 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m22:20:31.189162 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63ED1E090>]}
[0m22:20:31.190158 [info ] [Thread-1 (]: 16 of 20 OK created sql table model dbt_dev_intermediate.dim_inventory ......... [[32mSELECT 4581[0m in 0.06s]
[0m22:20:31.192401 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m22:20:31.193445 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m22:20:31.193971 [info ] [Thread-1 (]: 17 of 20 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m22:20:31.195654 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m22:20:31.196184 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m22:20:31.199048 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m22:20:31.200656 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m22:20:31.222161 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m22:20:31.223156 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:20:31.224137 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m22:20:31.225136 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:31.232283 [debug] [Thread-1 (]: SQL status: BEGIN in 0.007 seconds
[0m22:20:31.233283 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:20:31.234286 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m22:20:31.237801 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m22:20:31.240822 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:20:31.241798 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m22:20:31.242797 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:31.244899 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m22:20:31.244899 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:20:31.245811 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m22:20:31.250029 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:20:31.252033 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m22:20:31.256029 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:20:31.256029 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m22:20:31.258337 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m22:20:31.260359 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m22:20:31.261337 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63ED7DF70>]}
[0m22:20:31.262337 [info ] [Thread-1 (]: 17 of 20 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.07s]
[0m22:20:31.263927 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m22:20:31.264975 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m22:20:31.265566 [info ] [Thread-1 (]: 18 of 20 START sql table model dbt_dev_intermediate.fact_payment ............... [RUN]
[0m22:20:31.267186 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m22:20:31.268237 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m22:20:31.272308 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m22:20:31.273967 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m22:20:31.277280 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m22:20:31.277280 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:20:31.277280 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m22:20:31.282725 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:31.291845 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:20:31.292853 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:20:31.292853 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m22:20:31.303503 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.009 seconds
[0m22:20:31.305528 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:20:31.307033 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m22:20:31.308574 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:31.310575 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m22:20:31.311600 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:20:31.311929 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m22:20:31.320458 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m22:20:31.323449 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup"
[0m22:20:31.324459 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:20:31.324459 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup" cascade
[0m22:20:31.326964 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m22:20:31.327994 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m22:20:31.328989 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63EB278F0>]}
[0m22:20:31.329992 [info ] [Thread-1 (]: 18 of 20 OK created sql table model dbt_dev_intermediate.fact_payment .......... [[32mSELECT 14596[0m in 0.06s]
[0m22:20:31.332088 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m22:20:31.333129 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m22:20:31.334753 [info ] [Thread-1 (]: 19 of 20 START sql table model dbt_dev_intermediate.dim_rental ................. [RUN]
[0m22:20:31.335831 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m22:20:31.336372 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m22:20:31.340151 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m22:20:31.341850 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m22:20:31.345525 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m22:20:31.348057 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:20:31.350054 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m22:20:31.351051 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:31.360105 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m22:20:31.360105 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:20:31.361106 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m22:20:31.371332 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.010 seconds
[0m22:20:31.374470 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:20:31.374470 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m22:20:31.376804 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:31.376804 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m22:20:31.376804 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:20:31.376804 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m22:20:31.388444 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m22:20:31.391565 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup"
[0m22:20:31.392520 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:20:31.393029 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup" cascade
[0m22:20:31.395045 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m22:20:31.396134 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m22:20:31.397612 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63F348C80>]}
[0m22:20:31.398750 [info ] [Thread-1 (]: 19 of 20 OK created sql table model dbt_dev_intermediate.dim_rental ............ [[32mSELECT 16044[0m in 0.06s]
[0m22:20:31.400963 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m22:20:31.401492 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m22:20:31.402572 [info ] [Thread-1 (]: 20 of 20 START sql table model dbt_dev_intermediate.dim_staff .................. [RUN]
[0m22:20:31.404196 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m22:20:31.404738 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m22:20:31.407639 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m22:20:31.409933 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m22:20:31.414545 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m22:20:31.415522 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:20:31.417589 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m22:20:31.418612 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:20:31.427114 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m22:20:31.428123 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:20:31.428123 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m22:20:31.434120 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.005 seconds
[0m22:20:31.437673 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:20:31.437673 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m22:20:31.439685 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:20:31.441705 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m22:20:31.442679 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:20:31.442679 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m22:20:31.445688 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m22:20:31.448265 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup"
[0m22:20:31.449241 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:20:31.450240 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup" cascade
[0m22:20:31.452805 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m22:20:31.453816 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m22:20:31.455822 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2738c8f-2ad8-4c1a-a7b9-c81692f3686e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63F1C6810>]}
[0m22:20:31.456829 [info ] [Thread-1 (]: 20 of 20 OK created sql table model dbt_dev_intermediate.dim_staff ............. [[32mSELECT 2[0m in 0.05s]
[0m22:20:31.458620 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m22:20:31.460224 [debug] [MainThread]: Using postgres connection "master"
[0m22:20:31.460746 [debug] [MainThread]: On master: BEGIN
[0m22:20:31.461331 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:20:31.488240 [debug] [MainThread]: SQL status: BEGIN in 0.027 seconds
[0m22:20:31.489264 [debug] [MainThread]: On master: COMMIT
[0m22:20:31.489264 [debug] [MainThread]: Using postgres connection "master"
[0m22:20:31.490244 [debug] [MainThread]: On master: COMMIT
[0m22:20:31.492243 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:20:31.492243 [debug] [MainThread]: On master: Close
[0m22:20:31.493238 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:20:31.494243 [debug] [MainThread]: Connection 'create_data_warehouse_dbt_dev_intermediate' was properly closed.
[0m22:20:31.494243 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_raw' was properly closed.
[0m22:20:31.495242 [debug] [MainThread]: Connection 'model.data_warehouse.dim_staff' was properly closed.
[0m22:20:31.495242 [info ] [MainThread]: 
[0m22:20:31.497307 [info ] [MainThread]: Finished running 19 table models, 1 view model in 0 hours 0 minutes and 1.96 seconds (1.96s).
[0m22:20:31.502616 [debug] [MainThread]: Command end result
[0m22:20:31.533345 [info ] [MainThread]: 
[0m22:20:31.534346 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:20:31.535629 [info ] [MainThread]: 
[0m22:20:31.537276 [info ] [MainThread]: Done. PASS=20 WARN=0 ERROR=0 SKIP=0 TOTAL=20
[0m22:20:31.539192 [debug] [MainThread]: Command `dbt run` succeeded at 22:20:31.539192 after 2.94 seconds
[0m22:20:31.540190 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63D271DF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63D4A7650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E63D4A7D70>]}
[0m22:20:31.540190 [debug] [MainThread]: Flushing usage events
[0m22:23:10.005551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDBD159D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDB515DF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDAA582C0>]}


============================== 22:23:10.009702 | 4dceaf65-7551-49a8-8879-e24e75c37f67 ==============================
[0m22:23:10.009702 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:23:10.011235 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:23:10.265343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDBD95FA0>]}
[0m22:23:10.341875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDD98B0A40>]}
[0m22:23:10.344604 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:23:10.353376 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:23:10.515220 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m22:23:10.516230 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\mart\total_revenue.sql
[0m22:23:10.824310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDC161160>]}
[0m22:23:10.949393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDD505D60>]}
[0m22:23:10.950988 [info ] [MainThread]: Found 21 models, 4 data tests, 9 sources, 417 macros
[0m22:23:10.951909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDD531D60>]}
[0m22:23:10.954906 [info ] [MainThread]: 
[0m22:23:10.955906 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:23:10.962884 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m22:23:11.030875 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:23:11.031949 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:23:11.033021 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:23:11.045739 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.013 seconds
[0m22:23:11.047744 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:23:11.051178 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:23:11.052384 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:23:11.053417 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:23:11.062524 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.009 seconds
[0m22:23:11.063583 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:23:11.068102 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:23:11.068608 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:23:11.069258 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:23:11.087912 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.019 seconds
[0m22:23:11.088947 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:23:11.093281 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:23:11.093814 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:23:11.094871 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:23:11.118072 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.024 seconds
[0m22:23:11.120073 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:23:11.121580 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse, now create_data_warehouse_dbt_dev_mart)
[0m22:23:11.122085 [debug] [ThreadPool]: Creating schema "database: "data_warehouse"
schema: "dbt_dev_mart"
"
[0m22:23:11.128811 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_mart"
[0m22:23:11.129405 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_mart: BEGIN
[0m22:23:11.129911 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:23:11.136699 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m22:23:11.136699 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_mart"
[0m22:23:11.137705 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "create_data_warehouse_dbt_dev_mart"} */
create schema if not exists "dbt_dev_mart"
[0m22:23:11.138705 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m22:23:11.139699 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_mart: COMMIT
[0m22:23:11.141208 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_mart"
[0m22:23:11.141208 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_mart: COMMIT
[0m22:23:11.145234 [debug] [ThreadPool]: SQL status: COMMIT in 0.003 seconds
[0m22:23:11.146235 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_mart: Close
[0m22:23:11.148740 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_mart'
[0m22:23:11.154797 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m22:23:11.155847 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m22:23:11.156365 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:23:11.179525 [debug] [ThreadPool]: SQL status: BEGIN in 0.024 seconds
[0m22:23:11.181080 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m22:23:11.181080 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m22:23:11.185499 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m22:23:11.186512 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m22:23:11.188512 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m22:23:11.189509 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev)
[0m22:23:11.192561 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:23:11.193068 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m22:23:11.194132 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:23:11.201160 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m22:23:11.201704 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:23:11.202755 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m22:23:11.206805 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m22:23:11.207808 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m22:23:11.209819 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m22:23:11.210808 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_raw)
[0m22:23:11.215729 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:23:11.215729 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m22:23:11.216822 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:23:11.224276 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m22:23:11.225332 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:23:11.225863 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m22:23:11.229986 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:23:11.231514 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m22:23:11.233523 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m22:23:11.234521 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev_intermediate)
[0m22:23:11.237851 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m22:23:11.238520 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: BEGIN
[0m22:23:11.239028 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:23:11.247718 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m22:23:11.248723 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m22:23:11.248723 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediate"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediate'
  
[0m22:23:11.253242 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:23:11.254244 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: ROLLBACK
[0m22:23:11.256244 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: Close
[0m22:23:11.264096 [debug] [MainThread]: Using postgres connection "master"
[0m22:23:11.264641 [debug] [MainThread]: On master: BEGIN
[0m22:23:11.265175 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:23:11.271975 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m22:23:11.272995 [debug] [MainThread]: Using postgres connection "master"
[0m22:23:11.272995 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:23:11.282517 [debug] [MainThread]: SQL status: SELECT 38 in 0.009 seconds
[0m22:23:11.285031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDA83230>]}
[0m22:23:11.286026 [debug] [MainThread]: On master: ROLLBACK
[0m22:23:11.288150 [debug] [MainThread]: Using postgres connection "master"
[0m22:23:11.288150 [debug] [MainThread]: On master: BEGIN
[0m22:23:11.291148 [debug] [MainThread]: SQL status: BEGIN in 0.002 seconds
[0m22:23:11.291148 [debug] [MainThread]: On master: COMMIT
[0m22:23:11.292202 [debug] [MainThread]: Using postgres connection "master"
[0m22:23:11.293204 [debug] [MainThread]: On master: COMMIT
[0m22:23:11.295212 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:23:11.296216 [debug] [MainThread]: On master: Close
[0m22:23:11.297217 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:23:11.298216 [info ] [MainThread]: 
[0m22:23:11.302597 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m22:23:11.303209 [info ] [Thread-1 (]: 1 of 21 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m22:23:11.304287 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m22:23:11.305351 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m22:23:11.315315 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m22:23:11.316885 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m22:23:11.356626 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m22:23:11.358624 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:23:11.359632 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m22:23:11.361228 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:23:11.370977 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:23:11.371984 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:23:11.372987 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."actor"
  );
  
[0m22:23:11.376027 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m22:23:11.381548 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:23:11.382562 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m22:23:11.384558 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:23:11.387553 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:23:11.388667 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m22:23:11.389579 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:23:11.409580 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m22:23:11.411088 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:23:11.412420 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m22:23:11.416420 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:23:11.423026 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m22:23:11.430031 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:23:11.430031 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m22:23:11.434143 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m22:23:11.437142 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m22:23:11.439751 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDD9883D40>]}
[0m22:23:11.439751 [info ] [Thread-1 (]: 1 of 21 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.13s]
[0m22:23:11.442929 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m22:23:11.443460 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m22:23:11.444520 [info ] [Thread-1 (]: 2 of 21 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m22:23:11.446158 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m22:23:11.446722 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m22:23:11.450429 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m22:23:11.452053 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m22:23:11.458076 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m22:23:11.460079 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:23:11.461587 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m22:23:11.462598 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:11.490949 [debug] [Thread-1 (]: SQL status: BEGIN in 0.028 seconds
[0m22:23:11.492115 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:23:11.493135 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."address"
  );
  
[0m22:23:11.497146 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.003 seconds
[0m22:23:11.500166 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:23:11.500166 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m22:23:11.502695 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:11.505693 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:23:11.505693 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m22:23:11.508692 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:11.509693 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m22:23:11.511281 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:23:11.512208 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m22:23:11.519032 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:23:11.521662 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m22:23:11.522669 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:23:11.523670 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m22:23:11.528884 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:23:11.529995 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m22:23:11.530912 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDB978F0>]}
[0m22:23:11.532034 [info ] [Thread-1 (]: 2 of 21 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.09s]
[0m22:23:11.534475 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m22:23:11.535601 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m22:23:11.537179 [info ] [Thread-1 (]: 3 of 21 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m22:23:11.538303 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m22:23:11.539420 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m22:23:11.544307 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m22:23:11.546024 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m22:23:11.552961 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m22:23:11.554978 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:23:11.555981 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m22:23:11.556977 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:11.571635 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m22:23:11.572643 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:23:11.573652 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."customer"
  );
  
[0m22:23:11.578119 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.003 seconds
[0m22:23:11.582634 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:23:11.582634 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m22:23:11.585640 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:23:11.588642 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:23:11.589643 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m22:23:11.592283 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:23:11.594295 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m22:23:11.596292 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:23:11.597294 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m22:23:11.601180 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:23:11.603198 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m22:23:11.605121 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:23:11.605121 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m22:23:11.611114 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:23:11.612636 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m22:23:11.613643 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDBB3D40>]}
[0m22:23:11.614633 [info ] [Thread-1 (]: 3 of 21 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.08s]
[0m22:23:11.616639 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m22:23:11.617661 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m22:23:11.618713 [info ] [Thread-1 (]: 4 of 21 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m22:23:11.619818 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m22:23:11.620345 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m22:23:11.623718 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m22:23:11.626151 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m22:23:11.630925 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m22:23:11.632016 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:23:11.632940 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m22:23:11.633937 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:11.659561 [debug] [Thread-1 (]: SQL status: BEGIN in 0.026 seconds
[0m22:23:11.661067 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:23:11.662073 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."film"
  );
  
[0m22:23:11.669498 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.007 seconds
[0m22:23:11.673040 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:23:11.674096 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m22:23:11.676010 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:11.679105 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:23:11.680092 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m22:23:11.681545 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:11.684555 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m22:23:11.684555 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:23:11.685554 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m22:23:11.693065 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m22:23:11.696084 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m22:23:11.697069 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:23:11.697069 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m22:23:11.701097 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m22:23:11.703375 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m22:23:11.704287 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDB0EDE0>]}
[0m22:23:11.705283 [info ] [Thread-1 (]: 4 of 21 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.08s]
[0m22:23:11.706285 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m22:23:11.707495 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m22:23:11.708612 [info ] [Thread-1 (]: 5 of 21 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m22:23:11.709648 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m22:23:11.710720 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m22:23:11.714574 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m22:23:11.716266 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m22:23:11.722892 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m22:23:11.724856 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:23:11.725852 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m22:23:11.727173 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:11.737678 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:23:11.737678 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:23:11.738678 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m22:23:11.744219 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.005 seconds
[0m22:23:11.747219 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:23:11.747219 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m22:23:11.750192 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:11.753238 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:23:11.754217 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m22:23:11.756217 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:11.759210 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m22:23:11.760211 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:23:11.761233 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m22:23:11.768336 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:23:11.769329 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m22:23:11.771839 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:23:11.771839 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m22:23:11.776860 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:23:11.778855 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m22:23:11.779856 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDBACDA0>]}
[0m22:23:11.781366 [info ] [Thread-1 (]: 5 of 21 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.07s]
[0m22:23:11.783608 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m22:23:11.784747 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m22:23:11.785256 [info ] [Thread-1 (]: 6 of 21 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m22:23:11.786830 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m22:23:11.787369 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m22:23:11.791756 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m22:23:11.794266 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m22:23:11.800257 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m22:23:11.801817 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:23:11.802836 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m22:23:11.803826 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:11.833659 [debug] [Thread-1 (]: SQL status: BEGIN in 0.030 seconds
[0m22:23:11.833659 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:23:11.834687 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m22:23:11.839658 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m22:23:11.842763 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:23:11.843772 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m22:23:11.846773 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:23:11.848773 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:23:11.849772 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m22:23:11.852287 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:11.853291 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m22:23:11.854290 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:23:11.855290 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m22:23:11.860801 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:23:11.863813 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m22:23:11.864815 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:23:11.865814 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m22:23:11.869693 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m22:23:11.871223 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m22:23:11.872227 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDA7FD40>]}
[0m22:23:11.874239 [info ] [Thread-1 (]: 6 of 21 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.09s]
[0m22:23:11.876826 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m22:23:11.877350 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m22:23:11.878413 [info ] [Thread-1 (]: 7 of 21 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m22:23:11.879513 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m22:23:11.880656 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m22:23:11.883335 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m22:23:11.884993 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m22:23:11.889745 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m22:23:11.893262 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:23:11.894280 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m22:23:11.895273 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:11.924209 [debug] [Thread-1 (]: SQL status: BEGIN in 0.029 seconds
[0m22:23:11.925430 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:23:11.926438 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m22:23:11.929439 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.002 seconds
[0m22:23:11.933957 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:23:11.934977 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m22:23:11.936953 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:11.987164 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:23:11.988164 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m22:23:11.991295 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:11.994246 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m22:23:11.994246 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:23:11.995244 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m22:23:12.000242 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:23:12.002801 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m22:23:12.003804 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:23:12.004802 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m22:23:12.009242 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:23:12.011243 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m22:23:12.012312 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDFAA9C0>]}
[0m22:23:12.013316 [info ] [Thread-1 (]: 7 of 21 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.13s]
[0m22:23:12.015312 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m22:23:12.015827 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m22:23:12.016846 [info ] [Thread-1 (]: 8 of 21 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m22:23:12.017913 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m22:23:12.018465 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m22:23:12.021749 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m22:23:12.023360 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m22:23:12.029397 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m22:23:12.030906 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:23:12.032921 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m22:23:12.033938 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:12.061090 [debug] [Thread-1 (]: SQL status: BEGIN in 0.027 seconds
[0m22:23:12.061600 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:23:12.062608 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."payment"
  );
  
[0m22:23:12.072170 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.008 seconds
[0m22:23:12.075172 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:23:12.076173 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m22:23:12.079172 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:12.081728 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:23:12.082732 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m22:23:12.084734 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:23:12.086732 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m22:23:12.086732 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:23:12.087732 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m22:23:12.096840 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m22:23:12.098922 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m22:23:12.100845 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:23:12.100845 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m22:23:12.105284 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:23:12.107287 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m22:23:12.108286 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDFABF50>]}
[0m22:23:12.109287 [info ] [Thread-1 (]: 8 of 21 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.09s]
[0m22:23:12.112314 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m22:23:12.112819 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m22:23:12.113900 [info ] [Thread-1 (]: 9 of 21 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m22:23:12.114961 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m22:23:12.116034 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m22:23:12.120669 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m22:23:12.122849 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m22:23:12.128811 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m22:23:12.130807 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:23:12.131323 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m22:23:12.132333 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:12.141919 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m22:23:12.142921 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:23:12.143916 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."rental"
  );
  
[0m22:23:12.154446 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.010 seconds
[0m22:23:12.157531 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:23:12.158443 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m22:23:12.160950 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:12.164014 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:23:12.165006 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m22:23:12.166958 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:12.168961 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m22:23:12.169962 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:23:12.169962 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m22:23:12.179481 [debug] [Thread-1 (]: SQL status: COMMIT in 0.009 seconds
[0m22:23:12.183595 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m22:23:12.184609 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:23:12.185642 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m22:23:12.190893 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:23:12.193858 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m22:23:12.194894 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDA7F140>]}
[0m22:23:12.196223 [info ] [Thread-1 (]: 9 of 21 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.08s]
[0m22:23:12.198908 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m22:23:12.199540 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m22:23:12.200224 [info ] [Thread-1 (]: 10 of 21 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m22:23:12.201855 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m22:23:12.202359 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m22:23:12.206005 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m22:23:12.207395 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m22:23:12.212808 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m22:23:12.214773 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:23:12.214773 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m22:23:12.215770 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:12.232485 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m22:23:12.233496 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:23:12.234501 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."staff"
  );
  
[0m22:23:12.239491 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.005 seconds
[0m22:23:12.244002 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:23:12.245029 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m22:23:12.247005 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:23:12.250021 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:23:12.250021 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m22:23:12.252854 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:23:12.254869 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m22:23:12.255849 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:23:12.255849 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m22:23:12.259401 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:23:12.261926 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m22:23:12.262928 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:23:12.263928 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m22:23:12.267705 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m22:23:12.268804 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m22:23:12.270721 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDA7EF60>]}
[0m22:23:12.271229 [info ] [Thread-1 (]: 10 of 21 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.07s]
[0m22:23:12.273919 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m22:23:12.274726 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m22:23:12.276349 [info ] [Thread-1 (]: 11 of 21 START sql table model dbt_dev_intermediate.dim_actor .................. [RUN]
[0m22:23:12.277551 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m22:23:12.279135 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m22:23:12.282661 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m22:23:12.284583 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m22:23:12.287581 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m22:23:12.289584 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:23:12.291173 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m22:23:12.292096 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:12.303929 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m22:23:12.304954 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:23:12.304954 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m22:23:12.309604 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.003 seconds
[0m22:23:12.313141 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:23:12.313141 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor" rename to "dim_actor__dbt_backup"
[0m22:23:12.316121 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:12.318921 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:23:12.318921 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m22:23:12.321926 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:12.322929 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m22:23:12.324023 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:23:12.324927 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m22:23:12.329674 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:23:12.331983 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup"
[0m22:23:12.333041 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:23:12.333942 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup" cascade
[0m22:23:12.338046 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:23:12.339955 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m22:23:12.342025 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDBD3650>]}
[0m22:23:12.343025 [info ] [Thread-1 (]: 11 of 21 OK created sql table model dbt_dev_intermediate.dim_actor ............. [[32mSELECT 200[0m in 0.06s]
[0m22:23:12.344965 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m22:23:12.345472 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m22:23:12.346633 [info ] [Thread-1 (]: 12 of 21 START sql table model dbt_dev_intermediate.dim_address ................ [RUN]
[0m22:23:12.348420 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m22:23:12.349080 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m22:23:12.352344 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m22:23:12.353991 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m22:23:12.361320 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m22:23:12.362328 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:23:12.363337 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m22:23:12.364340 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:12.386462 [debug] [Thread-1 (]: SQL status: BEGIN in 0.022 seconds
[0m22:23:12.386997 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:23:12.387641 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m22:23:12.390331 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m22:23:12.394501 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:23:12.395476 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address" rename to "dim_address__dbt_backup"
[0m22:23:12.397474 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:23:12.399692 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:23:12.401250 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp" rename to "dim_address"
[0m22:23:12.403199 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:12.405221 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m22:23:12.405221 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:23:12.406605 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m22:23:12.411177 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:23:12.413121 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup"
[0m22:23:12.414136 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:23:12.415126 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup" cascade
[0m22:23:12.419674 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:23:12.421343 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m22:23:12.421343 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDD551760>]}
[0m22:23:12.422751 [info ] [Thread-1 (]: 12 of 21 OK created sql table model dbt_dev_intermediate.dim_address ........... [[32mSELECT 603[0m in 0.07s]
[0m22:23:12.425327 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m22:23:12.426370 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m22:23:12.427448 [info ] [Thread-1 (]: 13 of 21 START sql table model dbt_dev_intermediate.dim_customer ............... [RUN]
[0m22:23:12.428572 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m22:23:12.429790 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m22:23:12.432910 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m22:23:12.434707 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m22:23:12.438054 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m22:23:12.439065 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:23:12.439970 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m22:23:12.440967 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:12.451198 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:23:12.451198 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:23:12.452299 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m22:23:12.455206 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.003 seconds
[0m22:23:12.459284 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:23:12.460811 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer" rename to "dim_customer__dbt_backup"
[0m22:23:12.462376 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:23:12.465394 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:23:12.465394 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m22:23:12.468437 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:12.469484 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m22:23:12.471054 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:23:12.472057 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m22:23:12.478230 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:23:12.480238 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup"
[0m22:23:12.481753 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:23:12.481753 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup" cascade
[0m22:23:12.486778 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:23:12.487873 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m22:23:12.488861 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDB358B0>]}
[0m22:23:12.490047 [info ] [Thread-1 (]: 13 of 21 OK created sql table model dbt_dev_intermediate.dim_customer .......... [[32mSELECT 599[0m in 0.06s]
[0m22:23:12.492585 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m22:23:12.493648 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m22:23:12.495363 [info ] [Thread-1 (]: 14 of 21 START sql table model dbt_dev_intermediate.dim_film ................... [RUN]
[0m22:23:12.496168 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m22:23:12.497845 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m22:23:12.501171 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m22:23:12.502298 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m22:23:12.503985 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m22:23:12.503985 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:23:12.503985 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m22:23:12.503985 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:12.519261 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m22:23:12.520262 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:23:12.521282 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m22:23:12.531035 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.009 seconds
[0m22:23:12.534980 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:23:12.535990 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film" rename to "dim_film__dbt_backup"
[0m22:23:12.537977 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:12.540978 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:23:12.542114 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp" rename to "dim_film"
[0m22:23:12.545330 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:12.547326 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m22:23:12.548363 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:23:12.548363 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m22:23:12.557655 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m22:23:12.561161 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup"
[0m22:23:12.563169 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:23:12.563169 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup" cascade
[0m22:23:12.570091 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m22:23:12.571131 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m22:23:12.572441 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDD363C50>]}
[0m22:23:12.573452 [info ] [Thread-1 (]: 14 of 21 OK created sql table model dbt_dev_intermediate.dim_film .............. [[32mSELECT 1000[0m in 0.08s]
[0m22:23:12.575424 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m22:23:12.576543 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m22:23:12.578173 [info ] [Thread-1 (]: 15 of 21 START sql table model dbt_dev_intermediate.dim_film_actor ............. [RUN]
[0m22:23:12.579263 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m22:23:12.580391 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m22:23:12.583813 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m22:23:12.585609 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m22:23:12.589281 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m22:23:12.592810 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:23:12.593817 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m22:23:12.594821 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:12.627002 [debug] [Thread-1 (]: SQL status: BEGIN in 0.032 seconds
[0m22:23:12.628010 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:23:12.629015 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m22:23:12.635106 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.006 seconds
[0m22:23:12.639197 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:23:12.640203 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m22:23:12.643643 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:12.647659 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:23:12.647659 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m22:23:12.651272 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:12.653201 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m22:23:12.654209 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:23:12.655360 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m22:23:12.663431 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m22:23:12.665440 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup"
[0m22:23:12.667036 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:23:12.668047 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup" cascade
[0m22:23:12.672501 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:23:12.673801 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m22:23:12.673801 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDB57F20>]}
[0m22:23:12.673801 [info ] [Thread-1 (]: 15 of 21 OK created sql table model dbt_dev_intermediate.dim_film_actor ........ [[32mSELECT 5462[0m in 0.09s]
[0m22:23:12.678490 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m22:23:12.679231 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m22:23:12.680903 [info ] [Thread-1 (]: 16 of 21 START sql table model dbt_dev_intermediate.dim_inventory .............. [RUN]
[0m22:23:12.682020 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m22:23:12.682528 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m22:23:12.685426 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m22:23:12.687115 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m22:23:12.690913 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m22:23:12.693022 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:23:12.695020 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m22:23:12.696025 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:12.705678 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:23:12.706776 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:23:12.707680 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m22:23:12.713192 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.005 seconds
[0m22:23:12.716194 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:23:12.717192 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m22:23:12.719416 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:12.721932 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:23:12.721932 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m22:23:12.725078 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:12.728174 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m22:23:12.729086 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:23:12.730090 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m22:23:12.738804 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:23:12.742317 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup"
[0m22:23:12.744313 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:23:12.744313 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup" cascade
[0m22:23:12.748825 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:23:12.750846 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m22:23:12.751431 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDBD5580>]}
[0m22:23:12.753438 [info ] [Thread-1 (]: 16 of 21 OK created sql table model dbt_dev_intermediate.dim_inventory ......... [[32mSELECT 4581[0m in 0.07s]
[0m22:23:12.755379 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m22:23:12.755918 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m22:23:12.756523 [info ] [Thread-1 (]: 17 of 21 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m22:23:12.757708 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m22:23:12.758739 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m22:23:12.762001 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m22:23:12.763789 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m22:23:12.781510 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m22:23:12.782456 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:23:12.784688 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m22:23:12.784688 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:12.809700 [debug] [Thread-1 (]: SQL status: BEGIN in 0.025 seconds
[0m22:23:12.809700 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:23:12.811236 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m22:23:12.814141 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m22:23:12.817249 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:23:12.817866 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m22:23:12.819872 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:23:12.822179 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m22:23:12.822179 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:23:12.823175 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m22:23:12.827102 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:23:12.830166 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m22:23:12.833295 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:23:12.833295 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m22:23:12.836190 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.002 seconds
[0m22:23:12.837287 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m22:23:12.838278 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDBC8350>]}
[0m22:23:12.839609 [info ] [Thread-1 (]: 17 of 21 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.08s]
[0m22:23:12.841751 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m22:23:12.842299 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m22:23:12.843375 [info ] [Thread-1 (]: 18 of 21 START sql table model dbt_dev_intermediate.fact_payment ............... [RUN]
[0m22:23:12.844453 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m22:23:12.845045 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m22:23:12.848003 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m22:23:12.849319 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m22:23:12.853639 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m22:23:12.855530 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:23:12.855530 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m22:23:12.856562 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:12.866644 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:23:12.866644 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:23:12.867647 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m22:23:12.877318 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.009 seconds
[0m22:23:12.879592 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:23:12.881118 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment" rename to "fact_payment__dbt_backup"
[0m22:23:12.881726 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:12.881726 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:23:12.881726 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m22:23:12.881726 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:23:12.881726 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m22:23:12.892038 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:23:12.893036 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m22:23:12.903293 [debug] [Thread-1 (]: SQL status: COMMIT in 0.009 seconds
[0m22:23:12.905403 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup"
[0m22:23:12.906298 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:23:12.906298 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup" cascade
[0m22:23:12.911812 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:23:12.913901 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m22:23:12.914814 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDD5599D0>]}
[0m22:23:12.915814 [info ] [Thread-1 (]: 18 of 21 OK created sql table model dbt_dev_intermediate.fact_payment .......... [[32mSELECT 14596[0m in 0.07s]
[0m22:23:12.917628 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m22:23:12.918677 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m22:23:12.919235 [info ] [Thread-1 (]: 19 of 21 START sql table model dbt_dev_intermediate.dim_rental ................. [RUN]
[0m22:23:12.920947 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m22:23:12.922054 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m22:23:12.925898 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m22:23:12.927371 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m22:23:12.932728 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m22:23:12.934747 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:23:12.935731 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m22:23:12.936736 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:12.964509 [debug] [Thread-1 (]: SQL status: BEGIN in 0.028 seconds
[0m22:23:12.964509 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:23:12.965509 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m22:23:12.975040 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.009 seconds
[0m22:23:12.978124 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:23:12.979138 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental" rename to "dim_rental__dbt_backup"
[0m22:23:12.981639 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:12.984736 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:23:12.984736 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m22:23:12.986652 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:23:12.988649 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m22:23:12.989647 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:23:12.989647 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m22:23:12.998277 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m22:23:12.999362 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup"
[0m22:23:13.000869 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:23:13.001887 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup" cascade
[0m22:23:13.006618 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:23:13.008664 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m22:23:13.009622 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDB797F0>]}
[0m22:23:13.011136 [info ] [Thread-1 (]: 19 of 21 OK created sql table model dbt_dev_intermediate.dim_rental ............ [[32mSELECT 16044[0m in 0.09s]
[0m22:23:13.012947 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m22:23:13.013467 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m22:23:13.015235 [info ] [Thread-1 (]: 20 of 21 START sql table model dbt_dev_intermediate.dim_staff .................. [RUN]
[0m22:23:13.016288 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m22:23:13.017356 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m22:23:13.020754 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m22:23:13.022337 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m22:23:13.028415 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m22:23:13.029491 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:23:13.030573 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m22:23:13.031091 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:13.057944 [debug] [Thread-1 (]: SQL status: BEGIN in 0.027 seconds
[0m22:23:13.058942 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:23:13.059941 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m22:23:13.067459 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.007 seconds
[0m22:23:13.069479 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:23:13.070989 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff" rename to "dim_staff__dbt_backup"
[0m22:23:13.072997 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:23:13.076014 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:23:13.077015 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m22:23:13.080098 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:13.082256 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m22:23:13.083264 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:23:13.083264 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m22:23:13.087071 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:23:13.089112 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup"
[0m22:23:13.091091 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:23:13.091596 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup" cascade
[0m22:23:13.096609 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:23:13.097609 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m22:23:13.099602 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDD3792E0>]}
[0m22:23:13.101116 [info ] [Thread-1 (]: 20 of 21 OK created sql table model dbt_dev_intermediate.dim_staff ............. [[32mSELECT 2[0m in 0.08s]
[0m22:23:13.102128 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m22:23:13.103146 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m22:23:13.104322 [info ] [Thread-1 (]: 21 of 21 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m22:23:13.105503 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.total_revenue)
[0m22:23:13.106033 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m22:23:13.109724 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m22:23:13.112388 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m22:23:13.118146 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m22:23:13.120799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:23:13.121837 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m22:23:13.122810 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:23:13.133330 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:23:13.134335 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:23:13.134335 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    sum(amount) as total_revenue,
    payment_date
FROM
    "data_warehouse"."dbt_dev_intermediate"."fact_payment"
GROUP BY
    payment_date
  );
  
[0m22:23:13.159426 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.024 seconds
[0m22:23:13.162060 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:23:13.163133 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m22:23:13.165083 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:23:13.167059 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m22:23:13.167059 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:23:13.168318 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m22:23:13.177280 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m22:23:13.180869 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m22:23:13.181877 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:23:13.181877 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m22:23:13.183890 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m22:23:13.185886 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m22:23:13.186892 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4dceaf65-7551-49a8-8879-e24e75c37f67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDDBCC770>]}
[0m22:23:13.187896 [info ] [Thread-1 (]: 21 of 21 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.08s]
[0m22:23:13.189723 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m22:23:13.192120 [debug] [MainThread]: Using postgres connection "master"
[0m22:23:13.193165 [debug] [MainThread]: On master: BEGIN
[0m22:23:13.193804 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:23:13.227959 [debug] [MainThread]: SQL status: BEGIN in 0.034 seconds
[0m22:23:13.227959 [debug] [MainThread]: On master: COMMIT
[0m22:23:13.228967 [debug] [MainThread]: Using postgres connection "master"
[0m22:23:13.228967 [debug] [MainThread]: On master: COMMIT
[0m22:23:13.230943 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:23:13.230943 [debug] [MainThread]: On master: Close
[0m22:23:13.232964 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:23:13.232964 [debug] [MainThread]: Connection 'create_data_warehouse_dbt_dev_mart' was properly closed.
[0m22:23:13.233970 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_intermediate' was properly closed.
[0m22:23:13.234970 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m22:23:13.235963 [info ] [MainThread]: 
[0m22:23:13.236562 [info ] [MainThread]: Finished running 20 table models, 1 view model in 0 hours 0 minutes and 2.28 seconds (2.28s).
[0m22:23:13.242788 [debug] [MainThread]: Command end result
[0m22:23:13.271268 [info ] [MainThread]: 
[0m22:23:13.272276 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:23:13.273276 [info ] [MainThread]: 
[0m22:23:13.274286 [info ] [MainThread]: Done. PASS=21 WARN=0 ERROR=0 SKIP=0 TOTAL=21
[0m22:23:13.277342 [debug] [MainThread]: Command `dbt run` succeeded at 22:23:13.276342 after 3.41 seconds
[0m22:23:13.277342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDBD159D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDD3B1370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDB54CD40>]}
[0m22:23:13.279417 [debug] [MainThread]: Flushing usage events
[0m22:23:51.975341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB691AA80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB67127B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB6897020>]}


============================== 22:23:51.978980 | 5e0df96a-d72f-4cad-95d9-20be99cd1543 ==============================
[0m22:23:51.978980 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:23:51.980952 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt docs generate', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:23:52.184888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5e0df96a-d72f-4cad-95d9-20be99cd1543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB6A6C200>]}
[0m22:23:52.246532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5e0df96a-d72f-4cad-95d9-20be99cd1543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB6AE8650>]}
[0m22:23:52.248640 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:23:52.257171 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:23:52.401549 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:23:52.402555 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:23:52.438390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5e0df96a-d72f-4cad-95d9-20be99cd1543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB6C4FDA0>]}
[0m22:23:52.476855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5e0df96a-d72f-4cad-95d9-20be99cd1543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB7F09520>]}
[0m22:23:52.477821 [info ] [MainThread]: Found 21 models, 4 data tests, 9 sources, 417 macros
[0m22:23:52.478764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5e0df96a-d72f-4cad-95d9-20be99cd1543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB7D68FB0>]}
[0m22:23:52.482378 [info ] [MainThread]: 
[0m22:23:52.483742 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:23:52.491365 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_raw'
[0m22:23:52.554813 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:23:52.555785 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m22:23:52.557089 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:23:52.570853 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m22:23:52.571885 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:23:52.572863 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m22:23:52.575884 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:23:52.577879 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m22:23:52.579858 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m22:23:52.579858 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev_intermediate)
[0m22:23:52.584328 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m22:23:52.584846 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: BEGIN
[0m22:23:52.585379 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:23:52.593359 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m22:23:52.593897 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m22:23:52.594448 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediate"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediate'
  
[0m22:23:52.597475 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:23:52.599471 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: ROLLBACK
[0m22:23:52.601026 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: Close
[0m22:23:52.601026 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediate, now list_data_warehouse_dbt_dev_mart)
[0m22:23:52.605493 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m22:23:52.606065 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m22:23:52.606619 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:23:52.632450 [debug] [ThreadPool]: SQL status: BEGIN in 0.026 seconds
[0m22:23:52.633456 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m22:23:52.633456 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m22:23:52.637706 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m22:23:52.638734 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m22:23:52.639714 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m22:23:52.641227 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev)
[0m22:23:52.644238 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:23:52.644515 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m22:23:52.645164 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:23:52.662259 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m22:23:52.663340 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:23:52.664354 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m22:23:52.667571 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m22:23:52.668555 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m22:23:52.671067 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m22:23:52.676959 [debug] [MainThread]: Using postgres connection "master"
[0m22:23:52.677660 [debug] [MainThread]: On master: BEGIN
[0m22:23:52.678164 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:23:52.712327 [debug] [MainThread]: SQL status: BEGIN in 0.034 seconds
[0m22:23:52.712327 [debug] [MainThread]: Using postgres connection "master"
[0m22:23:52.713355 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:23:52.722575 [debug] [MainThread]: SQL status: SELECT 38 in 0.008 seconds
[0m22:23:52.724662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5e0df96a-d72f-4cad-95d9-20be99cd1543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB6BDC770>]}
[0m22:23:52.724662 [debug] [MainThread]: On master: ROLLBACK
[0m22:23:52.726574 [debug] [MainThread]: On master: Close
[0m22:23:52.727637 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:23:52.728574 [info ] [MainThread]: 
[0m22:23:52.733760 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m22:23:52.734383 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m22:23:52.735015 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m22:23:52.743149 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m22:23:52.744164 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m22:23:52.745182 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m22:23:52.747164 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m22:23:52.748161 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m22:23:52.749165 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m22:23:52.752367 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m22:23:52.754659 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m22:23:52.756178 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m22:23:52.757181 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m22:23:52.758183 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m22:23:52.759175 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m22:23:52.762433 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m22:23:52.763331 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m22:23:52.766287 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m22:23:52.767290 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m22:23:52.768282 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m22:23:52.769282 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m22:23:52.772511 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m22:23:52.774530 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m22:23:52.775516 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m22:23:52.776509 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m22:23:52.777514 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m22:23:52.777514 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m22:23:52.782037 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m22:23:52.783042 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m22:23:52.785034 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m22:23:52.786040 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m22:23:52.787036 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m22:23:52.788476 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m22:23:52.793010 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m22:23:52.794025 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m22:23:52.796056 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m22:23:52.797118 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m22:23:52.798015 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m22:23:52.799017 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m22:23:52.801724 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m22:23:52.803738 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m22:23:52.805742 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m22:23:52.806736 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m22:23:52.807577 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m22:23:52.807577 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m22:23:52.811258 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m22:23:52.812264 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m22:23:52.813264 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m22:23:52.814270 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m22:23:52.815271 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m22:23:52.816269 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m22:23:52.821230 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m22:23:52.824177 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m22:23:52.826226 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m22:23:52.827253 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m22:23:52.828258 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m22:23:52.829168 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m22:23:52.833775 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m22:23:52.835717 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m22:23:52.837918 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m22:23:52.838870 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m22:23:52.839836 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m22:23:52.840838 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m22:23:52.844913 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m22:23:52.845905 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m22:23:52.847896 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m22:23:52.847896 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m22:23:52.849909 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m22:23:52.850898 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m22:23:52.853430 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m22:23:52.855445 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m22:23:52.856448 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m22:23:52.856448 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m22:23:52.857438 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m22:23:52.858451 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m22:23:52.861065 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m22:23:52.862664 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m22:23:52.864800 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m22:23:52.865788 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m22:23:52.866788 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m22:23:52.866788 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m22:23:52.869784 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m22:23:52.872336 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m22:23:52.874345 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m22:23:52.874345 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m22:23:52.875320 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m22:23:52.876324 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m22:23:52.879985 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m22:23:52.880973 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m22:23:52.882272 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m22:23:52.883252 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m22:23:52.884252 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m22:23:52.885296 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m22:23:52.888261 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m22:23:52.890264 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m22:23:52.891279 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m22:23:52.892464 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m22:23:52.893457 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m22:23:52.894460 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m22:23:52.897459 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m22:23:52.899467 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m22:23:52.901038 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m22:23:52.901038 [debug] [Thread-1 (]: Began running node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m22:23:52.902001 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710)
[0m22:23:52.902990 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m22:23:52.914294 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710"
[0m22:23:52.916297 [debug] [Thread-1 (]: Began executing node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m22:23:52.918302 [debug] [Thread-1 (]: Finished running node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m22:23:52.919293 [debug] [Thread-1 (]: Began running node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m22:23:52.920307 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710, now test.data_warehouse.unique_my_first_dbt_model_id.16e066b321)
[0m22:23:52.921304 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m22:23:52.928771 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.unique_my_first_dbt_model_id.16e066b321"
[0m22:23:52.931279 [debug] [Thread-1 (]: Began executing node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m22:23:52.933291 [debug] [Thread-1 (]: Finished running node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m22:23:52.934288 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m22:23:52.935288 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.unique_my_first_dbt_model_id.16e066b321, now model.data_warehouse.fact_payment)
[0m22:23:52.936286 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m22:23:52.940287 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m22:23:52.941800 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m22:23:52.943806 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m22:23:52.944812 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m22:23:52.945814 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m22:23:52.945814 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m22:23:52.949807 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m22:23:52.951327 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m22:23:52.952344 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m22:23:52.953344 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m22:23:52.954355 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m22:23:52.955393 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m22:23:52.958359 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m22:23:52.959371 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m22:23:52.961926 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m22:23:52.962915 [debug] [Thread-1 (]: Began running node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m22:23:52.964027 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778)
[0m22:23:52.964027 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m22:23:52.968020 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778"
[0m22:23:52.971026 [debug] [Thread-1 (]: Began executing node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m22:23:52.972549 [debug] [Thread-1 (]: Finished running node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m22:23:52.973543 [debug] [Thread-1 (]: Began running node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m22:23:52.974561 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778, now test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493)
[0m22:23:52.975554 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m22:23:52.979548 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493"
[0m22:23:52.981055 [debug] [Thread-1 (]: Began executing node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m22:23:52.983060 [debug] [Thread-1 (]: Finished running node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m22:23:52.984067 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m22:23:52.985077 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493, now model.data_warehouse.total_revenue)
[0m22:23:52.986333 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m22:23:52.989958 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m22:23:52.990930 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m22:23:52.992286 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m22:23:52.994288 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:23:52.994288 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev' was properly closed.
[0m22:23:52.995286 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m22:23:52.999285 [debug] [MainThread]: Command end result
[0m22:23:53.429330 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m22:23:53.429330 [info ] [MainThread]: Building catalog
[0m22:23:53.439354 [debug] [ThreadPool]: Acquiring new postgres connection 'data_warehouse.information_schema'
[0m22:23:53.447072 [debug] [ThreadPool]: Using postgres connection "data_warehouse.information_schema"
[0m22:23:53.447072 [debug] [ThreadPool]: On data_warehouse.information_schema: BEGIN
[0m22:23:53.448979 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:23:53.471002 [debug] [ThreadPool]: SQL status: BEGIN in 0.022 seconds
[0m22:23:53.471002 [debug] [ThreadPool]: Using postgres connection "data_warehouse.information_schema"
[0m22:23:53.472009 [debug] [ThreadPool]: On data_warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "data_warehouse.information_schema"} */

    
    

    select
        'data_warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('film')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('inventory')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('payment')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('dim_rental')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('rental')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('actor')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('staff')) or (upper(sch.nspname) = upper('dbt_dev') and
           upper(tbl.relname) = upper('my_second_dbt_model')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('dim_staff')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('total_revenue')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('dim_actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('customer')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('inventory')) or (upper(sch.nspname) = upper('dbt_dev') and
           upper(tbl.relname) = upper('my_first_dbt_model')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('film_actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('payment')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('dim_film')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('dim_address')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('customer')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('rental')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('film_actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('staff')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('fact_payment')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('address')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('address')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('film')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('dim_inventory')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('dim_film_actor')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('actor')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m22:23:53.478033 [debug] [ThreadPool]: SQL status: SELECT 202 in 0.005 seconds
[0m22:23:53.488545 [debug] [ThreadPool]: On data_warehouse.information_schema: ROLLBACK
[0m22:23:53.491054 [debug] [ThreadPool]: On data_warehouse.information_schema: Close
[0m22:23:53.533228 [info ] [MainThread]: Catalog written to C:\Users\new user\OneDrive\Learning Progress Review\Data Engineering\Project2\dbt\data_warehouse\target\catalog.json
[0m22:23:53.536269 [debug] [MainThread]: Command `dbt docs generate` succeeded at 22:23:53.536269 after 1.67 seconds
[0m22:23:53.536269 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m22:23:53.537315 [debug] [MainThread]: Connection 'data_warehouse.information_schema' was properly closed.
[0m22:23:53.537315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB7EB6900>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB7EB69F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AFB82CBD70>]}
[0m22:23:53.538556 [debug] [MainThread]: Flushing usage events
[0m22:24:08.136459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000254A0C9DDF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000254A0C9DF70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000254A0C9DD00>]}


============================== 22:24:08.140990 | 83c81066-3432-48c8-ab48-d5c9f92033a7 ==============================
[0m22:24:08.140990 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:24:08.141274 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse\\logs', 'profiles_dir': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt docs serve', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:24:08.340947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '83c81066-3432-48c8-ab48-d5c9f92033a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000254A0A54380>]}
[0m22:24:08.401819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '83c81066-3432-48c8-ab48-d5c9f92033a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000254A093A990>]}
[0m22:32:42.205192 [error] [MainThread]: Encountered an error:

[0m22:32:42.308801 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\new user\AppData\Local\Programs\Python\Python312\Lib\site-packages\dbt\cli\requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\new user\AppData\Local\Programs\Python\Python312\Lib\site-packages\dbt\cli\requires.py", line 101, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\new user\AppData\Local\Programs\Python\Python312\Lib\site-packages\dbt\cli\requires.py", line 218, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\new user\AppData\Local\Programs\Python\Python312\Lib\site-packages\dbt\cli\requires.py", line 247, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\new user\AppData\Local\Programs\Python\Python312\Lib\site-packages\dbt\cli\requires.py", line 294, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\new user\AppData\Local\Programs\Python\Python312\Lib\site-packages\dbt\cli\main.py", line 303, in docs_serve
    results = task.run()
              ^^^^^^^^^^
  File "C:\Users\new user\AppData\Local\Programs\Python\Python312\Lib\site-packages\dbt\task\docs\serve.py", line 29, in run
    httpd.serve_forever()
  File "C:\Users\new user\AppData\Local\Programs\Python\Python312\Lib\socketserver.py", line 240, in serve_forever
    self._handle_request_noblock()
  File "C:\Users\new user\AppData\Local\Programs\Python\Python312\Lib\socketserver.py", line 318, in _handle_request_noblock
    self.process_request(request, client_address)
  File "C:\Users\new user\AppData\Local\Programs\Python\Python312\Lib\socketserver.py", line 349, in process_request
    self.finish_request(request, client_address)
  File "C:\Users\new user\AppData\Local\Programs\Python\Python312\Lib\socketserver.py", line 362, in finish_request
    self.RequestHandlerClass(request, client_address, self)
  File "C:\Users\new user\AppData\Local\Programs\Python\Python312\Lib\http\server.py", line 672, in __init__
    super().__init__(*args, **kwargs)
  File "C:\Users\new user\AppData\Local\Programs\Python\Python312\Lib\socketserver.py", line 761, in __init__
    self.handle()
  File "C:\Users\new user\AppData\Local\Programs\Python\Python312\Lib\http\server.py", line 436, in handle
    self.handle_one_request()
  File "C:\Users\new user\AppData\Local\Programs\Python\Python312\Lib\http\server.py", line 404, in handle_one_request
    self.raw_requestline = self.rfile.readline(65537)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\new user\AppData\Local\Programs\Python\Python312\Lib\socket.py", line 707, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[0m22:32:42.314547 [debug] [MainThread]: Command `dbt docs serve` failed at 22:32:42.314547 after 514.28 seconds
[0m22:32:42.315465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000254A0A1D790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000254A0869670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000254A0FEF740>]}
[0m22:32:42.315465 [debug] [MainThread]: Flushing usage events
[0m22:32:50.313006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC762CF80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC762D5E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC762DA60>]}


============================== 22:32:50.313006 | f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a ==============================
[0m22:32:50.313006 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:32:50.313006 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m22:32:50.523498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC669BBC0>]}
[0m22:32:50.601834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC782A510>]}
[0m22:32:50.604359 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:32:50.605905 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:32:50.763505 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m22:32:50.763505 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\mart\best_film.sql
[0m22:32:51.027882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC78C67B0>]}
[0m22:32:51.135458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC8C663F0>]}
[0m22:32:51.135458 [info ] [MainThread]: Found 22 models, 4 data tests, 9 sources, 417 macros
[0m22:32:51.135458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC782A2D0>]}
[0m22:32:51.135458 [info ] [MainThread]: 
[0m22:32:51.135458 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:32:51.135458 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m22:32:51.202369 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:32:51.202369 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:32:51.202369 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:32:51.219077 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.017 seconds
[0m22:32:51.219077 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:32:51.219077 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:32:51.219077 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:32:51.228699 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:32:51.253036 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.029 seconds
[0m22:32:51.253036 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:32:51.253036 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:32:51.263363 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:32:51.263896 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:32:51.286179 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.026 seconds
[0m22:32:51.286179 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:32:51.292946 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:32:51.292946 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:32:51.294959 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:32:51.302494 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m22:32:51.304062 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:32:51.307629 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_raw'
[0m22:32:51.313002 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:32:51.313519 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m22:32:51.314070 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:32:51.336643 [debug] [ThreadPool]: SQL status: BEGIN in 0.027 seconds
[0m22:32:51.336643 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:32:51.336643 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m22:32:51.336643 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.005 seconds
[0m22:32:51.336643 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m22:32:51.336643 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m22:32:51.351173 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev_mart)
[0m22:32:51.355914 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m22:32:51.356478 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m22:32:51.357051 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:32:51.364232 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m22:32:51.364767 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m22:32:51.365317 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m22:32:51.369003 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m22:32:51.369003 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m22:32:51.369003 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m22:32:51.369003 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_intermediate)
[0m22:32:51.376146 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m22:32:51.376708 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: BEGIN
[0m22:32:51.377214 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:32:51.402302 [debug] [ThreadPool]: SQL status: BEGIN in 0.028 seconds
[0m22:32:51.402302 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m22:32:51.402302 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediate"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediate'
  
[0m22:32:51.402302 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:32:51.402302 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: ROLLBACK
[0m22:32:51.402302 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: Close
[0m22:32:51.402302 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediate, now list_data_warehouse_dbt_dev)
[0m22:32:51.418272 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:32:51.419353 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m22:32:51.419881 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:32:51.435252 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m22:32:51.435252 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:32:51.435252 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m22:32:51.435252 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m22:32:51.435252 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m22:32:51.435252 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m22:32:51.453665 [debug] [MainThread]: Using postgres connection "master"
[0m22:32:51.454795 [debug] [MainThread]: On master: BEGIN
[0m22:32:51.455325 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:32:51.468997 [debug] [MainThread]: SQL status: BEGIN in 0.019 seconds
[0m22:32:51.468997 [debug] [MainThread]: Using postgres connection "master"
[0m22:32:51.468997 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:32:51.485294 [debug] [MainThread]: SQL status: SELECT 38 in 0.010 seconds
[0m22:32:51.487942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC8C663C0>]}
[0m22:32:51.487942 [debug] [MainThread]: On master: ROLLBACK
[0m22:32:51.487942 [debug] [MainThread]: Using postgres connection "master"
[0m22:32:51.487942 [debug] [MainThread]: On master: BEGIN
[0m22:32:51.487942 [debug] [MainThread]: SQL status: BEGIN in 0.003 seconds
[0m22:32:51.487942 [debug] [MainThread]: On master: COMMIT
[0m22:32:51.487942 [debug] [MainThread]: Using postgres connection "master"
[0m22:32:51.487942 [debug] [MainThread]: On master: COMMIT
[0m22:32:51.487942 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:32:51.487942 [debug] [MainThread]: On master: Close
[0m22:32:51.487942 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:32:51.499903 [info ] [MainThread]: 
[0m22:32:51.505140 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m22:32:51.505705 [info ] [Thread-1 (]: 1 of 22 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m22:32:51.507365 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m22:32:51.507901 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m22:32:51.514202 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m22:32:51.517220 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m22:32:51.554299 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m22:32:51.554299 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:32:51.554299 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m22:32:51.554299 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:32:51.570131 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m22:32:51.570131 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:32:51.570131 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."actor"
  );
  
[0m22:32:51.570131 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.003 seconds
[0m22:32:51.585475 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:32:51.585475 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m22:32:51.585475 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:51.585475 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:32:51.585475 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m22:32:51.585475 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:32:51.602654 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m22:32:51.602654 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:32:51.602654 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m22:32:51.617867 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:32:51.619411 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m22:32:51.619411 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:32:51.619411 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m22:32:51.636294 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m22:32:51.636294 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m22:32:51.636294 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC5043EC0>]}
[0m22:32:51.636294 [info ] [Thread-1 (]: 1 of 22 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.13s]
[0m22:32:51.643327 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m22:32:51.643849 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m22:32:51.645077 [info ] [Thread-1 (]: 2 of 22 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m22:32:51.646136 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m22:32:51.647244 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m22:32:51.650209 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m22:32:51.652143 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m22:32:51.654567 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m22:32:51.654567 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:32:51.654567 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m22:32:51.654567 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:51.669585 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:32:51.669585 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:32:51.669585 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."address"
  );
  
[0m22:32:51.669585 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.003 seconds
[0m22:32:51.669585 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:32:51.669585 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m22:32:51.669585 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:51.669585 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:32:51.684394 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m22:32:51.685960 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:51.685960 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m22:32:51.685960 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:32:51.685960 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m22:32:51.685960 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:32:51.685960 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m22:32:51.685960 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:32:51.685960 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m22:32:51.703966 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:32:51.703966 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m22:32:51.703966 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC9166300>]}
[0m22:32:51.707894 [info ] [Thread-1 (]: 2 of 22 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.06s]
[0m22:32:51.707894 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m22:32:51.710603 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m22:32:51.711705 [info ] [Thread-1 (]: 3 of 22 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m22:32:51.712295 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m22:32:51.713351 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m22:32:51.717698 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m22:32:51.719309 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m22:32:51.723789 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m22:32:51.723789 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:32:51.723789 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m22:32:51.723789 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:51.736369 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:32:51.739017 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:32:51.739017 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."customer"
  );
  
[0m22:32:51.739017 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.003 seconds
[0m22:32:51.739017 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:32:51.739017 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m22:32:51.739017 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:32:51.752051 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:32:51.753054 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m22:32:51.753682 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:51.753682 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m22:32:51.753682 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:32:51.753682 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m22:32:51.753682 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:32:51.767914 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m22:32:51.769600 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:32:51.769600 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m22:32:51.772815 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:32:51.772815 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m22:32:51.772815 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC9325F10>]}
[0m22:32:51.772815 [info ] [Thread-1 (]: 3 of 22 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.06s]
[0m22:32:51.781280 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m22:32:51.781921 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m22:32:51.783401 [info ] [Thread-1 (]: 4 of 22 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m22:32:51.784955 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m22:32:51.785736 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m22:32:51.789041 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m22:32:51.790727 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m22:32:51.793991 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m22:32:51.795907 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:32:51.796910 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m22:32:51.797899 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:51.819647 [debug] [Thread-1 (]: SQL status: BEGIN in 0.027 seconds
[0m22:32:51.819647 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:32:51.819647 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."film"
  );
  
[0m22:32:51.835487 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.009 seconds
[0m22:32:51.836493 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:32:51.836493 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m22:32:51.836493 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:32:51.836493 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:32:51.836493 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m22:32:51.836493 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:51.836493 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m22:32:51.836493 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:32:51.850990 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m22:32:51.853123 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:32:51.853123 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m22:32:51.853123 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:32:51.853123 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m22:32:51.853123 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:32:51.868063 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m22:32:51.869090 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC921BDA0>]}
[0m22:32:51.870101 [info ] [Thread-1 (]: 4 of 22 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.08s]
[0m22:32:51.872327 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m22:32:51.872945 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m22:32:51.874117 [info ] [Thread-1 (]: 5 of 22 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m22:32:51.875245 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m22:32:51.875770 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m22:32:51.879203 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m22:32:51.880845 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m22:32:51.886351 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m22:32:51.887340 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:32:51.888271 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m22:32:51.889612 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:51.889612 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:32:51.889612 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:32:51.900889 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m22:32:51.901573 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.005 seconds
[0m22:32:51.901573 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:32:51.901573 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m22:32:51.901573 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:51.901573 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:32:51.901573 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m22:32:51.917702 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:51.919800 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m22:32:51.920798 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:32:51.922720 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m22:32:51.929501 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:32:51.931499 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m22:32:51.933054 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:32:51.933054 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m22:32:51.938159 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:32:51.939179 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m22:32:51.941094 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC932A990>]}
[0m22:32:51.941094 [info ] [Thread-1 (]: 5 of 22 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.06s]
[0m22:32:51.943093 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m22:32:51.944799 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m22:32:51.945961 [info ] [Thread-1 (]: 6 of 22 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m22:32:51.947108 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m22:32:51.947637 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m22:32:51.950681 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m22:32:51.952084 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m22:32:51.955072 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m22:32:51.955072 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:32:51.955072 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m22:32:51.955072 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:51.968191 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m22:32:51.968191 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:32:51.968191 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m22:32:51.968191 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m22:32:51.968191 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:32:51.968191 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m22:32:51.986196 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:51.986196 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:32:51.986196 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m22:32:51.986196 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:51.986196 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m22:32:51.986196 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:32:51.986196 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m22:32:51.986196 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:32:52.002092 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m22:32:52.003193 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:32:52.003193 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m22:32:52.003193 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:32:52.003193 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m22:32:52.003193 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC915BCB0>]}
[0m22:32:52.003193 [info ] [Thread-1 (]: 6 of 22 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.06s]
[0m22:32:52.003193 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m22:32:52.016031 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m22:32:52.016575 [info ] [Thread-1 (]: 7 of 22 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m22:32:52.017475 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m22:32:52.018618 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m22:32:52.022324 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m22:32:52.023612 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m22:32:52.026997 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m22:32:52.026997 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:32:52.026997 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m22:32:52.026997 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:52.052676 [debug] [Thread-1 (]: SQL status: BEGIN in 0.027 seconds
[0m22:32:52.052676 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:32:52.052676 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m22:32:52.052676 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.002 seconds
[0m22:32:52.052676 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:32:52.052676 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m22:32:52.068823 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:52.070464 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:32:52.070464 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m22:32:52.070464 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:52.070464 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m22:32:52.070464 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:32:52.070464 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m22:32:52.084658 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:32:52.130134 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m22:32:52.131045 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:32:52.131045 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m22:32:52.135091 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m22:32:52.135091 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m22:32:52.135091 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC93B1430>]}
[0m22:32:52.135091 [info ] [Thread-1 (]: 7 of 22 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.12s]
[0m22:32:52.143575 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m22:32:52.144699 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m22:32:52.145807 [info ] [Thread-1 (]: 8 of 22 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m22:32:52.146847 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m22:32:52.147493 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m22:32:52.151574 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m22:32:52.153188 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m22:32:52.154824 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m22:32:52.154824 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:32:52.154824 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m22:32:52.154824 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:52.168038 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m22:32:52.168038 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:32:52.168038 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."payment"
  );
  
[0m22:32:52.183241 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.009 seconds
[0m22:32:52.186518 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:32:52.186518 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m22:32:52.186518 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:52.186518 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:32:52.186518 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m22:32:52.186518 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:52.186518 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m22:32:52.186518 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:32:52.186518 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m22:32:52.202392 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:32:52.202392 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m22:32:52.202392 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:32:52.202392 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m22:32:52.202392 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:32:52.202392 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m22:32:52.217407 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC8ADD430>]}
[0m22:32:52.218375 [info ] [Thread-1 (]: 8 of 22 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.06s]
[0m22:32:52.219384 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m22:32:52.221434 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m22:32:52.222473 [info ] [Thread-1 (]: 9 of 22 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m22:32:52.223554 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m22:32:52.224660 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m22:32:52.228476 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m22:32:52.230127 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m22:32:52.231689 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m22:32:52.235888 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:32:52.237549 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m22:32:52.237549 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:52.253973 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m22:32:52.253973 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:32:52.253973 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."rental"
  );
  
[0m22:32:52.269559 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.010 seconds
[0m22:32:52.269559 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:32:52.269559 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m22:32:52.269559 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:52.269559 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:32:52.269559 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m22:32:52.269559 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:52.269559 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m22:32:52.269559 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:32:52.284409 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m22:32:52.295529 [debug] [Thread-1 (]: SQL status: COMMIT in 0.011 seconds
[0m22:32:52.297617 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m22:32:52.298600 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:32:52.299535 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m22:32:52.304162 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:32:52.305254 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m22:32:52.306254 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC93C16D0>]}
[0m22:32:52.308344 [info ] [Thread-1 (]: 9 of 22 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.08s]
[0m22:32:52.309349 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m22:32:52.310627 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m22:32:52.311761 [info ] [Thread-1 (]: 10 of 22 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m22:32:52.313291 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m22:32:52.313921 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m22:32:52.318571 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m22:32:52.320323 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m22:32:52.321478 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m22:32:52.321478 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:32:52.321478 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m22:32:52.321478 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:52.336220 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m22:32:52.336220 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:32:52.336220 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."staff"
  );
  
[0m22:32:52.336220 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.007 seconds
[0m22:32:52.352733 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:32:52.353716 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m22:32:52.356714 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:52.356933 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:32:52.356933 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m22:32:52.356933 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:52.356933 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m22:32:52.356933 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:32:52.356933 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m22:32:52.370796 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:32:52.370796 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m22:32:52.370796 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:32:52.370796 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m22:32:52.370796 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:32:52.384150 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m22:32:52.385158 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC92DB620>]}
[0m22:32:52.386801 [info ] [Thread-1 (]: 10 of 22 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.07s]
[0m22:32:52.389061 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m22:32:52.389620 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m22:32:52.391358 [info ] [Thread-1 (]: 11 of 22 START sql table model dbt_dev_intermediate.dim_actor .................. [RUN]
[0m22:32:52.392491 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m22:32:52.393569 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m22:32:52.396780 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m22:32:52.397903 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m22:32:52.402648 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m22:32:52.404653 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:32:52.405652 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m22:32:52.406659 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:52.417277 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m22:32:52.418285 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:32:52.419284 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m22:32:52.421111 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m22:32:52.421111 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:32:52.421111 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor" rename to "dim_actor__dbt_backup"
[0m22:32:52.421111 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:32:52.421111 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:32:52.421111 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m22:32:52.421111 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:32:52.436658 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m22:32:52.437346 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:32:52.437346 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m22:32:52.437346 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:32:52.437346 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup"
[0m22:32:52.437346 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:32:52.437346 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup" cascade
[0m22:32:52.451683 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:32:52.452683 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m22:32:52.453682 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC8AB2ED0>]}
[0m22:32:52.455110 [info ] [Thread-1 (]: 11 of 22 OK created sql table model dbt_dev_intermediate.dim_actor ............. [[32mSELECT 200[0m in 0.06s]
[0m22:32:52.457512 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m22:32:52.458582 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m22:32:52.459115 [info ] [Thread-1 (]: 12 of 22 START sql table model dbt_dev_intermediate.dim_address ................ [RUN]
[0m22:32:52.460735 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m22:32:52.461368 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m22:32:52.465497 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m22:32:52.466651 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m22:32:52.470028 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m22:32:52.470028 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:32:52.470028 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m22:32:52.470028 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:52.486364 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m22:32:52.486364 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:32:52.486364 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m22:32:52.486364 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m22:32:52.486364 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:32:52.486364 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address" rename to "dim_address__dbt_backup"
[0m22:32:52.501683 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:52.503299 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:32:52.503299 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp" rename to "dim_address"
[0m22:32:52.503299 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:52.503299 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m22:32:52.503299 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:32:52.503299 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m22:32:52.517587 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:32:52.519144 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup"
[0m22:32:52.519144 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:32:52.519144 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup" cascade
[0m22:32:52.519144 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:32:52.519144 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m22:32:52.519144 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC9287DD0>]}
[0m22:32:52.519144 [info ] [Thread-1 (]: 12 of 22 OK created sql table model dbt_dev_intermediate.dim_address ........... [[32mSELECT 603[0m in 0.06s]
[0m22:32:52.519144 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m22:32:52.534249 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m22:32:52.535391 [info ] [Thread-1 (]: 13 of 22 START sql table model dbt_dev_intermediate.dim_customer ............... [RUN]
[0m22:32:52.536579 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m22:32:52.537184 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m22:32:52.540776 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m22:32:52.541954 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m22:32:52.545857 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m22:32:52.546886 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:32:52.546886 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m22:32:52.547854 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:52.569645 [debug] [Thread-1 (]: SQL status: BEGIN in 0.028 seconds
[0m22:32:52.569645 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:32:52.569645 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m22:32:52.569645 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m22:32:52.569645 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:32:52.583912 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer" rename to "dim_customer__dbt_backup"
[0m22:32:52.586436 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:52.589434 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:32:52.590433 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m22:32:52.592432 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:52.594435 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m22:32:52.594435 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:32:52.595437 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m22:32:52.600989 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:32:52.603033 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup"
[0m22:32:52.605051 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:32:52.605051 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup" cascade
[0m22:32:52.607031 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:32:52.607031 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m22:32:52.607031 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC771B1D0>]}
[0m22:32:52.612911 [info ] [Thread-1 (]: 13 of 22 OK created sql table model dbt_dev_intermediate.dim_customer .......... [[32mSELECT 599[0m in 0.07s]
[0m22:32:52.612911 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m22:32:52.616063 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m22:32:52.617281 [info ] [Thread-1 (]: 14 of 22 START sql table model dbt_dev_intermediate.dim_film ................... [RUN]
[0m22:32:52.618206 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m22:32:52.619365 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m22:32:52.622695 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m22:32:52.624367 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m22:32:52.626746 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m22:32:52.626746 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:32:52.626746 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m22:32:52.626746 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:52.652778 [debug] [Thread-1 (]: SQL status: BEGIN in 0.030 seconds
[0m22:32:52.652778 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:32:52.652778 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m22:32:52.671283 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.009 seconds
[0m22:32:52.674284 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:32:52.675305 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film" rename to "dim_film__dbt_backup"
[0m22:32:52.677284 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:32:52.680284 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:32:52.681288 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp" rename to "dim_film"
[0m22:32:52.684078 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:52.688625 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m22:32:52.689627 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:32:52.690627 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m22:32:52.698628 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m22:32:52.701615 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup"
[0m22:32:52.702725 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:32:52.703613 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup" cascade
[0m22:32:52.708138 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:32:52.708138 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m22:32:52.708138 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC762F6E0>]}
[0m22:32:52.712436 [info ] [Thread-1 (]: 14 of 22 OK created sql table model dbt_dev_intermediate.dim_film .............. [[32mSELECT 1000[0m in 0.09s]
[0m22:32:52.715023 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m22:32:52.716670 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m22:32:52.717769 [info ] [Thread-1 (]: 15 of 22 START sql table model dbt_dev_intermediate.dim_film_actor ............. [RUN]
[0m22:32:52.718907 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m22:32:52.719957 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m22:32:52.724337 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m22:32:52.725959 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m22:32:52.726507 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m22:32:52.733772 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:32:52.734790 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m22:32:52.735794 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:52.746230 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m22:32:52.747950 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:32:52.747950 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m22:32:52.754811 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.006 seconds
[0m22:32:52.759186 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:32:52.760191 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m22:32:52.762193 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:52.768115 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:32:52.769040 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m22:32:52.771027 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:32:52.772645 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m22:32:52.772645 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:32:52.772645 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m22:32:52.772645 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:32:52.786311 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup"
[0m22:32:52.787322 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:32:52.788323 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup" cascade
[0m22:32:52.792789 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:32:52.792789 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m22:32:52.792789 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC8ADEFF0>]}
[0m22:32:52.792789 [info ] [Thread-1 (]: 15 of 22 OK created sql table model dbt_dev_intermediate.dim_film_actor ........ [[32mSELECT 5462[0m in 0.07s]
[0m22:32:52.807385 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m22:32:52.808383 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m22:32:52.809383 [info ] [Thread-1 (]: 16 of 22 START sql table model dbt_dev_intermediate.dim_inventory .............. [RUN]
[0m22:32:52.810384 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m22:32:52.810384 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m22:32:52.824998 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m22:32:52.835261 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m22:32:52.840391 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m22:32:52.842413 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:32:52.843400 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m22:32:52.844228 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:52.858813 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m22:32:52.858813 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:32:52.858813 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m22:32:52.870004 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m22:32:52.875010 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:32:52.876011 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m22:32:52.878011 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:52.882009 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:32:52.883009 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m22:32:52.885872 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:32:52.886205 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m22:32:52.886205 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:32:52.886205 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m22:32:52.886205 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:32:52.886205 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup"
[0m22:32:52.886205 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:32:52.886205 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup" cascade
[0m22:32:52.901108 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:32:52.901108 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m22:32:52.901108 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC9173590>]}
[0m22:32:52.901108 [info ] [Thread-1 (]: 16 of 22 OK created sql table model dbt_dev_intermediate.dim_inventory ......... [[32mSELECT 4581[0m in 0.09s]
[0m22:32:52.901108 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m22:32:52.910921 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m22:32:52.911441 [info ] [Thread-1 (]: 17 of 22 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m22:32:52.912502 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m22:32:52.913018 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m22:32:52.918050 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m22:32:52.919192 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m22:32:52.940214 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m22:32:52.942226 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:32:52.943231 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m22:32:52.944232 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:52.952845 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m22:32:52.952845 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:32:52.953862 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m22:32:52.956946 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m22:32:52.956946 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:32:52.956946 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m22:32:52.956946 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:32:52.956946 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m22:32:52.967166 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:32:52.967706 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m22:32:52.972111 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:32:52.975304 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m22:32:52.981156 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:32:52.981708 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m22:32:52.983647 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m22:32:52.985794 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m22:32:52.986800 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC8AABEC0>]}
[0m22:32:52.988821 [info ] [Thread-1 (]: 17 of 22 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.07s]
[0m22:32:52.990423 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m22:32:52.990966 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m22:32:52.992082 [info ] [Thread-1 (]: 18 of 22 START sql table model dbt_dev_intermediate.fact_payment ............... [RUN]
[0m22:32:52.993189 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m22:32:52.994297 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m22:32:52.998836 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m22:32:53.000354 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m22:32:53.004437 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m22:32:53.006442 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:32:53.007444 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m22:32:53.008451 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:53.034459 [debug] [Thread-1 (]: SQL status: BEGIN in 0.030 seconds
[0m22:32:53.034459 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:32:53.034459 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m22:32:53.050239 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.008 seconds
[0m22:32:53.050874 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:32:53.050874 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment" rename to "fact_payment__dbt_backup"
[0m22:32:53.050874 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:32:53.050874 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:32:53.050874 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m22:32:53.050874 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:32:53.050874 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m22:32:53.050874 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:32:53.050874 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m22:32:53.067664 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m22:32:53.067664 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup"
[0m22:32:53.067664 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:32:53.067664 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup" cascade
[0m22:32:53.067664 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m22:32:53.083913 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m22:32:53.085918 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC932FB00>]}
[0m22:32:53.087060 [info ] [Thread-1 (]: 18 of 22 OK created sql table model dbt_dev_intermediate.fact_payment .......... [[32mSELECT 14596[0m in 0.09s]
[0m22:32:53.088052 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m22:32:53.089048 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_film
[0m22:32:53.089796 [info ] [Thread-1 (]: 19 of 22 START sql table model dbt_dev_mart.best_film .......................... [RUN]
[0m22:32:53.090864 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.best_film)
[0m22:32:53.091395 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_film
[0m22:32:53.094954 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_film"
[0m22:32:53.097403 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_film
[0m22:32:53.102450 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.best_film"
[0m22:32:53.102450 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_film"
[0m22:32:53.102450 [debug] [Thread-1 (]: On model.data_warehouse.best_film: BEGIN
[0m22:32:53.102450 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:53.117853 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m22:32:53.117853 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_film"
[0m22:32:53.117853 [debug] [Thread-1 (]: On model.data_warehouse.best_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."best_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    f.title AS film_title,
    COUNT(r.rental_id) AS rental_count
FROM 
    "data_warehouse"."dbt_dev_raw"."film" f
JOIN 
    "data_warehouse"."dbt_dev_raw"."inventory" i ON f.film_id = i.film_id
JOIN 
    "data_warehouse"."dbt_dev_raw"."rental" r ON i.inventory_id = r.inventory_id
GROUP BY 
    f.title
ORDER BY 
    rental_count DESC
LIMIT 1;
  );
  
[0m22:32:53.117853 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 27: LIMIT 1;
                ^

[0m22:32:53.117853 [debug] [Thread-1 (]: On model.data_warehouse.best_film: ROLLBACK
[0m22:32:53.117853 [debug] [Thread-1 (]: On model.data_warehouse.best_film: Close
[0m22:32:53.201212 [debug] [Thread-1 (]: Database Error in model best_film (models\mart\best_film.sql)
  syntax error at or near ";"
  LINE 27: LIMIT 1;
                  ^
  compiled Code at target\run\data_warehouse\models\mart\best_film.sql
[0m22:32:53.201212 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC77AAE70>]}
[0m22:32:53.201212 [error] [Thread-1 (]: 19 of 22 ERROR creating sql table model dbt_dev_mart.best_film ................. [[31mERROR[0m in 0.11s]
[0m22:32:53.201212 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_film
[0m22:32:53.201212 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m22:32:53.201212 [info ] [Thread-1 (]: 20 of 22 START sql table model dbt_dev_intermediate.dim_rental ................. [RUN]
[0m22:32:53.201212 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.best_film, now model.data_warehouse.dim_rental)
[0m22:32:53.216705 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m22:32:53.221820 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m22:32:53.222810 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m22:32:53.226723 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m22:32:53.227745 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:32:53.228758 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m22:32:53.229757 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:53.250971 [debug] [Thread-1 (]: SQL status: BEGIN in 0.028 seconds
[0m22:32:53.250971 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:32:53.250971 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m22:32:53.268849 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.010 seconds
[0m22:32:53.268849 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:32:53.268849 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental" rename to "dim_rental__dbt_backup"
[0m22:32:53.268849 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:32:53.268849 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:32:53.268849 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m22:32:53.268849 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:32:53.268849 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m22:32:53.268849 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:32:53.283514 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m22:32:53.285750 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m22:32:53.285750 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup"
[0m22:32:53.285750 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:32:53.285750 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup" cascade
[0m22:32:53.301634 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:32:53.303641 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m22:32:53.304642 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC76A8800>]}
[0m22:32:53.305655 [info ] [Thread-1 (]: 20 of 22 OK created sql table model dbt_dev_intermediate.dim_rental ............ [[32mSELECT 16044[0m in 0.10s]
[0m22:32:53.306646 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m22:32:53.308163 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m22:32:53.309218 [info ] [Thread-1 (]: 21 of 22 START sql table model dbt_dev_intermediate.dim_staff .................. [RUN]
[0m22:32:53.310297 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m22:32:53.310842 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m22:32:53.314018 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m22:32:53.315303 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m22:32:53.319539 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m22:32:53.319539 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:32:53.319539 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m22:32:53.319539 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:53.334601 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m22:32:53.334601 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:32:53.334601 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m22:32:53.334601 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.006 seconds
[0m22:32:53.351085 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:32:53.351810 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff" rename to "dim_staff__dbt_backup"
[0m22:32:53.351810 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:32:53.351810 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:32:53.351810 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m22:32:53.351810 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:32:53.351810 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m22:32:53.351810 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:32:53.351810 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m22:32:53.367023 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:32:53.368365 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup"
[0m22:32:53.368365 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:32:53.368365 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup" cascade
[0m22:32:53.368365 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:32:53.368365 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m22:32:53.368365 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC930BAA0>]}
[0m22:32:53.368365 [info ] [Thread-1 (]: 21 of 22 OK created sql table model dbt_dev_intermediate.dim_staff ............. [[32mSELECT 2[0m in 0.06s]
[0m22:32:53.368365 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m22:32:53.382686 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m22:32:53.383469 [info ] [Thread-1 (]: 22 of 22 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m22:32:53.385019 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.total_revenue)
[0m22:32:53.385019 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m22:32:53.388430 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m22:32:53.390119 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m22:32:53.395359 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m22:32:53.397359 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:32:53.398363 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m22:32:53.399362 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:32:53.406708 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:32:53.406708 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:32:53.406708 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    sum(amount) as total_revenue,
    payment_date
FROM
    "data_warehouse"."dbt_dev_intermediate"."fact_payment"
GROUP BY
    payment_date
  );
  
[0m22:32:53.441739 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.029 seconds
[0m22:32:53.446119 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:32:53.447005 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m22:32:53.449022 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:32:53.452311 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:32:53.453395 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m22:32:53.456689 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:32:53.457193 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m22:32:53.457193 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:32:53.457193 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m22:32:53.468775 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:32:53.470763 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m22:32:53.471845 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:32:53.472771 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m22:32:53.474665 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:32:53.474665 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m22:32:53.474665 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f19e135b-a318-4ac2-b7e7-5fcf8bb6b02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC8A929F0>]}
[0m22:32:53.474665 [info ] [Thread-1 (]: 22 of 22 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.09s]
[0m22:32:53.484466 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m22:32:53.486831 [debug] [MainThread]: Using postgres connection "master"
[0m22:32:53.487365 [debug] [MainThread]: On master: BEGIN
[0m22:32:53.488423 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:32:53.499673 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m22:32:53.499946 [debug] [MainThread]: On master: COMMIT
[0m22:32:53.500538 [debug] [MainThread]: Using postgres connection "master"
[0m22:32:53.501613 [debug] [MainThread]: On master: COMMIT
[0m22:32:53.503238 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:32:53.503768 [debug] [MainThread]: On master: Close
[0m22:32:53.504295 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:32:53.505300 [debug] [MainThread]: Connection 'list_data_warehouse' was properly closed.
[0m22:32:53.506304 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev' was properly closed.
[0m22:32:53.507311 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m22:32:53.508577 [info ] [MainThread]: 
[0m22:32:53.509662 [info ] [MainThread]: Finished running 21 table models, 1 view model in 0 hours 0 minutes and 2.37 seconds (2.37s).
[0m22:32:53.510472 [debug] [MainThread]: Command end result
[0m22:32:53.577983 [info ] [MainThread]: 
[0m22:32:53.577983 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:32:53.577983 [info ] [MainThread]: 
[0m22:32:53.577983 [error] [MainThread]:   Database Error in model best_film (models\mart\best_film.sql)
  syntax error at or near ";"
  LINE 27: LIMIT 1;
                  ^
  compiled Code at target\run\data_warehouse\models\mart\best_film.sql
[0m22:32:53.577983 [info ] [MainThread]: 
[0m22:32:53.583603 [info ] [MainThread]: Done. PASS=21 WARN=0 ERROR=1 SKIP=0 TOTAL=22
[0m22:32:53.586089 [debug] [MainThread]: Command `dbt run` failed at 22:32:53.586089 after 3.38 seconds
[0m22:32:53.587109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC698D4F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC72A5AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026FC78C7620>]}
[0m22:32:54.850110 [debug] [MainThread]: Flushing usage events
[0m22:33:22.472477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258E49DE270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EA8DBBC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EA6792B0>]}


============================== 22:33:22.488114 | ab8d9e08-0dcc-469e-b66a-66728607e515 ==============================
[0m22:33:22.488114 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:33:22.488114 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse', 'log_path': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:33:22.676929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EA7F9C70>]}
[0m22:33:22.739515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EACFDF10>]}
[0m22:33:22.739515 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:33:22.748059 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:33:22.907732 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:33:22.907732 [debug] [MainThread]: Partial parsing: updated file: data_warehouse://models\mart\best_film.sql
[0m22:33:23.165638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EC176660>]}
[0m22:33:23.276735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EC186630>]}
[0m22:33:23.276735 [info ] [MainThread]: Found 22 models, 4 data tests, 9 sources, 417 macros
[0m22:33:23.276735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EC17B1A0>]}
[0m22:33:23.276735 [info ] [MainThread]: 
[0m22:33:23.276735 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:33:23.276735 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m22:33:23.354687 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:33:23.355682 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:33:23.355682 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:33:23.369805 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.014 seconds
[0m22:33:23.371823 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:33:23.374828 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:33:23.375538 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:33:23.376117 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:33:23.383841 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m22:33:23.384924 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:33:23.387150 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:33:23.388917 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:33:23.389578 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:33:23.396587 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m22:33:23.397659 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:33:23.400386 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:33:23.402029 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:33:23.402533 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:33:23.409451 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m22:33:23.411100 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:33:23.414761 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev'
[0m22:33:23.420356 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:33:23.420913 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m22:33:23.421457 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:33:23.441049 [debug] [ThreadPool]: SQL status: BEGIN in 0.027 seconds
[0m22:33:23.441049 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:33:23.441049 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m22:33:23.449564 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m22:33:23.449564 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m22:33:23.449564 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m22:33:23.458911 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_intermediate)
[0m22:33:23.463927 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m22:33:23.463927 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: BEGIN
[0m22:33:23.465051 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:33:23.489022 [debug] [ThreadPool]: SQL status: BEGIN in 0.031 seconds
[0m22:33:23.489022 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m22:33:23.489022 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediate"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediate'
  
[0m22:33:23.489022 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.004 seconds
[0m22:33:23.489022 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: ROLLBACK
[0m22:33:23.504461 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: Close
[0m22:33:23.504461 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediate, now list_data_warehouse_dbt_dev_mart)
[0m22:33:23.509620 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m22:33:23.509620 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m22:33:23.509620 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:33:23.520316 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m22:33:23.520316 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m22:33:23.520316 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m22:33:23.520316 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m22:33:23.520316 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m22:33:23.520316 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m22:33:23.520316 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_raw)
[0m22:33:23.538644 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:33:23.539391 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m22:33:23.540038 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:33:23.552545 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m22:33:23.552545 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:33:23.552545 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m22:33:23.552545 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:33:23.552545 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m22:33:23.552545 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m22:33:23.571971 [debug] [MainThread]: Using postgres connection "master"
[0m22:33:23.572590 [debug] [MainThread]: On master: BEGIN
[0m22:33:23.573175 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:33:23.579042 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m22:33:23.579042 [debug] [MainThread]: Using postgres connection "master"
[0m22:33:23.579042 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:33:23.583547 [debug] [MainThread]: SQL status: SELECT 38 in 0.008 seconds
[0m22:33:23.583547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EC1CE3C0>]}
[0m22:33:23.583547 [debug] [MainThread]: On master: ROLLBACK
[0m22:33:23.583547 [debug] [MainThread]: Using postgres connection "master"
[0m22:33:23.583547 [debug] [MainThread]: On master: BEGIN
[0m22:33:23.599181 [debug] [MainThread]: SQL status: BEGIN in 0.002 seconds
[0m22:33:23.599181 [debug] [MainThread]: On master: COMMIT
[0m22:33:23.599181 [debug] [MainThread]: Using postgres connection "master"
[0m22:33:23.599181 [debug] [MainThread]: On master: COMMIT
[0m22:33:23.599181 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:33:23.599181 [debug] [MainThread]: On master: Close
[0m22:33:23.599181 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:33:23.606433 [info ] [MainThread]: 
[0m22:33:23.611433 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m22:33:23.611962 [info ] [Thread-1 (]: 1 of 22 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m22:33:23.613623 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m22:33:23.614108 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m22:33:23.621310 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m22:33:23.621310 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m22:33:23.652110 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m22:33:23.652110 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:33:23.652110 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m22:33:23.652110 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:33:23.670178 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m22:33:23.670178 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:33:23.670178 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."actor"
  );
  
[0m22:33:23.670178 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.003 seconds
[0m22:33:23.686816 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:33:23.687710 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m22:33:23.689701 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:23.692788 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:33:23.692788 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m22:33:23.695702 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:23.712216 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m22:33:23.713241 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:33:23.715141 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m22:33:23.716927 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:33:23.716927 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m22:33:23.716927 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:33:23.732026 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m22:33:23.732026 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:33:23.732026 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m22:33:23.740946 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258E859C110>]}
[0m22:33:23.740946 [info ] [Thread-1 (]: 1 of 22 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.12s]
[0m22:33:23.743486 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m22:33:23.744594 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m22:33:23.745729 [info ] [Thread-1 (]: 2 of 22 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m22:33:23.746828 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m22:33:23.747480 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m22:33:23.750837 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m22:33:23.752062 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m22:33:23.754992 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m22:33:23.754992 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:33:23.754992 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m22:33:23.754992 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:23.768631 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:33:23.768631 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:33:23.768631 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."address"
  );
  
[0m22:33:23.768631 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.003 seconds
[0m22:33:23.768631 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:33:23.768631 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m22:33:23.768631 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:23.785611 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:33:23.785611 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m22:33:23.785611 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:23.785611 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m22:33:23.785611 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:33:23.785611 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m22:33:23.785611 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m22:33:23.801429 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m22:33:23.801429 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:33:23.801429 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m22:33:23.801429 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:33:23.801429 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m22:33:23.801429 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EC7CDAC0>]}
[0m22:33:23.801429 [info ] [Thread-1 (]: 2 of 22 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m22:33:23.817565 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m22:33:23.818648 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m22:33:23.819849 [info ] [Thread-1 (]: 3 of 22 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m22:33:23.821452 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m22:33:23.822100 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m22:33:23.826303 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m22:33:23.827986 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m22:33:23.832560 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m22:33:23.834590 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:33:23.835630 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m22:33:23.836634 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:23.846531 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:33:23.846531 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:33:23.847555 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."customer"
  );
  
[0m22:33:23.851756 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.003 seconds
[0m22:33:23.851756 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:33:23.851756 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m22:33:23.851756 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:23.851756 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:33:23.851756 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m22:33:23.851756 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:23.851756 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m22:33:23.851756 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:33:23.866738 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m22:33:23.868746 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:33:23.868746 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m22:33:23.868746 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:33:23.868746 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m22:33:23.868746 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:33:23.868746 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m22:33:23.884071 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EC838620>]}
[0m22:33:23.885201 [info ] [Thread-1 (]: 3 of 22 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.06s]
[0m22:33:23.887166 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m22:33:23.888482 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m22:33:23.889095 [info ] [Thread-1 (]: 4 of 22 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m22:33:23.890714 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m22:33:23.891252 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m22:33:23.894168 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m22:33:23.895384 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m22:33:23.899829 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m22:33:23.901831 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:33:23.902105 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m22:33:23.902105 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:23.917878 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m22:33:23.917878 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:33:23.917878 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."film"
  );
  
[0m22:33:23.934311 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.010 seconds
[0m22:33:23.935176 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:33:23.935176 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m22:33:23.935176 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:23.935176 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:33:23.935176 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m22:33:23.935176 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:23.935176 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m22:33:23.935176 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:33:23.950085 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m22:33:23.952016 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m22:33:23.952016 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m22:33:23.952016 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:33:23.952016 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m22:33:23.967003 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:33:23.968090 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m22:33:23.970040 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EC72AC30>]}
[0m22:33:23.971043 [info ] [Thread-1 (]: 4 of 22 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.08s]
[0m22:33:23.972044 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m22:33:23.973106 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m22:33:23.974182 [info ] [Thread-1 (]: 5 of 22 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m22:33:23.975297 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m22:33:23.976399 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m22:33:23.979342 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m22:33:23.980596 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m22:33:23.985215 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m22:33:23.985215 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:33:23.985215 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m22:33:23.985215 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:24.000999 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m22:33:24.000999 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:33:24.000999 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m22:33:24.000999 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m22:33:24.016618 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:33:24.016618 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m22:33:24.019625 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.021624 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:33:24.022624 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m22:33:24.024629 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.026721 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m22:33:24.027627 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:33:24.027627 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m22:33:24.033829 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:33:24.035836 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m22:33:24.036847 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:33:24.037848 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m22:33:24.042700 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:33:24.043791 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m22:33:24.044808 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EC739CD0>]}
[0m22:33:24.046151 [info ] [Thread-1 (]: 5 of 22 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.07s]
[0m22:33:24.048159 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m22:33:24.048938 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m22:33:24.050006 [info ] [Thread-1 (]: 6 of 22 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m22:33:24.051171 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m22:33:24.052303 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m22:33:24.055530 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m22:33:24.056788 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m22:33:24.060597 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m22:33:24.061831 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:33:24.063062 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m22:33:24.064026 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:24.068669 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m22:33:24.068669 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:33:24.068669 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m22:33:24.068669 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m22:33:24.068669 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:33:24.083733 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m22:33:24.086764 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.088849 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:33:24.089857 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m22:33:24.092014 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.094005 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m22:33:24.095019 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:33:24.096009 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m22:33:24.102648 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:33:24.104672 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m22:33:24.105676 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:33:24.106651 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m22:33:24.111651 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:33:24.112766 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m22:33:24.114689 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EC1761B0>]}
[0m22:33:24.114689 [info ] [Thread-1 (]: 6 of 22 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.06s]
[0m22:33:24.116958 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m22:33:24.118179 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m22:33:24.118721 [info ] [Thread-1 (]: 7 of 22 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m22:33:24.119760 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m22:33:24.120737 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m22:33:24.123735 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m22:33:24.124734 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m22:33:24.128734 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m22:33:24.130729 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:33:24.130729 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m22:33:24.131733 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:24.151660 [debug] [Thread-1 (]: SQL status: BEGIN in 0.025 seconds
[0m22:33:24.151660 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:33:24.151660 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m22:33:24.151660 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.002 seconds
[0m22:33:24.151660 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:33:24.151660 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m22:33:24.167107 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.168537 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:33:24.168537 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m22:33:24.168537 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.168537 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m22:33:24.168537 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:33:24.168537 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m22:33:24.168537 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:33:24.225636 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m22:33:24.226637 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:33:24.227635 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m22:33:24.233341 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:33:24.233341 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m22:33:24.233341 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258ECCD5970>]}
[0m22:33:24.233341 [info ] [Thread-1 (]: 7 of 22 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.11s]
[0m22:33:24.239235 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m22:33:24.239829 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m22:33:24.240879 [info ] [Thread-1 (]: 8 of 22 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m22:33:24.242026 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m22:33:24.243253 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m22:33:24.246637 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m22:33:24.247696 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m22:33:24.251342 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m22:33:24.251342 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:33:24.251342 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m22:33:24.251342 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:24.269247 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m22:33:24.269247 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:33:24.269247 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."payment"
  );
  
[0m22:33:24.283182 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.007 seconds
[0m22:33:24.285530 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:33:24.285530 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m22:33:24.285530 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.285530 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:33:24.285530 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m22:33:24.285530 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.285530 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m22:33:24.285530 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:33:24.299921 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m22:33:24.301620 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m22:33:24.301620 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m22:33:24.301620 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:33:24.301620 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m22:33:24.317399 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:33:24.319404 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m22:33:24.320405 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258E9D1A9F0>]}
[0m22:33:24.321500 [info ] [Thread-1 (]: 8 of 22 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.08s]
[0m22:33:24.323322 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m22:33:24.323830 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m22:33:24.325033 [info ] [Thread-1 (]: 9 of 22 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m22:33:24.326073 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m22:33:24.327207 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m22:33:24.331092 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m22:33:24.332794 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m22:33:24.335694 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m22:33:24.335694 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:33:24.335694 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m22:33:24.335694 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:24.350939 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m22:33:24.350939 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:33:24.350939 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."rental"
  );
  
[0m22:33:24.366308 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.008 seconds
[0m22:33:24.368432 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:33:24.368432 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m22:33:24.368432 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.368432 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:33:24.368432 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m22:33:24.378468 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.378468 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m22:33:24.378468 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:33:24.383098 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m22:33:24.385035 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:33:24.385035 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m22:33:24.385035 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:33:24.385035 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m22:33:24.385035 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:33:24.400062 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m22:33:24.401101 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EACFC1D0>]}
[0m22:33:24.402097 [info ] [Thread-1 (]: 9 of 22 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.08s]
[0m22:33:24.404100 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m22:33:24.404100 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m22:33:24.405769 [info ] [Thread-1 (]: 10 of 22 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m22:33:24.406823 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m22:33:24.407360 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m22:33:24.411242 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m22:33:24.413070 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m22:33:24.416479 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m22:33:24.418105 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:33:24.418105 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m22:33:24.418105 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:24.418105 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m22:33:24.418105 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:33:24.418105 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."staff"
  );
  
[0m22:33:24.433528 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.006 seconds
[0m22:33:24.433528 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:33:24.433528 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m22:33:24.433528 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:33:24.433528 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:33:24.433528 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m22:33:24.433528 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:33:24.449723 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m22:33:24.449723 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:33:24.451811 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m22:33:24.451811 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:33:24.451811 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m22:33:24.451811 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:33:24.451811 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m22:33:24.451811 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:33:24.466558 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m22:33:24.467574 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EC8517C0>]}
[0m22:33:24.468684 [info ] [Thread-1 (]: 10 of 22 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.06s]
[0m22:33:24.468684 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m22:33:24.471721 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m22:33:24.472867 [info ] [Thread-1 (]: 11 of 22 START sql table model dbt_dev_intermediate.dim_actor .................. [RUN]
[0m22:33:24.473911 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m22:33:24.474970 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m22:33:24.477625 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m22:33:24.478868 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m22:33:24.483119 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m22:33:24.485336 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:33:24.485336 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m22:33:24.485336 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:24.501652 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m22:33:24.501652 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:33:24.501652 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m22:33:24.501652 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m22:33:24.501652 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:33:24.501652 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor" rename to "dim_actor__dbt_backup"
[0m22:33:24.501652 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:33:24.518191 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:33:24.518191 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m22:33:24.518191 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.518191 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m22:33:24.518191 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:33:24.518191 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m22:33:24.518191 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:33:24.518191 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup"
[0m22:33:24.518191 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:33:24.533032 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup" cascade
[0m22:33:24.534912 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:33:24.534912 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m22:33:24.534912 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EBFEFEF0>]}
[0m22:33:24.540796 [info ] [Thread-1 (]: 11 of 22 OK created sql table model dbt_dev_intermediate.dim_actor ............. [[32mSELECT 200[0m in 0.06s]
[0m22:33:24.540796 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m22:33:24.543457 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m22:33:24.544547 [info ] [Thread-1 (]: 12 of 22 START sql table model dbt_dev_intermediate.dim_address ................ [RUN]
[0m22:33:24.545619 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m22:33:24.546157 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m22:33:24.550261 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m22:33:24.551540 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m22:33:24.554432 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m22:33:24.554432 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:33:24.554432 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m22:33:24.554432 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:24.567633 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m22:33:24.568538 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:33:24.568538 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m22:33:24.568538 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.003 seconds
[0m22:33:24.568538 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:33:24.568538 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address" rename to "dim_address__dbt_backup"
[0m22:33:24.568538 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.568538 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:33:24.583122 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp" rename to "dim_address"
[0m22:33:24.585483 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.586387 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m22:33:24.586387 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:33:24.586387 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m22:33:24.586387 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:33:24.586387 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup"
[0m22:33:24.586387 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:33:24.586387 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup" cascade
[0m22:33:24.601431 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:33:24.601431 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m22:33:24.601431 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258E802ED20>]}
[0m22:33:24.601431 [info ] [Thread-1 (]: 12 of 22 OK created sql table model dbt_dev_intermediate.dim_address ........... [[32mSELECT 603[0m in 0.06s]
[0m22:33:24.601431 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m22:33:24.608422 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m22:33:24.609478 [info ] [Thread-1 (]: 13 of 22 START sql table model dbt_dev_intermediate.dim_customer ............... [RUN]
[0m22:33:24.610849 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m22:33:24.611482 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m22:33:24.614890 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m22:33:24.616660 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m22:33:24.619859 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m22:33:24.619859 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:33:24.619859 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m22:33:24.619859 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:24.634817 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m22:33:24.634817 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:33:24.634817 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m22:33:24.634817 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.003 seconds
[0m22:33:24.634817 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:33:24.634817 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer" rename to "dim_customer__dbt_backup"
[0m22:33:24.650191 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.651663 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:33:24.651663 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m22:33:24.651663 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.651663 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m22:33:24.651663 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:33:24.651663 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m22:33:24.651663 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:33:24.651663 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup"
[0m22:33:24.667411 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:33:24.667411 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup" cascade
[0m22:33:24.668583 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:33:24.668583 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m22:33:24.668583 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EC7A1760>]}
[0m22:33:24.675857 [info ] [Thread-1 (]: 13 of 22 OK created sql table model dbt_dev_intermediate.dim_customer .......... [[32mSELECT 599[0m in 0.06s]
[0m22:33:24.675857 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m22:33:24.675857 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m22:33:24.679288 [info ] [Thread-1 (]: 14 of 22 START sql table model dbt_dev_intermediate.dim_film ................... [RUN]
[0m22:33:24.680072 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m22:33:24.681133 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m22:33:24.685213 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m22:33:24.687159 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m22:33:24.689960 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m22:33:24.689960 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:33:24.689960 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m22:33:24.689960 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:24.700956 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m22:33:24.700956 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:33:24.700956 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m22:33:24.700956 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m22:33:24.718541 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:33:24.718541 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film" rename to "dim_film__dbt_backup"
[0m22:33:24.718541 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:33:24.718541 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:33:24.718541 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp" rename to "dim_film"
[0m22:33:24.718541 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:33:24.718541 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m22:33:24.718541 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:33:24.718541 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m22:33:24.734694 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:33:24.734694 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup"
[0m22:33:24.734694 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:33:24.734694 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup" cascade
[0m22:33:24.734694 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:33:24.734694 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m22:33:24.749803 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EAC32840>]}
[0m22:33:24.750877 [info ] [Thread-1 (]: 14 of 22 OK created sql table model dbt_dev_intermediate.dim_film .............. [[32mSELECT 1000[0m in 0.05s]
[0m22:33:24.752900 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m22:33:24.753550 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m22:33:24.754734 [info ] [Thread-1 (]: 15 of 22 START sql table model dbt_dev_intermediate.dim_film_actor ............. [RUN]
[0m22:33:24.755943 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m22:33:24.756571 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m22:33:24.759803 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m22:33:24.760886 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m22:33:24.764203 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m22:33:24.765208 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:33:24.767212 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m22:33:24.768223 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:24.770832 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:33:24.770832 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:33:24.770832 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m22:33:24.783557 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m22:33:24.783557 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:33:24.783557 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m22:33:24.783557 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.783557 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:33:24.783557 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m22:33:24.783557 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.783557 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m22:33:24.783557 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:33:24.783557 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m22:33:24.803846 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:33:24.803846 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup"
[0m22:33:24.803846 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:33:24.803846 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup" cascade
[0m22:33:24.803846 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:33:24.803846 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m22:33:24.803846 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EABA4260>]}
[0m22:33:24.817083 [info ] [Thread-1 (]: 15 of 22 OK created sql table model dbt_dev_intermediate.dim_film_actor ........ [[32mSELECT 5462[0m in 0.05s]
[0m22:33:24.819411 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m22:33:24.820505 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m22:33:24.821040 [info ] [Thread-1 (]: 16 of 22 START sql table model dbt_dev_intermediate.dim_inventory .............. [RUN]
[0m22:33:24.822178 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m22:33:24.823344 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m22:33:24.826999 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m22:33:24.828141 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m22:33:24.830300 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m22:33:24.832952 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:33:24.833411 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m22:33:24.834418 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:24.836634 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:33:24.836634 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:33:24.836634 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m22:33:24.850537 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m22:33:24.852041 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:33:24.852041 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m22:33:24.852041 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.852041 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:33:24.852041 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m22:33:24.852041 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:24.852041 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m22:33:24.852041 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:33:24.866474 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m22:33:24.870006 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:33:24.873114 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup"
[0m22:33:24.874007 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:33:24.874007 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup" cascade
[0m22:33:24.878861 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:33:24.879943 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m22:33:24.880958 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EC825D30>]}
[0m22:33:24.882495 [info ] [Thread-1 (]: 16 of 22 OK created sql table model dbt_dev_intermediate.dim_inventory ......... [[32mSELECT 4581[0m in 0.06s]
[0m22:33:24.884138 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m22:33:24.884734 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m22:33:24.885794 [info ] [Thread-1 (]: 17 of 22 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m22:33:24.887532 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m22:33:24.888134 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m22:33:24.892231 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m22:33:24.893393 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m22:33:24.902505 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m22:33:24.902505 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:33:24.902505 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m22:33:24.914298 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:24.917568 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:33:24.917568 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:33:24.917568 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m22:33:24.917568 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m22:33:24.917568 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:33:24.917568 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m22:33:24.932869 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:33:24.935511 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m22:33:24.935511 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:33:24.935511 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m22:33:24.938455 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:33:24.938455 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m22:33:24.938455 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:33:24.938455 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m22:33:24.938455 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m22:33:24.950408 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m22:33:24.951668 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EC85E4E0>]}
[0m22:33:24.951668 [info ] [Thread-1 (]: 17 of 22 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.06s]
[0m22:33:24.954300 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m22:33:24.955971 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m22:33:24.957101 [info ] [Thread-1 (]: 18 of 22 START sql table model dbt_dev_intermediate.fact_payment ............... [RUN]
[0m22:33:24.958147 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m22:33:24.958740 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m22:33:24.961952 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m22:33:24.963059 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m22:33:24.968411 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m22:33:24.968411 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:33:24.968411 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m22:33:24.968411 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:24.968411 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m22:33:24.968411 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:33:24.968411 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m22:33:24.989581 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.008 seconds
[0m22:33:24.993090 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:33:24.993090 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment" rename to "fact_payment__dbt_backup"
[0m22:33:24.993090 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:33:24.999355 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:33:25.000493 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m22:33:25.002216 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:33:25.002216 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m22:33:25.002216 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:33:25.002216 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m22:33:25.002216 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:33:25.002216 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup"
[0m22:33:25.016066 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:33:25.017733 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup" cascade
[0m22:33:25.022884 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:33:25.024054 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m22:33:25.025781 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258ECCF0CB0>]}
[0m22:33:25.026896 [info ] [Thread-1 (]: 18 of 22 OK created sql table model dbt_dev_intermediate.fact_payment .......... [[32mSELECT 14596[0m in 0.07s]
[0m22:33:25.028116 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m22:33:25.028740 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_film
[0m22:33:25.029893 [info ] [Thread-1 (]: 19 of 22 START sql table model dbt_dev_mart.best_film .......................... [RUN]
[0m22:33:25.030978 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.best_film)
[0m22:33:25.031483 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_film
[0m22:33:25.036595 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_film"
[0m22:33:25.038394 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_film
[0m22:33:25.042348 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.best_film"
[0m22:33:25.043552 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_film"
[0m22:33:25.044624 [debug] [Thread-1 (]: On model.data_warehouse.best_film: BEGIN
[0m22:33:25.045226 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:25.051802 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m22:33:25.051802 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_film"
[0m22:33:25.051802 [debug] [Thread-1 (]: On model.data_warehouse.best_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."best_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    f.title AS film_title,
    COUNT(r.rental_id) AS rental_count
FROM 
    "data_warehouse"."dbt_dev_raw"."film" f
JOIN 
    "data_warehouse"."dbt_dev_raw"."inventory" i ON f.film_id = i.film_id
JOIN 
    "data_warehouse"."dbt_dev_raw"."rental" r ON i.inventory_id = r.inventory_id
GROUP BY 
    f.title
ORDER BY 
    rental_count DESC
LIMIT 1
  );
  
[0m22:33:25.067425 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.012 seconds
[0m22:33:25.068615 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_film"
[0m22:33:25.068615 [debug] [Thread-1 (]: On model.data_warehouse.best_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_film"} */
alter table "data_warehouse"."dbt_dev_mart"."best_film__dbt_tmp" rename to "best_film"
[0m22:33:25.068615 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:33:25.068615 [debug] [Thread-1 (]: On model.data_warehouse.best_film: COMMIT
[0m22:33:25.068615 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_film"
[0m22:33:25.068615 [debug] [Thread-1 (]: On model.data_warehouse.best_film: COMMIT
[0m22:33:25.068615 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:33:25.084315 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."best_film__dbt_backup"
[0m22:33:25.084315 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_film"
[0m22:33:25.084315 [debug] [Thread-1 (]: On model.data_warehouse.best_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_film"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."best_film__dbt_backup" cascade
[0m22:33:25.084315 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m22:33:25.084315 [debug] [Thread-1 (]: On model.data_warehouse.best_film: Close
[0m22:33:25.084315 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EBFDC0E0>]}
[0m22:33:25.091726 [info ] [Thread-1 (]: 19 of 22 OK created sql table model dbt_dev_mart.best_film ..................... [[32mSELECT 1[0m in 0.05s]
[0m22:33:25.091726 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_film
[0m22:33:25.094579 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m22:33:25.095122 [info ] [Thread-1 (]: 20 of 22 START sql table model dbt_dev_intermediate.dim_rental ................. [RUN]
[0m22:33:25.096167 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.best_film, now model.data_warehouse.dim_rental)
[0m22:33:25.096700 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m22:33:25.100349 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m22:33:25.101963 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m22:33:25.105341 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m22:33:25.105341 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:33:25.105341 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m22:33:25.105341 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:25.118448 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m22:33:25.118448 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:33:25.118448 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m22:33:25.118448 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.008 seconds
[0m22:33:25.135289 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:33:25.135289 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental" rename to "dim_rental__dbt_backup"
[0m22:33:25.135289 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:33:25.135289 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:33:25.135289 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m22:33:25.135289 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:25.135289 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m22:33:25.135289 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:33:25.135289 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m22:33:25.152514 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m22:33:25.152514 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup"
[0m22:33:25.152514 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:33:25.152514 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup" cascade
[0m22:33:25.164255 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:33:25.167154 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m22:33:25.168165 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EABDA390>]}
[0m22:33:25.169147 [info ] [Thread-1 (]: 20 of 22 OK created sql table model dbt_dev_intermediate.dim_rental ............ [[32mSELECT 16044[0m in 0.07s]
[0m22:33:25.171145 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m22:33:25.172255 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m22:33:25.173303 [info ] [Thread-1 (]: 21 of 22 START sql table model dbt_dev_intermediate.dim_staff .................. [RUN]
[0m22:33:25.173856 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m22:33:25.174926 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m22:33:25.178214 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m22:33:25.179365 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m22:33:25.184435 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m22:33:25.184435 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:33:25.184435 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m22:33:25.184435 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:25.184435 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m22:33:25.184435 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:33:25.199310 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m22:33:25.201701 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.007 seconds
[0m22:33:25.201701 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:33:25.201701 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff" rename to "dim_staff__dbt_backup"
[0m22:33:25.201701 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:33:25.215864 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:33:25.216995 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m22:33:25.218956 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:33:25.220901 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m22:33:25.221918 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:33:25.221918 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m22:33:25.227382 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:33:25.230501 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup"
[0m22:33:25.231410 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:33:25.232418 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup" cascade
[0m22:33:25.237311 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:33:25.238328 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m22:33:25.239334 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258ECCD9730>]}
[0m22:33:25.241251 [info ] [Thread-1 (]: 21 of 22 OK created sql table model dbt_dev_intermediate.dim_staff ............. [[32mSELECT 2[0m in 0.07s]
[0m22:33:25.243046 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m22:33:25.244111 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m22:33:25.245250 [info ] [Thread-1 (]: 22 of 22 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m22:33:25.246314 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.total_revenue)
[0m22:33:25.246933 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m22:33:25.250005 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m22:33:25.251696 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m22:33:25.254465 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m22:33:25.254465 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:33:25.254465 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m22:33:25.254465 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:25.269826 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m22:33:25.270859 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:33:25.270859 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    sum(amount) as total_revenue,
    payment_date
FROM
    "data_warehouse"."dbt_dev_intermediate"."fact_payment"
GROUP BY
    payment_date
  );
  
[0m22:33:25.289826 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.022 seconds
[0m22:33:25.289826 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:33:25.289826 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m22:33:25.299396 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:33:25.299396 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:33:25.299396 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m22:33:25.299396 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:33:25.299396 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m22:33:25.299396 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:33:25.299396 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m22:33:25.316460 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:33:25.316460 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m22:33:25.316460 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:33:25.316460 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m22:33:25.316460 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:33:25.316460 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m22:33:25.316460 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab8d9e08-0dcc-469e-b66a-66728607e515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EC1DC230>]}
[0m22:33:25.316460 [info ] [Thread-1 (]: 22 of 22 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.07s]
[0m22:33:25.331801 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m22:33:25.334370 [debug] [MainThread]: Using postgres connection "master"
[0m22:33:25.335518 [debug] [MainThread]: On master: BEGIN
[0m22:33:25.336116 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:33:25.351576 [debug] [MainThread]: SQL status: BEGIN in 0.018 seconds
[0m22:33:25.351576 [debug] [MainThread]: On master: COMMIT
[0m22:33:25.351576 [debug] [MainThread]: Using postgres connection "master"
[0m22:33:25.351576 [debug] [MainThread]: On master: COMMIT
[0m22:33:25.351576 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:33:25.351576 [debug] [MainThread]: On master: Close
[0m22:33:25.351576 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:33:25.351576 [debug] [MainThread]: Connection 'list_data_warehouse' was properly closed.
[0m22:33:25.360555 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_raw' was properly closed.
[0m22:33:25.360555 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m22:33:25.360555 [info ] [MainThread]: 
[0m22:33:25.363426 [info ] [MainThread]: Finished running 21 table models, 1 view model in 0 hours 0 minutes and 2.08 seconds (2.08s).
[0m22:33:25.369005 [debug] [MainThread]: Command end result
[0m22:33:25.400913 [info ] [MainThread]: 
[0m22:33:25.400913 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:33:25.400913 [info ] [MainThread]: 
[0m22:33:25.400913 [info ] [MainThread]: Done. PASS=22 WARN=0 ERROR=0 SKIP=0 TOTAL=22
[0m22:33:25.400913 [debug] [MainThread]: Command `dbt run` succeeded at 22:33:25.400913 after 3.03 seconds
[0m22:33:25.400913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EA23CC80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EA9E36B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258EC851DC0>]}
[0m22:33:26.722509 [debug] [MainThread]: Flushing usage events
[0m22:34:46.815301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CE0F8D520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CE0F8D970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CE0F8DE50>]}


============================== 22:34:46.815301 | c08076a8-c173-4443-9c5c-5ebf2f4e7d5d ==============================
[0m22:34:46.815301 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:34:46.815301 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:34:47.018148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c08076a8-c173-4443-9c5c-5ebf2f4e7d5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CE10080E0>]}
[0m22:34:47.065997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c08076a8-c173-4443-9c5c-5ebf2f4e7d5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CE11C9BE0>]}
[0m22:34:47.081015 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:34:47.081015 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:34:47.237325 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m22:34:47.237325 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\mart\mvp_actor.sql
[0m22:34:47.409723 [error] [MainThread]: Encountered an error:
Compilation Error in model mvp_actor (models\mart\mvp_actor.sql)
  unexpected '}'
    line 12
      {{ref('actor')} a
[0m22:34:47.412729 [debug] [MainThread]: Command `dbt run` failed at 22:34:47.411737 after 0.71 seconds
[0m22:34:47.413734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CE06A6E40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CE2503470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CE247B020>]}
[0m22:34:47.413734 [debug] [MainThread]: Flushing usage events
[0m22:34:58.177572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C16D4A3DA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C16FC784A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C16F3EDDF0>]}


============================== 22:34:58.177572 | 300f0a22-3cec-4f03-b180-6901be934f56 ==============================
[0m22:34:58.177572 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:34:58.177572 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse', 'log_path': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:34:58.382307 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '300f0a22-3cec-4f03-b180-6901be934f56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C16F9985F0>]}
[0m22:34:58.440662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '300f0a22-3cec-4f03-b180-6901be934f56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C16FF29670>]}
[0m22:34:58.442579 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:34:58.451688 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:34:58.583304 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m22:34:58.598910 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\mart\mvp_actor.sql
[0m22:34:58.773750 [error] [MainThread]: Encountered an error:
Compilation Error in model mvp_actor (models\mart\mvp_actor.sql)
  unexpected '}'
    line 12
      {{ref('actor')} a
[0m22:34:58.775882 [debug] [MainThread]: Command `dbt run` failed at 22:34:58.775882 after 0.70 seconds
[0m22:34:58.776787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C16FBA5550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C16FFA10A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C16FCC9CD0>]}
[0m22:34:58.777787 [debug] [MainThread]: Flushing usage events
[0m22:35:09.668805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C150C440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C150CF20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C150CDD0>]}


============================== 22:35:09.668805 | a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa ==============================
[0m22:35:09.668805 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:35:09.684463 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse', 'log_path': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:35:09.884026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C16A85F0>]}
[0m22:35:09.946111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C18FA1E0>]}
[0m22:35:09.948017 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:35:09.955786 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:35:10.074818 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m22:35:10.074818 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models\mart\mvp_actor.sql
[0m22:35:10.311030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C2D2AFC0>]}
[0m22:35:10.412314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C2D36D50>]}
[0m22:35:10.412314 [info ] [MainThread]: Found 23 models, 4 data tests, 9 sources, 417 macros
[0m22:35:10.412314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C2A3CB60>]}
[0m22:35:10.412314 [info ] [MainThread]: 
[0m22:35:10.427933 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:35:10.427933 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m22:35:10.483080 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:35:10.483080 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:35:10.483080 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:35:10.508021 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.016 seconds
[0m22:35:10.509047 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:35:10.512028 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:35:10.513001 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:35:10.513678 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:35:10.521016 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m22:35:10.522085 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:35:10.525328 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:35:10.525740 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:35:10.526327 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:35:10.548332 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.029 seconds
[0m22:35:10.555373 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:35:10.559597 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m22:35:10.560182 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:35:10.560692 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:35:10.579207 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.027 seconds
[0m22:35:10.579207 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m22:35:10.579207 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_mart'
[0m22:35:10.596962 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m22:35:10.597616 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m22:35:10.598272 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:35:10.603331 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m22:35:10.603331 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m22:35:10.603331 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m22:35:10.610345 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m22:35:10.610345 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m22:35:10.610345 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m22:35:10.610345 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_raw)
[0m22:35:10.619363 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:35:10.619363 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m22:35:10.620012 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:35:10.630081 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m22:35:10.630081 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:35:10.630081 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m22:35:10.630081 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:35:10.641587 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m22:35:10.641587 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m22:35:10.641587 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev)
[0m22:35:10.647873 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:35:10.648442 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m22:35:10.648952 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:35:10.673013 [debug] [ThreadPool]: SQL status: BEGIN in 0.031 seconds
[0m22:35:10.673013 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:35:10.673013 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m22:35:10.673013 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m22:35:10.673013 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m22:35:10.673013 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m22:35:10.689265 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_intermediate)
[0m22:35:10.692120 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m22:35:10.692650 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: BEGIN
[0m22:35:10.693165 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:35:10.704336 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m22:35:10.704336 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m22:35:10.704336 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediate"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediate'
  
[0m22:35:10.704336 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:35:10.704336 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: ROLLBACK
[0m22:35:10.704336 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: Close
[0m22:35:10.724807 [debug] [MainThread]: Using postgres connection "master"
[0m22:35:10.725523 [debug] [MainThread]: On master: BEGIN
[0m22:35:10.726035 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:35:10.732581 [debug] [MainThread]: SQL status: BEGIN in 0.008 seconds
[0m22:35:10.732581 [debug] [MainThread]: Using postgres connection "master"
[0m22:35:10.732581 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:35:10.736087 [debug] [MainThread]: SQL status: SELECT 38 in 0.008 seconds
[0m22:35:10.736087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C32D3260>]}
[0m22:35:10.736087 [debug] [MainThread]: On master: ROLLBACK
[0m22:35:10.736087 [debug] [MainThread]: Using postgres connection "master"
[0m22:35:10.736087 [debug] [MainThread]: On master: BEGIN
[0m22:35:10.751733 [debug] [MainThread]: SQL status: BEGIN in 0.002 seconds
[0m22:35:10.751733 [debug] [MainThread]: On master: COMMIT
[0m22:35:10.751733 [debug] [MainThread]: Using postgres connection "master"
[0m22:35:10.751733 [debug] [MainThread]: On master: COMMIT
[0m22:35:10.755759 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:35:10.755759 [debug] [MainThread]: On master: Close
[0m22:35:10.755759 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:35:10.755759 [info ] [MainThread]: 
[0m22:35:10.763475 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m22:35:10.764093 [info ] [Thread-1 (]: 1 of 23 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m22:35:10.765138 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m22:35:10.765944 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m22:35:10.771017 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m22:35:10.771017 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m22:35:10.803666 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m22:35:10.803666 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:35:10.803666 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m22:35:10.803666 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:35:10.824822 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m22:35:10.824822 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:35:10.825933 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."actor"
  );
  
[0m22:35:10.828827 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m22:35:10.835563 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:35:10.835563 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m22:35:10.837610 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:10.840695 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:35:10.841704 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m22:35:10.843704 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:35:10.856015 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m22:35:10.856015 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:35:10.856015 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m22:35:10.856015 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:35:10.870289 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m22:35:10.870289 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m22:35:10.870289 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m22:35:10.870289 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:35:10.870289 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m22:35:10.886645 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278BF06C050>]}
[0m22:35:10.887736 [info ] [Thread-1 (]: 1 of 23 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.12s]
[0m22:35:10.890128 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m22:35:10.890718 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m22:35:10.891871 [info ] [Thread-1 (]: 2 of 23 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m22:35:10.892425 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m22:35:10.893522 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m22:35:10.897045 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m22:35:10.898761 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m22:35:10.901845 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m22:35:10.901845 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:35:10.901845 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m22:35:10.901845 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:10.919910 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m22:35:10.919910 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:35:10.919910 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."address"
  );
  
[0m22:35:10.919910 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.003 seconds
[0m22:35:10.919910 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:35:10.919910 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m22:35:10.919910 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:10.936832 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:35:10.936832 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m22:35:10.936832 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:10.936832 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m22:35:10.936832 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:35:10.936832 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m22:35:10.936832 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:35:10.952213 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m22:35:10.954252 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m22:35:10.955259 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m22:35:10.960549 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:35:10.961650 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m22:35:10.962573 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C2D2ACC0>]}
[0m22:35:10.963555 [info ] [Thread-1 (]: 2 of 23 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.07s]
[0m22:35:10.965550 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m22:35:10.966442 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m22:35:10.967478 [info ] [Thread-1 (]: 3 of 23 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m22:35:10.968552 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m22:35:10.969512 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m22:35:10.973604 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m22:35:10.975330 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m22:35:10.978522 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m22:35:10.979523 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:35:10.980532 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m22:35:10.981556 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:11.003750 [debug] [Thread-1 (]: SQL status: BEGIN in 0.027 seconds
[0m22:35:11.003750 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:35:11.003750 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."customer"
  );
  
[0m22:35:11.003750 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.003 seconds
[0m22:35:11.003750 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:35:11.003750 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m22:35:11.018601 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.021220 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:35:11.021220 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m22:35:11.021220 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.028031 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m22:35:11.028559 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:35:11.029618 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m22:35:11.032903 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:35:11.035921 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m22:35:11.036451 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m22:35:11.037660 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m22:35:11.039332 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:35:11.039332 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m22:35:11.039332 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C33F8EC0>]}
[0m22:35:11.046045 [info ] [Thread-1 (]: 3 of 23 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.07s]
[0m22:35:11.046045 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m22:35:11.048933 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m22:35:11.050099 [info ] [Thread-1 (]: 4 of 23 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m22:35:11.050755 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m22:35:11.051985 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m22:35:11.055105 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m22:35:11.055667 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m22:35:11.059582 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m22:35:11.060683 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:35:11.061849 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m22:35:11.062361 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:11.071614 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m22:35:11.071614 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:35:11.071614 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."film"
  );
  
[0m22:35:11.071614 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.010 seconds
[0m22:35:11.086480 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:35:11.087543 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m22:35:11.087543 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.087543 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:35:11.087543 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m22:35:11.087543 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.087543 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m22:35:11.087543 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:35:11.087543 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m22:35:11.103631 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:35:11.103631 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m22:35:11.103631 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m22:35:11.103631 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m22:35:11.103631 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:35:11.103631 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m22:35:11.103631 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C340BF80>]}
[0m22:35:11.118670 [info ] [Thread-1 (]: 4 of 23 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.05s]
[0m22:35:11.120434 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m22:35:11.121003 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m22:35:11.122145 [info ] [Thread-1 (]: 5 of 23 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m22:35:11.123311 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m22:35:11.123819 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m22:35:11.126757 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m22:35:11.128475 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m22:35:11.133281 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m22:35:11.135849 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:35:11.136903 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m22:35:11.137908 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:11.148186 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:35:11.148186 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:35:11.149184 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m22:35:11.153939 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.005 seconds
[0m22:35:11.156957 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:35:11.156957 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m22:35:11.156957 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.156957 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:35:11.156957 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m22:35:11.156957 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.169697 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m22:35:11.170434 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:35:11.171749 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m22:35:11.171749 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:35:11.171749 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m22:35:11.171749 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m22:35:11.171749 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m22:35:11.186653 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:35:11.187760 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m22:35:11.188736 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C32F8140>]}
[0m22:35:11.190653 [info ] [Thread-1 (]: 5 of 23 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.07s]
[0m22:35:11.192156 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m22:35:11.193311 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m22:35:11.194376 [info ] [Thread-1 (]: 6 of 23 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m22:35:11.195476 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m22:35:11.196537 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m22:35:11.199816 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m22:35:11.201988 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m22:35:11.204381 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m22:35:11.204381 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:35:11.204381 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m22:35:11.204381 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:11.219581 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m22:35:11.219581 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:35:11.219581 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m22:35:11.219581 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m22:35:11.219581 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:35:11.234590 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m22:35:11.237303 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:35:11.237303 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:35:11.237303 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m22:35:11.237303 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.237303 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m22:35:11.237303 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:35:11.237303 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m22:35:11.252267 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:35:11.253983 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m22:35:11.253983 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m22:35:11.257034 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m22:35:11.257034 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:35:11.257034 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m22:35:11.257034 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C339C4D0>]}
[0m22:35:11.257034 [info ] [Thread-1 (]: 6 of 23 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.06s]
[0m22:35:11.267826 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m22:35:11.268582 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m22:35:11.269658 [info ] [Thread-1 (]: 7 of 23 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m22:35:11.271270 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m22:35:11.272306 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m22:35:11.275309 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m22:35:11.276460 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m22:35:11.280306 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m22:35:11.281324 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:35:11.282303 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m22:35:11.283304 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:11.287203 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m22:35:11.287203 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:35:11.287203 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m22:35:11.287203 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.002 seconds
[0m22:35:11.287203 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:35:11.301739 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m22:35:11.303938 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.303938 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:35:11.303938 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m22:35:11.303938 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.303938 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m22:35:11.303938 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:35:11.303938 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m22:35:11.318538 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:35:11.361579 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m22:35:11.362580 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m22:35:11.363595 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m22:35:11.368919 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:35:11.370005 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m22:35:11.371926 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C34270B0>]}
[0m22:35:11.372920 [info ] [Thread-1 (]: 7 of 23 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.10s]
[0m22:35:11.375162 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m22:35:11.375718 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m22:35:11.376818 [info ] [Thread-1 (]: 8 of 23 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m22:35:11.377352 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m22:35:11.377999 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m22:35:11.381399 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m22:35:11.383609 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m22:35:11.387342 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m22:35:11.387342 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:35:11.387342 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m22:35:11.387342 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:11.402572 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m22:35:11.402850 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:35:11.402850 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."payment"
  );
  
[0m22:35:11.402850 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.008 seconds
[0m22:35:11.402850 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:35:11.402850 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m22:35:11.418292 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.420721 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:35:11.420721 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m22:35:11.420721 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.420721 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m22:35:11.420721 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:35:11.420721 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m22:35:11.435103 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:35:11.436866 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m22:35:11.436866 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m22:35:11.436866 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m22:35:11.436866 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:35:11.436866 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m22:35:11.436866 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C3434200>]}
[0m22:35:11.448575 [info ] [Thread-1 (]: 8 of 23 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.06s]
[0m22:35:11.448575 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m22:35:11.451504 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m22:35:11.452078 [info ] [Thread-1 (]: 9 of 23 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m22:35:11.453234 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m22:35:11.453772 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m22:35:11.457120 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m22:35:11.458593 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m22:35:11.462355 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m22:35:11.464363 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:35:11.464363 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m22:35:11.465365 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:11.470162 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:35:11.470162 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:35:11.470162 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."rental"
  );
  
[0m22:35:11.485774 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.009 seconds
[0m22:35:11.485774 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:35:11.485774 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m22:35:11.485774 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.494380 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:35:11.494380 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m22:35:11.494380 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.494380 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m22:35:11.494380 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:35:11.494380 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m22:35:11.504243 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:35:11.504243 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m22:35:11.504243 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m22:35:11.504243 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m22:35:11.504243 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:35:11.504243 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m22:35:11.518317 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C3434A40>]}
[0m22:35:11.519334 [info ] [Thread-1 (]: 9 of 23 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.05s]
[0m22:35:11.521580 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m22:35:11.522161 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m22:35:11.523532 [info ] [Thread-1 (]: 10 of 23 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m22:35:11.524718 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m22:35:11.525297 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m22:35:11.530059 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m22:35:11.531903 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m22:35:11.535276 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m22:35:11.537324 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:35:11.538306 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m22:35:11.539535 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:11.557420 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m22:35:11.557420 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:35:11.557420 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."public"."staff"
  );
  
[0m22:35:11.557420 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.006 seconds
[0m22:35:11.570199 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:35:11.570199 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m22:35:11.570199 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.570199 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:35:11.570199 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m22:35:11.570199 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:35:11.570199 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m22:35:11.570199 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:35:11.570199 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m22:35:11.586800 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:35:11.586800 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m22:35:11.586800 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m22:35:11.586800 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m22:35:11.586800 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:35:11.586800 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m22:35:11.586800 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C1922060>]}
[0m22:35:11.599406 [info ] [Thread-1 (]: 10 of 23 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.06s]
[0m22:35:11.601719 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m22:35:11.602342 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m22:35:11.604246 [info ] [Thread-1 (]: 11 of 23 START sql table model dbt_dev_intermediate.dim_actor .................. [RUN]
[0m22:35:11.605417 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m22:35:11.606057 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m22:35:11.609412 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m22:35:11.610728 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m22:35:11.615009 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m22:35:11.616010 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:35:11.618182 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m22:35:11.618182 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:11.621307 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:35:11.621307 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:35:11.621307 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m22:35:11.621307 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m22:35:11.635647 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:35:11.635647 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor" rename to "dim_actor__dbt_backup"
[0m22:35:11.635647 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.635647 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:35:11.635647 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m22:35:11.635647 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:35:11.635647 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m22:35:11.635647 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:35:11.635647 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m22:35:11.653529 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:35:11.653529 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup"
[0m22:35:11.653529 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m22:35:11.657539 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup" cascade
[0m22:35:11.657539 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:35:11.657539 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m22:35:11.657539 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C19BB3B0>]}
[0m22:35:11.665842 [info ] [Thread-1 (]: 11 of 23 OK created sql table model dbt_dev_intermediate.dim_actor ............. [[32mSELECT 200[0m in 0.05s]
[0m22:35:11.665842 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m22:35:11.668865 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m22:35:11.669912 [info ] [Thread-1 (]: 12 of 23 START sql table model dbt_dev_intermediate.dim_address ................ [RUN]
[0m22:35:11.671069 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m22:35:11.671606 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m22:35:11.674706 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m22:35:11.676321 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m22:35:11.679702 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m22:35:11.679702 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:35:11.679702 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m22:35:11.679702 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:11.704348 [debug] [Thread-1 (]: SQL status: BEGIN in 0.028 seconds
[0m22:35:11.704348 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:35:11.704348 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m22:35:11.704348 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m22:35:11.719365 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:35:11.720364 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address" rename to "dim_address__dbt_backup"
[0m22:35:11.720364 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.720364 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:35:11.720364 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp" rename to "dim_address"
[0m22:35:11.720364 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.720364 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m22:35:11.720364 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:35:11.720364 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m22:35:11.736476 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:35:11.736476 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup"
[0m22:35:11.736476 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m22:35:11.736476 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup" cascade
[0m22:35:11.736476 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:35:11.736476 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m22:35:11.736476 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C33BC710>]}
[0m22:35:11.749671 [info ] [Thread-1 (]: 12 of 23 OK created sql table model dbt_dev_intermediate.dim_address ........... [[32mSELECT 603[0m in 0.07s]
[0m22:35:11.752138 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m22:35:11.753347 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m22:35:11.753866 [info ] [Thread-1 (]: 13 of 23 START sql table model dbt_dev_intermediate.dim_customer ............... [RUN]
[0m22:35:11.754963 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m22:35:11.756789 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m22:35:11.759981 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m22:35:11.761043 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m22:35:11.765062 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m22:35:11.765960 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:35:11.767971 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m22:35:11.768640 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:11.786803 [debug] [Thread-1 (]: SQL status: BEGIN in 0.024 seconds
[0m22:35:11.786803 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:35:11.786803 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m22:35:11.786803 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m22:35:11.786803 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:35:11.786803 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer" rename to "dim_customer__dbt_backup"
[0m22:35:11.802408 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.803949 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:35:11.803949 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m22:35:11.803949 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.803949 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m22:35:11.803949 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:35:11.803949 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m22:35:11.818322 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:35:11.820095 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup"
[0m22:35:11.820095 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m22:35:11.820095 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup" cascade
[0m22:35:11.820095 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:35:11.820095 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m22:35:11.820095 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C32A1820>]}
[0m22:35:11.820095 [info ] [Thread-1 (]: 13 of 23 OK created sql table model dbt_dev_intermediate.dim_customer .......... [[32mSELECT 599[0m in 0.07s]
[0m22:35:11.833010 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m22:35:11.833625 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m22:35:11.834739 [info ] [Thread-1 (]: 14 of 23 START sql table model dbt_dev_intermediate.dim_film ................... [RUN]
[0m22:35:11.835776 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m22:35:11.836504 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m22:35:11.839901 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m22:35:11.841167 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m22:35:11.845374 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m22:35:11.846273 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:35:11.847259 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m22:35:11.848283 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:11.857966 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:35:11.857966 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:35:11.857966 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m22:35:11.868662 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.009 seconds
[0m22:35:11.868662 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:35:11.868662 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film" rename to "dim_film__dbt_backup"
[0m22:35:11.868662 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.868662 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:35:11.868662 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp" rename to "dim_film"
[0m22:35:11.868662 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.868662 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m22:35:11.884742 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:35:11.884742 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m22:35:11.887449 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:35:11.887449 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup"
[0m22:35:11.887449 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m22:35:11.887449 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup" cascade
[0m22:35:11.887449 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:35:11.902588 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m22:35:11.903336 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C1992540>]}
[0m22:35:11.904700 [info ] [Thread-1 (]: 14 of 23 OK created sql table model dbt_dev_intermediate.dim_film .............. [[32mSELECT 1000[0m in 0.07s]
[0m22:35:11.906824 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m22:35:11.907504 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m22:35:11.908675 [info ] [Thread-1 (]: 15 of 23 START sql table model dbt_dev_intermediate.dim_film_actor ............. [RUN]
[0m22:35:11.909758 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m22:35:11.910378 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m22:35:11.913622 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m22:35:11.915172 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m22:35:11.919600 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m22:35:11.920915 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:35:11.920915 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m22:35:11.920915 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:11.936783 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m22:35:11.936783 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:35:11.936783 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m22:35:11.936783 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m22:35:11.936783 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:35:11.951576 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m22:35:11.952590 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:35:11.954366 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:35:11.957924 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m22:35:11.957924 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:11.957924 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m22:35:11.957924 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:35:11.957924 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m22:35:11.969851 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:35:11.969851 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup"
[0m22:35:11.969851 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m22:35:11.969851 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup" cascade
[0m22:35:11.969851 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:35:11.969851 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m22:35:11.969851 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C18AE690>]}
[0m22:35:11.969851 [info ] [Thread-1 (]: 15 of 23 OK created sql table model dbt_dev_intermediate.dim_film_actor ........ [[32mSELECT 5462[0m in 0.06s]
[0m22:35:11.984960 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m22:35:11.985066 [debug] [Thread-1 (]: Began running node model.data_warehouse.mvp_actor
[0m22:35:11.986339 [info ] [Thread-1 (]: 16 of 23 START sql table model dbt_dev_mart.mvp_actor .......................... [RUN]
[0m22:35:11.987483 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.mvp_actor)
[0m22:35:11.988048 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.mvp_actor
[0m22:35:11.991036 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.mvp_actor"
[0m22:35:11.992867 [debug] [Thread-1 (]: Began executing node model.data_warehouse.mvp_actor
[0m22:35:11.996181 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.mvp_actor"
[0m22:35:11.998171 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.mvp_actor"
[0m22:35:11.999165 [debug] [Thread-1 (]: On model.data_warehouse.mvp_actor: BEGIN
[0m22:35:12.000261 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:12.004235 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:35:12.004235 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.mvp_actor"
[0m22:35:12.004235 [debug] [Thread-1 (]: On model.data_warehouse.mvp_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.mvp_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."mvp_actor__dbt_tmp"
  
  
    as
  
  (
    


SELECT 
    a.first_name, 
    a.last_name, 
    COUNT(fa.film_id) AS roles_count
FROM 
    "data_warehouse"."dbt_dev_raw"."actor" a
JOIN 
    "data_warehouse"."dbt_dev_raw"."film_actor" fa ON a.actor_id = fa.actor_id
GROUP BY 
    a.actor_id, a.first_name, a.last_name
ORDER BY 
    roles_count DESC
LIMIT 1
  );
  
[0m22:35:12.004235 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.005 seconds
[0m22:35:12.018949 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.mvp_actor"
[0m22:35:12.018949 [debug] [Thread-1 (]: On model.data_warehouse.mvp_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.mvp_actor"} */
alter table "data_warehouse"."dbt_dev_mart"."mvp_actor__dbt_tmp" rename to "mvp_actor"
[0m22:35:12.022247 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:12.022247 [debug] [Thread-1 (]: On model.data_warehouse.mvp_actor: COMMIT
[0m22:35:12.022247 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.mvp_actor"
[0m22:35:12.022247 [debug] [Thread-1 (]: On model.data_warehouse.mvp_actor: COMMIT
[0m22:35:12.022247 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:35:12.022247 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."mvp_actor__dbt_backup"
[0m22:35:12.022247 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.mvp_actor"
[0m22:35:12.034622 [debug] [Thread-1 (]: On model.data_warehouse.mvp_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.mvp_actor"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."mvp_actor__dbt_backup" cascade
[0m22:35:12.037083 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m22:35:12.037083 [debug] [Thread-1 (]: On model.data_warehouse.mvp_actor: Close
[0m22:35:12.037083 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C329E030>]}
[0m22:35:12.041022 [info ] [Thread-1 (]: 16 of 23 OK created sql table model dbt_dev_mart.mvp_actor ..................... [[32mSELECT 1[0m in 0.05s]
[0m22:35:12.041022 [debug] [Thread-1 (]: Finished running node model.data_warehouse.mvp_actor
[0m22:35:12.043945 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m22:35:12.044550 [info ] [Thread-1 (]: 17 of 23 START sql table model dbt_dev_intermediate.dim_inventory .............. [RUN]
[0m22:35:12.045704 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.mvp_actor, now model.data_warehouse.dim_inventory)
[0m22:35:12.046309 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m22:35:12.049249 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m22:35:12.050495 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m22:35:12.055010 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m22:35:12.058031 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:35:12.058031 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m22:35:12.058031 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:12.069022 [debug] [Thread-1 (]: SQL status: BEGIN in 0.008 seconds
[0m22:35:12.069996 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:35:12.069996 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m22:35:12.069996 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m22:35:12.069996 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:35:12.069996 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m22:35:12.069996 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:35:12.069996 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:35:12.069996 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m22:35:12.086236 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:35:12.087577 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m22:35:12.087577 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:35:12.087577 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m22:35:12.087577 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:35:12.087577 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup"
[0m22:35:12.087577 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m22:35:12.087577 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup" cascade
[0m22:35:12.102960 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m22:35:12.102960 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m22:35:12.102960 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C33ECB30>]}
[0m22:35:12.107779 [info ] [Thread-1 (]: 17 of 23 OK created sql table model dbt_dev_intermediate.dim_inventory ......... [[32mSELECT 4581[0m in 0.06s]
[0m22:35:12.110102 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m22:35:12.110616 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m22:35:12.111808 [info ] [Thread-1 (]: 18 of 23 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m22:35:12.112853 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m22:35:12.113388 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m22:35:12.116190 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m22:35:12.117941 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m22:35:12.121706 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m22:35:12.135827 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:35:12.136820 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m22:35:12.137968 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:12.137968 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:35:12.137968 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:35:12.137968 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m22:35:12.151358 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m22:35:12.154577 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:35:12.154577 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m22:35:12.158084 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:35:12.158084 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m22:35:12.158084 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:35:12.158084 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m22:35:12.158084 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:35:12.168046 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m22:35:12.169715 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m22:35:12.169715 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m22:35:12.169715 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.002 seconds
[0m22:35:12.169715 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m22:35:12.169715 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C33EEED0>]}
[0m22:35:12.169715 [info ] [Thread-1 (]: 18 of 23 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.06s]
[0m22:35:12.169715 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m22:35:12.180986 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m22:35:12.181726 [info ] [Thread-1 (]: 19 of 23 START sql table model dbt_dev_intermediate.fact_payment ............... [RUN]
[0m22:35:12.182828 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m22:35:12.184108 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m22:35:12.187526 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m22:35:12.188860 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m22:35:12.192609 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m22:35:12.194618 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:35:12.195617 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m22:35:12.195617 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:12.219162 [debug] [Thread-1 (]: SQL status: BEGIN in 0.030 seconds
[0m22:35:12.219162 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:35:12.219162 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m22:35:12.236863 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.009 seconds
[0m22:35:12.236863 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:35:12.236863 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment" rename to "fact_payment__dbt_backup"
[0m22:35:12.236863 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:12.236863 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:35:12.236863 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m22:35:12.236863 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:12.253017 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m22:35:12.253017 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:35:12.253017 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m22:35:12.289016 [debug] [Thread-1 (]: SQL status: COMMIT in 0.033 seconds
[0m22:35:12.292011 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup"
[0m22:35:12.293016 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m22:35:12.294021 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup" cascade
[0m22:35:12.299014 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:35:12.300104 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m22:35:12.301940 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C18AD640>]}
[0m22:35:12.303537 [info ] [Thread-1 (]: 19 of 23 OK created sql table model dbt_dev_intermediate.fact_payment .......... [[32mSELECT 14596[0m in 0.12s]
[0m22:35:12.305474 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m22:35:12.306527 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_film
[0m22:35:12.307606 [info ] [Thread-1 (]: 20 of 23 START sql table model dbt_dev_mart.best_film .......................... [RUN]
[0m22:35:12.308698 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.best_film)
[0m22:35:12.309808 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_film
[0m22:35:12.313475 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_film"
[0m22:35:12.315175 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_film
[0m22:35:12.319661 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.best_film"
[0m22:35:12.321965 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_film"
[0m22:35:12.322392 [debug] [Thread-1 (]: On model.data_warehouse.best_film: BEGIN
[0m22:35:12.322392 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:12.337384 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m22:35:12.337384 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_film"
[0m22:35:12.337384 [debug] [Thread-1 (]: On model.data_warehouse.best_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."best_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    f.title AS film_title,
    COUNT(r.rental_id) AS rental_count
FROM 
    "data_warehouse"."dbt_dev_raw"."film" f
JOIN 
    "data_warehouse"."dbt_dev_raw"."inventory" i ON f.film_id = i.film_id
JOIN 
    "data_warehouse"."dbt_dev_raw"."rental" r ON i.inventory_id = r.inventory_id
GROUP BY 
    f.title
ORDER BY 
    rental_count DESC
LIMIT 1
  );
  
[0m22:35:12.356566 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.012 seconds
[0m22:35:12.359276 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_film"
[0m22:35:12.360277 [debug] [Thread-1 (]: On model.data_warehouse.best_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_film"} */
alter table "data_warehouse"."dbt_dev_mart"."best_film" rename to "best_film__dbt_backup"
[0m22:35:12.362185 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:12.364728 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_film"
[0m22:35:12.365738 [debug] [Thread-1 (]: On model.data_warehouse.best_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_film"} */
alter table "data_warehouse"."dbt_dev_mart"."best_film__dbt_tmp" rename to "best_film"
[0m22:35:12.368118 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:35:12.370166 [debug] [Thread-1 (]: On model.data_warehouse.best_film: COMMIT
[0m22:35:12.371194 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_film"
[0m22:35:12.372225 [debug] [Thread-1 (]: On model.data_warehouse.best_film: COMMIT
[0m22:35:12.376234 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:35:12.378234 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."best_film__dbt_backup"
[0m22:35:12.379253 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_film"
[0m22:35:12.380744 [debug] [Thread-1 (]: On model.data_warehouse.best_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_film"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."best_film__dbt_backup" cascade
[0m22:35:12.385750 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:35:12.387339 [debug] [Thread-1 (]: On model.data_warehouse.best_film: Close
[0m22:35:12.387339 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C33F9820>]}
[0m22:35:12.387339 [info ] [Thread-1 (]: 20 of 23 OK created sql table model dbt_dev_mart.best_film ..................... [[32mSELECT 1[0m in 0.08s]
[0m22:35:12.387339 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_film
[0m22:35:12.392956 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m22:35:12.393489 [info ] [Thread-1 (]: 21 of 23 START sql table model dbt_dev_intermediate.dim_rental ................. [RUN]
[0m22:35:12.394609 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.best_film, now model.data_warehouse.dim_rental)
[0m22:35:12.395190 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m22:35:12.398723 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m22:35:12.400553 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m22:35:12.404921 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m22:35:12.405096 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:35:12.405096 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m22:35:12.405096 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:12.417751 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m22:35:12.418887 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:35:12.418887 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m22:35:12.418887 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.009 seconds
[0m22:35:12.418887 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:35:12.418887 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental" rename to "dim_rental__dbt_backup"
[0m22:35:12.435427 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:35:12.438888 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:35:12.438888 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m22:35:12.442229 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:12.442229 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m22:35:12.442229 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:35:12.442229 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m22:35:12.452885 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m22:35:12.452885 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup"
[0m22:35:12.452885 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m22:35:12.452885 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup" cascade
[0m22:35:12.458493 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:35:12.458493 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m22:35:12.458493 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C337EC60>]}
[0m22:35:12.468080 [info ] [Thread-1 (]: 21 of 23 OK created sql table model dbt_dev_intermediate.dim_rental ............ [[32mSELECT 16044[0m in 0.06s]
[0m22:35:12.470116 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m22:35:12.470391 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m22:35:12.471494 [info ] [Thread-1 (]: 22 of 23 START sql table model dbt_dev_intermediate.dim_staff .................. [RUN]
[0m22:35:12.472765 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m22:35:12.473794 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m22:35:12.476828 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m22:35:12.478477 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m22:35:12.481791 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m22:35:12.483842 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:35:12.485817 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m22:35:12.485817 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:12.488438 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m22:35:12.488438 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:35:12.488438 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m22:35:12.501831 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.009 seconds
[0m22:35:12.501831 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:35:12.501831 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff" rename to "dim_staff__dbt_backup"
[0m22:35:12.501831 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:35:12.501831 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:35:12.516837 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m22:35:12.518870 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:35:12.519424 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m22:35:12.519424 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:35:12.519424 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m22:35:12.519424 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m22:35:12.519424 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup"
[0m22:35:12.519424 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m22:35:12.519424 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup" cascade
[0m22:35:12.535532 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:35:12.535532 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m22:35:12.535532 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C338D9D0>]}
[0m22:35:12.535532 [info ] [Thread-1 (]: 22 of 23 OK created sql table model dbt_dev_intermediate.dim_staff ............. [[32mSELECT 2[0m in 0.06s]
[0m22:35:12.535532 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m22:35:12.541947 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m22:35:12.542999 [info ] [Thread-1 (]: 23 of 23 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m22:35:12.544260 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.total_revenue)
[0m22:35:12.544874 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m22:35:12.548365 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m22:35:12.549647 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m22:35:12.554594 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m22:35:12.554594 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:35:12.558612 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m22:35:12.558612 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:35:12.568627 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m22:35:12.568865 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:35:12.568865 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    sum(amount) as total_revenue,
    payment_date
FROM
    "data_warehouse"."dbt_dev_intermediate"."fact_payment"
GROUP BY
    payment_date
  );
  
[0m22:35:12.594398 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.023 seconds
[0m22:35:12.594398 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:35:12.594398 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m22:35:12.594398 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:12.602867 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:35:12.602867 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m22:35:12.602867 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:35:12.602867 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m22:35:12.602867 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:35:12.602867 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m22:35:12.618782 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m22:35:12.621770 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m22:35:12.622777 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m22:35:12.622777 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m22:35:12.628262 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:35:12.629261 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m22:35:12.630269 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a40bd3d7-e6c0-43f6-b965-f7d03bdd31aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C33ED730>]}
[0m22:35:13.939049 [info ] [Thread-1 (]: 23 of 23 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.09s]
[0m22:35:13.939049 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m22:35:13.954615 [debug] [MainThread]: Using postgres connection "master"
[0m22:35:13.955614 [debug] [MainThread]: On master: BEGIN
[0m22:35:13.956811 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:35:13.962308 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m22:35:13.962308 [debug] [MainThread]: On master: COMMIT
[0m22:35:13.962308 [debug] [MainThread]: Using postgres connection "master"
[0m22:35:13.962308 [debug] [MainThread]: On master: COMMIT
[0m22:35:13.962308 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:35:13.962308 [debug] [MainThread]: On master: Close
[0m22:35:13.972912 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:35:13.973986 [debug] [MainThread]: Connection 'list_data_warehouse' was properly closed.
[0m22:35:13.974944 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_intermediate' was properly closed.
[0m22:35:13.975954 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m22:35:13.976467 [info ] [MainThread]: 
[0m22:35:13.977619 [info ] [MainThread]: Finished running 22 table models, 1 view model in 0 hours 0 minutes and 3.55 seconds (3.55s).
[0m22:35:13.981723 [debug] [MainThread]: Command end result
[0m22:35:14.009565 [info ] [MainThread]: 
[0m22:35:14.010564 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:35:14.012606 [info ] [MainThread]: 
[0m22:35:14.012606 [info ] [MainThread]: Done. PASS=23 WARN=0 ERROR=0 SKIP=0 TOTAL=23
[0m22:35:14.012606 [debug] [MainThread]: Command `dbt run` succeeded at 22:35:14.012606 after 4.46 seconds
[0m22:35:14.012606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C3257C20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C162EE40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278C162ED20>]}
[0m22:35:14.012606 [debug] [MainThread]: Flushing usage events
[0m22:39:07.450439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002514447E690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002514447E5D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002514447D340>]}


============================== 22:39:07.454675 | b68ded9e-4d8a-468a-adfc-78f0371a13e4 ==============================
[0m22:39:07.454675 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:39:07.456671 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m22:39:07.647801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b68ded9e-4d8a-468a-adfc-78f0371a13e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251444A0230>]}
[0m22:39:07.706680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b68ded9e-4d8a-468a-adfc-78f0371a13e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251444A30B0>]}
[0m22:39:07.708636 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:39:07.716600 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:39:07.856332 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:39:07.857333 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:39:07.887239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b68ded9e-4d8a-468a-adfc-78f0371a13e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025144703E60>]}
[0m22:39:07.914689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b68ded9e-4d8a-468a-adfc-78f0371a13e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002514593E300>]}
[0m22:39:07.914689 [info ] [MainThread]: Found 23 models, 4 data tests, 9 sources, 417 macros
[0m22:39:07.914689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b68ded9e-4d8a-468a-adfc-78f0371a13e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251441FCA10>]}
[0m22:39:07.930872 [info ] [MainThread]: 
[0m22:39:07.931869 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:39:07.937569 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev_mart'
[0m22:39:08.001123 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m22:39:08.002125 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m22:39:08.003124 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:39:08.017488 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m22:39:08.017488 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m22:39:08.018518 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m22:39:08.022491 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.004 seconds
[0m22:39:08.024507 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m22:39:08.025495 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m22:39:08.026509 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_raw)
[0m22:39:08.029545 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:39:08.030596 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m22:39:08.031147 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:39:08.052372 [debug] [ThreadPool]: SQL status: BEGIN in 0.028 seconds
[0m22:39:08.052372 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m22:39:08.052372 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m22:39:08.052372 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:39:08.052372 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m22:39:08.052372 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m22:39:08.068596 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev)
[0m22:39:08.072164 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:39:08.072227 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m22:39:08.072865 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:39:08.109122 [debug] [ThreadPool]: SQL status: BEGIN in 0.036 seconds
[0m22:39:08.109122 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m22:39:08.110121 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m22:39:08.114121 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m22:39:08.115121 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m22:39:08.117120 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m22:39:08.118121 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_intermediate)
[0m22:39:08.121472 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m22:39:08.122066 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: BEGIN
[0m22:39:08.122612 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:39:08.149872 [debug] [ThreadPool]: SQL status: BEGIN in 0.035 seconds
[0m22:39:08.149872 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m22:39:08.149872 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediate"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediate'
  
[0m22:39:08.149872 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:39:08.149872 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: ROLLBACK
[0m22:39:08.165407 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: Close
[0m22:39:08.173113 [debug] [MainThread]: Using postgres connection "master"
[0m22:39:08.173680 [debug] [MainThread]: On master: BEGIN
[0m22:39:08.174200 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:39:08.203104 [debug] [MainThread]: SQL status: BEGIN in 0.029 seconds
[0m22:39:08.204103 [debug] [MainThread]: Using postgres connection "master"
[0m22:39:08.204103 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:39:08.214104 [debug] [MainThread]: SQL status: SELECT 38 in 0.009 seconds
[0m22:39:08.216102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b68ded9e-4d8a-468a-adfc-78f0371a13e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025144700AA0>]}
[0m22:39:08.217103 [debug] [MainThread]: On master: ROLLBACK
[0m22:39:08.219105 [debug] [MainThread]: On master: Close
[0m22:39:08.220103 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:39:08.221107 [info ] [MainThread]: 
[0m22:39:08.226286 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m22:39:08.227387 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_warehouse.actor'
[0m22:39:08.227927 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m22:39:08.235668 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m22:39:08.237672 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m22:39:08.238662 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m22:39:08.239663 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m22:39:08.240664 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m22:39:08.241665 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m22:39:08.245314 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m22:39:08.247325 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m22:39:08.248792 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m22:39:08.249814 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m22:39:08.249814 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m22:39:08.250802 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m22:39:08.254886 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m22:39:08.255800 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m22:39:08.257821 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m22:39:08.258814 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m22:39:08.259803 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m22:39:08.260802 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m22:39:08.263804 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m22:39:08.265087 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m22:39:08.267097 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m22:39:08.267097 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m22:39:08.268107 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m22:39:08.269094 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m22:39:08.273101 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m22:39:08.274114 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m22:39:08.276107 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m22:39:08.277111 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m22:39:08.278111 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m22:39:08.278111 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m22:39:08.282108 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m22:39:08.283110 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m22:39:08.285151 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m22:39:08.285151 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m22:39:08.286155 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m22:39:08.287117 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m22:39:08.290431 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m22:39:08.291440 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m22:39:08.292345 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m22:39:08.293398 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m22:39:08.294346 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m22:39:08.295350 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m22:39:08.298338 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m22:39:08.299346 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m22:39:08.300339 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m22:39:08.301344 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m22:39:08.302345 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m22:39:08.303348 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m22:39:08.306346 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m22:39:08.308350 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m22:39:08.310343 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m22:39:08.311339 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m22:39:08.311339 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m22:39:08.312339 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m22:39:08.315338 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m22:39:08.317345 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m22:39:08.318345 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m22:39:08.319339 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m22:39:08.319339 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m22:39:08.320338 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m22:39:08.325062 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m22:39:08.326972 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m22:39:08.329014 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m22:39:08.329979 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m22:39:08.329979 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m22:39:08.330975 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m22:39:08.333963 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m22:39:08.335964 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m22:39:08.336972 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m22:39:08.337972 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m22:39:08.337972 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m22:39:08.338962 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m22:39:08.342061 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m22:39:08.342969 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m22:39:08.345006 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m22:39:08.345006 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m22:39:08.345963 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m22:39:08.345963 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m22:39:08.349063 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m22:39:08.350225 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m22:39:08.350225 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m22:39:08.350225 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m22:39:08.350225 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m22:39:08.350225 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m22:39:08.350225 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m22:39:08.350225 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m22:39:08.350225 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m22:39:08.350225 [debug] [Thread-1 (]: Began running node model.data_warehouse.mvp_actor
[0m22:39:08.350225 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.mvp_actor)
[0m22:39:08.350225 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.mvp_actor
[0m22:39:08.365857 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.mvp_actor"
[0m22:39:08.365857 [debug] [Thread-1 (]: Began executing node model.data_warehouse.mvp_actor
[0m22:39:08.365857 [debug] [Thread-1 (]: Finished running node model.data_warehouse.mvp_actor
[0m22:39:08.365857 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m22:39:08.365857 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.mvp_actor, now model.data_warehouse.dim_inventory)
[0m22:39:08.365857 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m22:39:08.365857 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m22:39:08.365857 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m22:39:08.365857 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m22:39:08.365857 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m22:39:08.365857 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m22:39:08.381477 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m22:39:08.382741 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m22:39:08.382741 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m22:39:08.382741 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m22:39:08.388246 [debug] [Thread-1 (]: Began running node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m22:39:08.388246 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710)
[0m22:39:08.388246 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m22:39:08.397252 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710"
[0m22:39:08.397252 [debug] [Thread-1 (]: Began executing node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m22:39:08.397252 [debug] [Thread-1 (]: Finished running node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m22:39:08.397252 [debug] [Thread-1 (]: Began running node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m22:39:08.397252 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710, now test.data_warehouse.unique_my_first_dbt_model_id.16e066b321)
[0m22:39:08.397252 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m22:39:08.397252 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.unique_my_first_dbt_model_id.16e066b321"
[0m22:39:08.412887 [debug] [Thread-1 (]: Began executing node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m22:39:08.412887 [debug] [Thread-1 (]: Finished running node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m22:39:08.412887 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m22:39:08.412887 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.unique_my_first_dbt_model_id.16e066b321, now model.data_warehouse.fact_payment)
[0m22:39:08.412887 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m22:39:08.412887 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m22:39:08.412887 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m22:39:08.412887 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m22:39:08.412887 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_film
[0m22:39:08.412887 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.best_film)
[0m22:39:08.412887 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_film
[0m22:39:08.428511 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_film"
[0m22:39:08.428511 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_film
[0m22:39:08.428511 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_film
[0m22:39:08.428511 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m22:39:08.428511 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.best_film, now model.data_warehouse.dim_rental)
[0m22:39:08.428511 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m22:39:08.428511 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m22:39:08.428511 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m22:39:08.428511 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m22:39:08.428511 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m22:39:08.444224 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m22:39:08.444734 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m22:39:08.444734 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m22:39:08.444734 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m22:39:08.444734 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m22:39:08.444734 [debug] [Thread-1 (]: Began running node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m22:39:08.444734 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778)
[0m22:39:08.444734 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m22:39:08.444734 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778"
[0m22:39:08.444734 [debug] [Thread-1 (]: Began executing node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m22:39:08.444734 [debug] [Thread-1 (]: Finished running node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m22:39:08.460243 [debug] [Thread-1 (]: Began running node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m22:39:08.460243 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778, now test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493)
[0m22:39:08.460243 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m22:39:08.460243 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493"
[0m22:39:08.468298 [debug] [Thread-1 (]: Began executing node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m22:39:08.469864 [debug] [Thread-1 (]: Finished running node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m22:39:08.470950 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m22:39:08.471481 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493, now model.data_warehouse.total_revenue)
[0m22:39:08.472015 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m22:39:08.475911 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m22:39:08.477557 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m22:39:08.478709 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m22:39:08.480659 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:39:08.480659 [debug] [MainThread]: Connection 'list_data_warehouse_dbt_dev_intermediate' was properly closed.
[0m22:39:08.481657 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m22:39:08.485656 [debug] [MainThread]: Command end result
[0m22:39:08.585494 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m22:39:08.585494 [info ] [MainThread]: Building catalog
[0m22:39:08.598978 [debug] [ThreadPool]: Acquiring new postgres connection 'data_warehouse.information_schema'
[0m22:39:08.607979 [debug] [ThreadPool]: Using postgres connection "data_warehouse.information_schema"
[0m22:39:08.607979 [debug] [ThreadPool]: On data_warehouse.information_schema: BEGIN
[0m22:39:08.608984 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:39:08.616974 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m22:39:08.617994 [debug] [ThreadPool]: Using postgres connection "data_warehouse.information_schema"
[0m22:39:08.618990 [debug] [ThreadPool]: On data_warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "data_warehouse.information_schema"} */

    
    

    select
        'data_warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('film_actor')) or (upper(sch.nspname) = upper('dbt_dev') and
           upper(tbl.relname) = upper('my_first_dbt_model')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('inventory')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('dim_inventory')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('best_film')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('payment')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('address')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('rental')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('film')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('inventory')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('mvp_actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('customer')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('dim_staff')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('payment')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('total_revenue')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('rental')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('dim_rental')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('film_actor')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('customer')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('dim_film')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('actor')) or (upper(sch.nspname) = upper('dbt_dev') and
           upper(tbl.relname) = upper('my_second_dbt_model')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('dim_film_actor')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('fact_payment')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('actor')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('address')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('film')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('dim_address')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('staff')) or (upper(sch.nspname) = upper('dbt_dev_intermediate') and
           upper(tbl.relname) = upper('dim_actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('staff')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m22:39:08.625978 [debug] [ThreadPool]: SQL status: SELECT 207 in 0.006 seconds
[0m22:39:08.637314 [debug] [ThreadPool]: On data_warehouse.information_schema: ROLLBACK
[0m22:39:08.640316 [debug] [ThreadPool]: On data_warehouse.information_schema: Close
[0m22:39:08.682612 [info ] [MainThread]: Catalog written to C:\Users\new user\OneDrive\Learning Progress Review\Data Engineering\Project2\dbt\data_warehouse\target\catalog.json
[0m22:39:08.684668 [debug] [MainThread]: Command `dbt docs generate` succeeded at 22:39:08.684668 after 1.35 seconds
[0m22:39:08.685723 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m22:39:08.685723 [debug] [MainThread]: Connection 'data_warehouse.information_schema' was properly closed.
[0m22:39:08.686671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251458FF620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251458FB530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251444FE510>]}
[0m22:39:08.687675 [debug] [MainThread]: Flushing usage events
[0m22:39:15.967267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019FC2BE1970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019FC2BE1490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019FC37F5BE0>]}


============================== 22:39:15.970304 | 80e1ed02-55d2-4879-a6a4-dc8ac1fd77f5 ==============================
[0m22:39:15.970304 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:39:15.971398 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\new user\\OneDrive\\Learning Progress Review\\Data Engineering\\Project2\\dbt\\data_warehouse\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs serve', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:39:16.157611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '80e1ed02-55d2-4879-a6a4-dc8ac1fd77f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019FC3A18410>]}
[0m22:39:16.218131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '80e1ed02-55d2-4879-a6a4-dc8ac1fd77f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019FC3AF9760>]}
